{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(seed=41)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import scipy.stats as st\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load kyc\n",
    "df_kyc = pd.read_csv('kyc.csv')\n",
    "\n",
    "# load cash\n",
    "df_cash = pd.read_csv('cash_trxns.csv')\n",
    "\n",
    "# load emt\n",
    "df_emt = pd.read_csv('emt_trxns.csv')\n",
    "\n",
    "# load wire\n",
    "df_wire = pd.read_csv('wire_trxns.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process KYC Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binarize gender column\n",
    "<br>\n",
    "\n",
    "One-hot_encode the Occupation column. Occupations are not ordinal, and so ordinal encoding would not be ideal.\n",
    "<br>\n",
    "\n",
    "Not including Name as this feature is not generalizable to unseen data. Same with cust_id.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarized gender\n",
    "df_kyc.loc[(df_kyc.Gender)=='female', 'Gender'] = 0\n",
    "df_kyc.loc[(df_kyc.Gender)=='male', 'Gender'] = 1\n",
    "df_kyc.loc[(df_kyc.Gender)=='other', 'Gender'] = -1\n",
    "\n",
    "# One-hot-encode Occupation\n",
    "df_kyc = pd.get_dummies(df_kyc, prefix=['Occ'], columns=['Occupation'], dtype=int)\n",
    "\n",
    "# # Ordinal-encode Occupation\n",
    "# df_kyc['Occupation']= df_kyc['Occupation'].map(dict(zip(df_kyc['Occupation'].unique(), np.arange(len(df_kyc['Occupation'].unique())))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Cash Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can join the Cash dataframe to the KYC dataframe by customer id. <br>\n",
    "\n",
    "In the Cash dataframe, we do not require trxn_id, as it is not useful for the classification task. <br>\n",
    "\n",
    "The amount can be unified by sum. The sum might be more informative than average. As large/small sums <br> \n",
    "express information in the average, while averages might dampen the signal between extreme (really large and really small) amounts <br>\n",
    "\n",
    "The type, we can count the number of deposits and number of withdrawals for each cust_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Type\n",
    "\n",
    "# get number of deposts for each cust_id\n",
    "df_cash_deposits = df_cash.loc[df_cash.type =='deposit'].groupby('cust_id').count()['type']\n",
    "# merge with df_cash\n",
    "df_cash = df_cash.merge(df_cash_deposits.rename('deposits'), how = 'left', left_on='cust_id', right_on='cust_id').fillna(0)\n",
    "\n",
    "\n",
    "# get number of withdrawals for each cust_id\n",
    "df_cash_withdrawals = df_cash.loc[df_cash.type =='withdrawal'].groupby('cust_id').count()['type']\n",
    "# merge with df_cash\n",
    "df_cash = df_cash.merge(df_cash_withdrawals.rename('withdrawals'), how = 'left', left_on='cust_id', right_on='cust_id').fillna(0)\n",
    "\n",
    "\n",
    "# Process Amount\n",
    "\n",
    "# get total sum of amounts \n",
    "df_cash_amounts = df_cash.groupby('cust_id')['amount'].sum()\n",
    "df_cash = df_cash.merge(df_cash_amounts.rename('amount_cash'), how = 'left', left_on='cust_id', right_on='cust_id')\n",
    "\n",
    "# drop duplicates\n",
    "df_cash = df_cash.drop_duplicates('cust_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process EMT Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add the emt data to the kyc dataset by customer id. <br>\n",
    "\n",
    "We can get the the total amount recieved and total amount sent for each customer id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total wire amount sent\n",
    "df_amount_sent = df_emt.drop(columns=['emt message']).groupby('id sender').sum()['emt value']\n",
    "# merge with df_emt\n",
    "df_emt = df_emt.merge(df_amount_sent.rename('amount_emt_sent'), how = 'left', left_on='id sender', right_on='id sender').fillna(0)\n",
    "\n",
    "# get total wire amount recieved\n",
    "df_amount_received = df_emt.drop(columns=['emt message']).groupby('id receiver').sum()['emt value']\n",
    "# merge with df_emt\n",
    "df_emt = df_emt.merge(df_amount_received.rename('amount_emt_received'), how = 'left', left_on='id receiver', right_on='id receiver').fillna(0)\n",
    "\n",
    "# get a message-sent flag\n",
    "df_emt.loc[df_emt['emt message'] != 0, 'message_flag'] = 1\n",
    "df_emt['message_flag'].fillna(0, inplace=True)\n",
    "message_flag_dict  = dict(zip(df_emt['id sender'].unique(), \n",
    "                            df_emt[['id sender', 'message_flag']].groupby('id sender').sum()['message_flag']))\n",
    "\n",
    "# drop duplicates\n",
    "df_emt_sender = df_emt.drop_duplicates('id sender')\n",
    "df_emt_receiver = df_emt.drop_duplicates('id receiver')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Wire Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add the wire data to the kyc dataset by customer id. <br>\n",
    "\n",
    "We can get the the total amount recieved and total amount sent for each customer id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total wire amount sent\n",
    "df_amount_sent = df_wire.groupby('id sender').sum()['wire value']\n",
    "# merge with df_wire\n",
    "df_wire = df_wire.merge(df_amount_sent.rename('amount_wire_sent'), how = 'left', left_on='id sender', right_on='id sender').fillna(0)\n",
    "\n",
    "# get total wire amount recieved\n",
    "df_amount_received = df_wire.groupby('id receiver').sum()['wire value']\n",
    "# merge with df_wire\n",
    "df_wire = df_wire.merge(df_amount_received.rename('amount_wire_received'), how = 'left', left_on='id receiver', right_on='id receiver').fillna(0)\n",
    "\n",
    "# # domestic transaction\n",
    "# df_wire['domestic'] = 0\n",
    "# df_wire.loc[(df_wire['country sender'] == 'CA') & (df_wire['country receiver'] == 'CA'), \n",
    "#             'domestic'] = 1\n",
    "# # foregin outbound transaction\n",
    "# df_wire['foreign_outbound'] = 0\n",
    "# df_wire.loc[(df_wire['country sender'] == 'CA') & (df_wire['country receiver'] != 'CA'), \n",
    "#             'foreign_outbound'] = 1\n",
    "# # foregin inbound transaction\n",
    "# df_wire['foreign_inbound'] = 0\n",
    "# df_wire.loc[(df_wire['country sender'] != 'CA') & (df_wire['country receiver'] == 'CA'), \n",
    "#             'foreign_inbound'] = 1\n",
    "# # unkown transaction\n",
    "# df_wire['unknown'] = 0\n",
    "# df_wire.loc[(df_wire['country sender'].isnull()) | (df_wire['country receiver'].isnull()), \n",
    "#             'unknown'] = 1\n",
    "\n",
    "# # Transaction Dictionaries\n",
    "# sender_domestic_dict = dict(zip(df_wire[['id sender', 'domestic']].groupby('id sender').sum().index,\n",
    "#                                 df_wire[['id sender', 'domestic']].groupby('id sender').sum()['domestic']))\n",
    "# sender_foreign_dict = dict(zip(df_wire[['id sender', 'foreign_outbound']].groupby('id sender').sum().index,\n",
    "#                                 df_wire[['id sender', 'foreign_outbound']].groupby('id sender').sum()['foreign_outbound']))\n",
    "# sender_other_dict = dict(zip(df_wire[['id sender', 'unknown']].groupby('id sender').sum().index,\n",
    "#                                 df_wire[['id sender', 'unknown']].groupby('id sender').sum()['unknown']))\n",
    "\n",
    "# receiver_domestic_dict = dict(zip(df_wire[['id receiver', 'domestic']].groupby('id receiver').sum().index,\n",
    "#                                 df_wire[['id receiver', 'domestic']].groupby('id receiver').sum()['domestic']))\n",
    "# receiver_foreign_dict= dict(zip(df_wire[['id receiver', 'foreign_inbound']].groupby('id receiver').sum().index,\n",
    "#                                 df_wire[['id receiver', 'foreign_inbound']].groupby('id receiver').sum()['foreign_inbound']))\n",
    "# receiver_other_dict = dict(zip(df_wire[['id receiver', 'unknown']].groupby('id receiver').sum().index,\n",
    "#                                 df_wire[['id receiver', 'unknown']].groupby('id receiver').sum()['unknown']))\n",
    "\n",
    "\n",
    "# Country Dictionary\n",
    "df_countries = pd.concat([df_wire[['id sender', 'country sender']].rename(columns = {'id sender': 'id', 'country sender': 'country'}) , \n",
    "                         df_wire[['id receiver', 'country receiver']].rename(columns = {'id receiver': 'id', 'country receiver': 'country'})])\n",
    "df_countries.drop_duplicates(inplace=True)\n",
    "\n",
    "country_dict = dict(zip(df_countries['id'], \n",
    "                            df_countries['country']))\n",
    "\n",
    "\n",
    "# drop duplicates\n",
    "df_wire_sender = df_wire.drop_duplicates('id sender')\n",
    "df_wire_receiver = df_wire.drop_duplicates('id receiver')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can merge all the new features back to the kyc dataset on customer id. <br>\n",
    "\n",
    "Empty values we can assign zero, as imputing the values will create erroneous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge df_cash with df_kyc\n",
    "df_kyc=df_kyc.merge(df_cash[['cust_id','deposits','withdrawals','amount_cash']], how = 'outer', left_on='cust_id', right_on='cust_id')\n",
    "\n",
    "\n",
    "# merge df_emt with df_kyc\n",
    "df_kyc=df_kyc.merge(df_emt_sender[['id sender','amount_emt_sent']], how = 'left', left_on='cust_id', right_on='id sender')\n",
    "df_kyc=df_kyc.merge(df_emt_receiver[['id receiver','amount_emt_received']], how = 'left', left_on='cust_id', right_on='id receiver')\n",
    "\n",
    "# merge df_wire with df_kyc\n",
    "df_kyc=df_kyc.merge(df_wire_sender[['id sender','amount_wire_sent']], how = 'left', left_on='cust_id', right_on='id sender')\n",
    "df_kyc=df_kyc.merge(df_wire_receiver[['id receiver','amount_wire_received']], how = 'left', left_on='cust_id', right_on='id receiver')\n",
    "\n",
    "# # add dictionaries\n",
    "df_kyc['message_flag'] = df_kyc['cust_id'].map(message_flag_dict)\n",
    "df_kyc['country'] = df_kyc['cust_id'].map(country_dict)\n",
    "# df_kyc['sender_domestic'] = df_kyc['cust_id'].map(sender_domestic_dict).fillna(0)\n",
    "# df_kyc['sender_foreign'] = df_kyc['cust_id'].map(sender_foreign_dict).fillna(0)\n",
    "# # df_kyc['sender_other'] = df_kyc['cust_id'].map(sender_other_dict).fillna(0) # no others in kyc dataset\n",
    "# df_kyc['receiver_domestic'] = df_kyc['cust_id'].map(receiver_domestic_dict).fillna(0)\n",
    "# df_kyc['receiver_foreign'] = df_kyc['cust_id'].map(receiver_foreign_dict).fillna(0)\n",
    "# # df_kyc['receiver_other'] = df_kyc['cust_id'].map(receiver_other_dict).fillna(0) # no others in kyc dataset\n",
    "\n",
    "# one-hot-encode country\n",
    "df_kyc = pd.get_dummies(df_kyc, prefix=['Country'], columns=['country'], dtype=int)\n",
    "\n",
    "# remove Name and cust_id from dataframe\n",
    "df_kyc.drop(columns=['Name', 'cust_id', 'id sender_x', 'id sender_y', 'id receiver_x', 'id receiver_y'], inplace=True)\n",
    "df_kyc = df_kyc.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can create a basic z-score outlier function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_zscore(df, train_mean, train_std):\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    outliers = np.where(((df - train_mean)/train_std) >= 3)\n",
    "    # replaceo outliers with null values\n",
    "    for o in outliers:\n",
    "        df.iloc[o[0],o[1]] = np.nan\n",
    "    \n",
    "    # Fill null values with mean\n",
    "    df = df.fillna(df.mean())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split, Filter Outliers, Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "df_train = df_kyc.iloc[:int(len(df_kyc)*0.75),:]\n",
    "df_val = df_kyc.iloc[int(len(df_kyc)*0.75):int(len(df_kyc)*0.85),:]\n",
    "df_test = df_kyc.iloc[int(len(df_kyc)*0.85):,:]\n",
    "\n",
    "# remove outliers\n",
    "df_train = detect_outliers_zscore(df_train, df_train.mean(), df_train.std())\n",
    "df_val = detect_outliers_zscore(df_val, df_train.mean(), df_train.std())\n",
    "\n",
    "# Split target and non-target on training data\n",
    "df_train_non_target = df_train.loc[df_train.label == 0]\n",
    "df_train_target = df_train.loc[df_train.label == 1]\n",
    "\n",
    "# Standardize data\n",
    "columns_to_scale = ['Age', 'Tenure','amount_cash', 'amount_emt_sent', 'deposits', 'withdrawals',\n",
    "                    'amount_emt_received','amount_wire_sent','amount_wire_received',]\n",
    "# columns_to_scale = ['Age', 'Tenure','amount_cash', 'amount_emt_sent', 'deposits', 'withdrawals',\n",
    "#                     'amount_emt_received','amount_wire_sent','amount_wire_received', 'sender_domestic',\n",
    "#                     'sender_foreign', 'receiver_domestic', 'receiver_foreign']\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# copy data\n",
    "df_train_sc = df_train.copy()\n",
    "df_val_sc = df_val.copy()\n",
    "df_test_sc = df_test.copy()\n",
    "\n",
    "# scale training set\n",
    "scaled_train = sc.fit_transform(df_train[columns_to_scale])\n",
    "df_train_sc[columns_to_scale] = scaled_train\n",
    "# scale validation set\n",
    "scaled_val = sc.transform(df_val[columns_to_scale])\n",
    "df_val_sc[columns_to_scale] = scaled_val\n",
    "# scale test set\n",
    "\n",
    "\n",
    "# Split target and non-target on scaled training data\n",
    "df_train_non_target_sc = df_train_sc.loc[df_train_sc.label == 0]\n",
    "df_train_target_sc = df_train_sc.loc[df_train_sc.label == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalance Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 142714 non-target lables in training\n",
      "There are 4127 target lables in trianing\n",
      "There are 34.58056699781924 times more non-target lables\n",
      "There are 19027 non-target lables in validation\n",
      "There are 552 target lables in validation\n",
      "There are 34.469202898550726 times more non-target lables\n"
     ]
    }
   ],
   "source": [
    "df_kyc.label.value_counts()\n",
    "\n",
    "print('There are', df_train.label.value_counts()[0], 'non-target lables in training')\n",
    "print('There are', df_train.label.value_counts()[1], 'target lables in trianing')\n",
    "print('There are', df_train.label.value_counts()[0]/df_train.label.value_counts()[1], 'times more non-target lables')\n",
    "\n",
    "print('There are', df_val.label.value_counts()[0], 'non-target lables in validation')\n",
    "print('There are', df_val.label.value_counts()[1], 'target lables in validation')\n",
    "print('There are', df_val.label.value_counts()[0]/df_val.label.value_counts()[1], 'times more non-target lables')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start with a random forest and see the effects of upsampling and downsampling on the performance. Random forest models are fairly intuitive and easy to tune if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.27      0.42     19027\n",
      "           1       0.04      0.99      0.07       552\n",
      "\n",
      "    accuracy                           0.29     19579\n",
      "   macro avg       0.52      0.63      0.25     19579\n",
      "weighted avg       0.97      0.29      0.41     19579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Downsample minority class\n",
    "df_kyc_majority_downsampled = resample(df_train_non_target_sc, \n",
    "                                 replace=True,     \n",
    "                                 n_samples=len(df_train_target_sc))\n",
    "df_downsampled = pd.concat([df_train_target_sc,df_kyc_majority_downsampled])\n",
    "\n",
    "# shuffle dataset\n",
    "df_downsampled = df_downsampled.sample(frac=1)\n",
    "\n",
    "# get logistic regressor\n",
    "# clf = LogisticRegression()\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# define classifier\n",
    "clf = clf.fit(df_downsampled.drop(columns=['label']), df_downsampled['label'])\n",
    "\n",
    "# prediction dfs\n",
    "df_kyc_val_X = df_val.drop(columns=['label'])\n",
    "df_kyc_val_y = df_val['label']\n",
    "\n",
    "# predict\n",
    "predictions = clf.predict(df_kyc_val_X)\n",
    "\n",
    "# report\n",
    "print(classification_report(df_kyc_val_y,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     19027\n",
      "           1       0.50      0.23      0.32       552\n",
      "\n",
      "    accuracy                           0.97     19579\n",
      "   macro avg       0.74      0.61      0.65     19579\n",
      "weighted avg       0.96      0.97      0.97     19579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Upsample minority class\n",
    "df_kyc_minority_upsampled = resample(df_train_target_sc, \n",
    "                                 replace=True,     \n",
    "                                 n_samples=len(df_train_non_target_sc))\n",
    "df_upsampled = pd.concat([df_train_non_target_sc,df_kyc_minority_upsampled])\n",
    "\n",
    "# shuffle dataset\n",
    "df_upsampled = df_upsampled.sample(frac=1)\n",
    "\n",
    "# get logistic regressor\n",
    "# clf = LogisticRegression()\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# define classifier\n",
    "clf = clf.fit(df_upsampled.drop(columns=['label']), df_upsampled['label'])\n",
    "\n",
    "# prediction dfs\n",
    "df_kyc_val_X = df_val.drop(columns=['label'])\n",
    "df_kyc_val_y = df_val['label']\n",
    "\n",
    "# predict\n",
    "predictions = clf.predict(df_kyc_val_X)\n",
    "\n",
    "# report\n",
    "print(classification_report(df_kyc_val_y,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some custom models for further experimentation. These models will be composite models, containing multiple versions of themselves that can then be used in multi-voting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogistic(LogisticRegression):\n",
    "    def __init__(self, number_of_models, penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, \n",
    "                 intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', \n",
    "                 max_iter=500, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None):\n",
    "        super().__init__(penalty=penalty, dual=dual, tol=tol, C=C, fit_intercept=fit_intercept, \n",
    "                 intercept_scaling=intercept_scaling, class_weight=class_weight, random_state=random_state,\n",
    "                 solver=solver, max_iter=max_iter, multi_class=multi_class, verbose=verbose, warm_start=warm_start,\n",
    "                 n_jobs=n_jobs, l1_ratio=n_jobs)\n",
    "\n",
    "        self.model = [LogisticRegression() for i in range(number_of_models)]\n",
    "    \n",
    "    def fit(self, sample_ids, df_kyc_train):\n",
    "\n",
    "        # for each of the 31 modules, train each model\n",
    "        for i, id in enumerate(sample_ids):\n",
    "            df_train_X = df_kyc_train.loc[id].drop(columns=['label'])\n",
    "            df_train_y = df_kyc_train.loc[id]['label']\n",
    "            self.model[i] = self.model[i].fit(df_train_X,df_train_y)\n",
    "\n",
    "        return self.model\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        predictions = []\n",
    "\n",
    "        # for each model, predict, and then take the majority\n",
    "        preds = [self.model[i].predict(X) for i in range(len(self.model))]\n",
    "        # stack arrays\n",
    "        preds = np.vstack(preds)\n",
    "\n",
    "        for i in range(preds.shape[1]):\n",
    "            predictions.append(st.mode(preds[:,i])[0])\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRandomForestClassifier(RandomForestClassifier):\n",
    "    def __init__(self, number_of_models, n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, \n",
    "                 min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', \n",
    "                 max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, \n",
    "                 n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, \n",
    "                 ccp_alpha=0.0, max_samples=None):\n",
    "        super().__init__(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, \n",
    "                         min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, \n",
    "                         min_weight_fraction_leaf=min_weight_fraction_leaf, max_features=max_features, \n",
    "                         max_leaf_nodes=max_leaf_nodes, min_impurity_decrease=min_impurity_decrease, \n",
    "                         bootstrap=bootstrap, oob_score=oob_score, n_jobs=n_jobs, random_state=random_state, \n",
    "                         verbose=verbose, warm_start=warm_start, class_weight=class_weight, \n",
    "                         ccp_alpha=ccp_alpha, max_samples=max_samples)\n",
    "\n",
    "        self.model = [RandomForestClassifier() for _ in range(number_of_models)]\n",
    "    \n",
    "    def fit(self, cluster_ids, df_kyc_train):\n",
    "\n",
    "        # for each of the 31 modules, train each model\n",
    "        for i, id in enumerate(cluster_ids):\n",
    "            df_train_X = df_kyc_train.loc[id].drop(columns=['label'])\n",
    "            df_train_y = df_kyc_train.loc[id]['label']\n",
    "            self.model[i] = self.model[i].fit(df_train_X,df_train_y)\n",
    "\n",
    "        return self.model\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        predictions = []\n",
    "\n",
    "        # for each model, predict, and then take the majority\n",
    "        preds = [self.model[i].predict(X) for i in range(len(self.model))]\n",
    "        # stack arrays\n",
    "        preds = np.vstack(preds)\n",
    "\n",
    "        for i in range(preds.shape[1]):\n",
    "            predictions.append(st.mode(preds[:,i])[0])\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Random Forest -- Minority Class Sensitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRandomForestClusterClassifier(RandomForestClassifier):\n",
    "    def __init__(self, number_of_models, n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, \n",
    "                 min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', \n",
    "                 max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, \n",
    "                 n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, \n",
    "                 ccp_alpha=0.0, max_samples=None):\n",
    "        super().__init__(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, \n",
    "                         min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, \n",
    "                         min_weight_fraction_leaf=min_weight_fraction_leaf, max_features=max_features, \n",
    "                         max_leaf_nodes=max_leaf_nodes, min_impurity_decrease=min_impurity_decrease, \n",
    "                         bootstrap=bootstrap, oob_score=oob_score, n_jobs=n_jobs, random_state=random_state, \n",
    "                         verbose=verbose, warm_start=warm_start, class_weight=class_weight, \n",
    "                         ccp_alpha=ccp_alpha, max_samples=max_samples)\n",
    "\n",
    "        self.model = [RandomForestClassifier() for _ in range(number_of_models)]\n",
    "    \n",
    "    def fit(self, cluster_ids, df_kyc_train):\n",
    "\n",
    "        # for each of the 31 modules, train each model\n",
    "        for i, id in enumerate(cluster_ids):\n",
    "            df_train_X = df_kyc_train.loc[id].drop(columns=['label'])\n",
    "            df_train_y = df_kyc_train.loc[id]['label']\n",
    "            self.model[i] = self.model[i].fit(df_train_X,df_train_y)\n",
    "\n",
    "        return self.model\n",
    "    \n",
    "    def predict(self, X, threshold=0.5):\n",
    "        \n",
    "        '''\n",
    "        Make classification one models predicts minority class\n",
    "        This ensemble method is instead of voting, and is minority sensitive\n",
    "\n",
    "        '''\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        # for each model, predict, and then take the majority\n",
    "        preds = [self.model[i].predict_proba(X)[:,1] for i in range(len(self.model))] # only take minority class predictions\n",
    "\n",
    "        # stack arrays\n",
    "        preds = np.vstack(preds)\n",
    "\n",
    "        for i in range(preds.shape[1]):\n",
    "            if preds[:,i].any() >= threshold:\n",
    "                value = 1\n",
    "            else:\n",
    "                value = 0\n",
    "            predictions.append(value)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def my_f1_macro_metric(y_true, y_pred):\n",
    "#     from sklearn.metrics import f1_score\n",
    "#     # f1_score = f1_score(y_true, y_pred, average='macro')\n",
    "#     metric = keras.metrics.F1Score(average='macro', threshold=None, \n",
    "#                                    name=\"f1_score\", dtype=None)\n",
    "#     # metric.update_state(y_true, y_pred)\n",
    "    \n",
    "#     # metric.result()\n",
    "#     return  metric.update_state(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyNeuralNetwork(input_shape):   \n",
    "    # Deep stacked MLP with dropout\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Input(shape=input_shape),\n",
    "        # keras.layers.Flatten(input_shape=input_shape),\n",
    "        # keras.layers.Dense(1024, kernel_initializer='normal', activation='relu',\n",
    "        #                    kernel_regularizer= keras.regularizers.L1L2(l1=0.01, l2=0.01)),\n",
    "        # keras.layers.Dense(512, kernel_initializer='normal', activation='relu'),\n",
    "        # keras.layers.Dropout(0.1),\n",
    "        # keras.layers.Dense(256, kernel_initializer='normal', activation='relu',\n",
    "        #                    kernel_regularizer= keras.regularizers.L1L2(l1=0.01, l2=0.01)),\n",
    "        # keras.layers.Dropout(0.1),\n",
    "        # keras.layers.Dense(128,kernel_initializer='normal', activation='relu'),\n",
    "        keras.layers.Dense(64,kernel_initializer='normal', activation='relu'),\n",
    "        keras.layers.Dense(32,kernel_initializer='normal', activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss = keras.losses.BinaryCrossentropy() ,\n",
    "        metrics=[keras.metrics.BinaryAccuracy()],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNeuralNetworkClassifier():\n",
    "    def __init__(self, number_of_models, input_shape):\n",
    "\n",
    "        self.model = [MyNeuralNetwork(input_shape) for _ in range(number_of_models)]\n",
    "    \n",
    "    def fit(self, cluster_ids, df_kyc_train, epochs, batch_size):\n",
    "\n",
    "        # for each of the 31 modules, train each model\n",
    "        for i, id in enumerate(cluster_ids):\n",
    "            df_train_X = df_kyc_train.loc[id].drop(columns=['label'])\n",
    "            df_train_y = df_kyc_train.loc[id]['label']\n",
    "            self.model[i].fit(df_train_X, df_train_y, epochs=epochs, batch_size=batch_size)\n",
    "            \n",
    "    \n",
    "    def predict(self, X, threshold = 0.5):\n",
    "        \n",
    "        predictions = []\n",
    "\n",
    "        # for each model, predict, and then take the majority\n",
    "        preds = [self.model[i].predict(X).T for i in range(len(self.model))]\n",
    "\n",
    "        # binarize predictions\n",
    "        preds = [np.where(preds[i] <= threshold, 0 ,1) for i in range(len(preds))]\n",
    "\n",
    "        # stack arrays\n",
    "        preds = np.vstack(preds)\n",
    "\n",
    "        for i in range(preds.shape[1]):\n",
    "\n",
    "            predictions.append(st.mode(preds[:,i])[0])\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make a variant of the network with early stopping for longer training runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStoppingByLossVal(keras.callbacks.Callback):\n",
    "    def __init__(self, model, X_val, y_val):\n",
    "        super(keras.callbacks.Callback, self).__init__()\n",
    "        # self.monitor = monitor\n",
    "        self.patience = 0\n",
    "        self.best_f1 = 0\n",
    "        self.X = X_val\n",
    "        self.y = y_val\n",
    "        self.model = model\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}): # need to pass epoch & logs because keras expects it\n",
    "        from sklearn.metrics import f1_score\n",
    "        y_pred = (self.model.predict(self.X).ravel()>0.5)+0 # need binary outputs for sklearn f1_score \n",
    "\n",
    "        current_f1 = f1_score(self.y, y_pred, average='macro')\n",
    "        print('Validation Macro F1 Score', current_f1)\n",
    "\n",
    "        if current_f1 > self.best_f1:\n",
    "            # update best f1\n",
    "            self.best_f1 = current_f1\n",
    "            # reset patience\n",
    "            self.patience = 0\n",
    "\n",
    "        if self.patience == 2:\n",
    "            print('Early Stopping')\n",
    "            self.model.stop_training = True\n",
    "        \n",
    "        self.patience+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNeuralNetworkClassifierEarlyStopping():\n",
    "    def __init__(self, number_of_models, input_shape):\n",
    "\n",
    "        self.model = [MyNeuralNetwork(input_shape) for _ in range(number_of_models)]\n",
    "    \n",
    "    def fit(self, cluster_ids, df_kyc_train, epochs, batch_size):\n",
    "\n",
    "        # for each of the 31 modules, train each model\n",
    "        for i, id in enumerate(cluster_ids):\n",
    "            # Split Val-&-Train. Id's are already shuffled\n",
    "            train_ids = id[:int(len(id)*0.85)]\n",
    "            val_ids = id[int(len(id)*0.85):]\n",
    "            df_train_X = df_kyc_train.loc[train_ids].drop(columns=['label'])\n",
    "            df_train_y = df_kyc_train.loc[train_ids]['label']\n",
    "            df_val_X = df_kyc_train.loc[val_ids].drop(columns=['label'])\n",
    "            df_val_y = df_kyc_train.loc[val_ids]['label']\n",
    "\n",
    "            callbacks = [EarlyStoppingByLossVal(self.model[i], df_val_X, df_val_y)]\n",
    "\n",
    "            self.model[i].fit(df_train_X, df_train_y, epochs=epochs, \n",
    "                              batch_size=batch_size, \n",
    "                              validation_data= (df_val_X, df_val_y),\n",
    "                              callbacks=callbacks)\n",
    "            \n",
    "    \n",
    "    def predict(self, X, threshold = 0.5):\n",
    "        \n",
    "        predictions = []\n",
    "        \n",
    "        # switch to eval mode\n",
    "\n",
    "        # for each model, predict, and then take the majority\n",
    "        preds = [self.model[i].predict(X).T for i in range(len(self.model))]\n",
    "\n",
    "        # binarize predictions\n",
    "        preds = [np.where(preds[i] <= threshold, 0 ,1) for i in range(len(preds))]\n",
    "\n",
    "        # stack arrays\n",
    "        preds = np.vstack(preds)\n",
    "\n",
    "        for i in range(preds.shape[1]):\n",
    "\n",
    "            predictions.append(st.mode(preds[:,i])[0])\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster-Based Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority class is ~34x larger than minority class. We can divide the majority class into 34 distinct agglomerative clusters, using k-means clustering. We can then pair each cluster with the entire minority class dataset and train 34 random forest classifiers, ensembling them in a  multi-voting scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     19027\n",
      "           1       0.03      1.00      0.05       552\n",
      "\n",
      "    accuracy                           0.03     19579\n",
      "   macro avg       0.01      0.50      0.03     19579\n",
      "weighted avg       0.00      0.03      0.00     19579\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Define KMeans Algorithm\n",
    "# Fit algorithm on majority class\n",
    "kmeans = KMeans(n_clusters=34, random_state=0, n_init=\"auto\", max_iter=50).fit(df_train_non_target_sc)\n",
    "\n",
    "# For each cluster, concatenate with minority class\n",
    "\n",
    "cluster_ids = []\n",
    "for c in range(34):\n",
    "    # Get Majority training dataset\n",
    "    cluster_index = np.where(kmeans.labels_ == c)\n",
    "    df_majority_cluster = df_train_non_target_sc.iloc[cluster_index]\n",
    "\n",
    "    # Concatenate with minority dataset\n",
    "    df_cluster_train = pd.concat([df_majority_cluster, df_train_target_sc])\n",
    "\n",
    "    # Shuffle dataset\n",
    "    df_cluster_train = df_cluster_train.sample(frac=1)\n",
    "\n",
    "    # Store Ids\n",
    "    cluster_ids.append(df_cluster_train.index)\n",
    "\n",
    "\n",
    "# Train Custom Random Forest Model\n",
    "resampling_model = MyRandomForestClassifier(34)\n",
    "\n",
    "# Train Model\n",
    "resampling_model.fit(cluster_ids, df_train_sc)\n",
    "\n",
    "# predict\n",
    "df_kyc_val_X = df_val_sc.drop(columns=['label'])\n",
    "df_kyc_val_y = df_val_sc['label']\n",
    "\n",
    "predictions = resampling_model.predict(df_kyc_val_X)\n",
    "\n",
    "# print report\n",
    "print(classification_report(df_kyc_val_y,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling Investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate Number of Resampled Models to Use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedure:\n",
    "\n",
    "Perform 123719 -choose-3543  n number of times, until the resampling error (sampling error formula) is reduced on Age and Tenure. This will give you 'n' models to train. This will ensure that the n resamplings accurately covers the 123719  non-target population statistics (on two dimensions, age and tenure)\n",
    "\n",
    "For each model, give one random sample of 3543  from the non-target population, and the entire 3543  target population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_iterations = 34\n",
    "sample_size = 3543 \n",
    "total_sample_size = sample_size\n",
    "sample_errors_age = []\n",
    "sample_errors_tenure = []\n",
    "sample_ids = []\n",
    "\n",
    "\n",
    "# calculate Z-score on Age and Tenure (95 percentile)\n",
    "# Z-score = (X - mu)/sigma\n",
    "Z_age = (df_train_non_target.Age.quantile(0.95) - df_train_non_target.Age.mean())/df_train_non_target.Age.std()\n",
    "Z_tenure = (df_train_non_target.Tenure.quantile(0.95) - df_train_non_target.Tenure.mean())/df_train_non_target.Tenure.std()\n",
    "\n",
    "\n",
    "for _ in range(number_of_iterations):\n",
    "    # get a random sample of non-target indexes\n",
    "    sample = np.random.choice(len(df_train_non_target), sample_size, replace=False).tolist()\n",
    "    sample_ids.append(sample)\n",
    "    # update total sample size\n",
    "    total_sample_size+=sample_size\n",
    "\n",
    "    # calculate sample error\n",
    "    # SE = Z * sigma/sqrt(sample_size)\n",
    "    SE_age =  Z_age * df_train_non_target.Age.std() / np.sqrt(total_sample_size)\n",
    "    SE_tenure =  Z_tenure * df_train_non_target.Tenure.std() / np.sqrt(total_sample_size)\n",
    "\n",
    "    # store results\n",
    "    sample_errors_age.append(SE_age)\n",
    "    sample_errors_tenure.append(SE_tenure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2,1, figsize=(10,5))\n",
    "\n",
    "axs[0].plot(range(len(sample_errors_age)), sample_errors_age, label = 'Age sampling error')\n",
    "axs[1].plot(range(len(sample_errors_tenure)), sample_errors_tenure, label = 'Tenure sampling error')\n",
    "axs[0].legend()\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use 31 independent models. We have the samples ids stored. Use these sample ids to get the non-target data, and join with entire target data. <br>\n",
    "This will create 31 datasets of 3542 non-target and target records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update sample ids\n",
    "sample_ids = sample_ids[:-3]\n",
    "\n",
    "# for each 31 non-target sample, add the target indexes\n",
    "for i in range(len(sample_ids)):\n",
    "    sample_ids[i].extend(df_train_target.index.to_list())\n",
    "    # shuffle the data\n",
    "    np.random.shuffle(sample_ids[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Up-and-Downsampling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the benchmark case, upsampling seems to perform better than downsampling. <br>\n",
    "\n",
    "Usample the minority class by a random amount (no greater than majority class) for a number k iterations. <br>\n",
    "Then randomly downsample the majority class to the same size.\n",
    "\n",
    "Batch these datasets together and use to train k models. Ensemble models and use multi-voting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Random Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of models\n",
    "number_of_iterations = number_of_models = 31\n",
    "\n",
    "# sample ids list\n",
    "sample_ids = []\n",
    "\n",
    "# size of class imbalance\n",
    "class_imb = len(df_train_non_target_sc) - len(df_train_target_sc)\n",
    "\n",
    "# get resampled data\n",
    "for i in range(number_of_iterations):\n",
    "\n",
    "    # random choice for upsampling (not larger than majority class)\n",
    "    up_rnd = np.random.choice(class_imb, 1)[0]\n",
    "\n",
    "    # update minority size\n",
    "    minority_size = len(df_train_target) + up_rnd\n",
    "\n",
    "    # upsample minority class\n",
    "    df_kyc_minority_upsampled = resample(df_train_target_sc, \n",
    "                                    replace=True,     \n",
    "                                    n_samples=minority_size)\n",
    "\n",
    "    # downsample majority class\n",
    "    df_kyc_majority_downsampled = resample(df_train_non_target_sc, \n",
    "                                    replace=True,     \n",
    "                                    n_samples=minority_size)\n",
    "    # join dataframes\n",
    "    df_kyc_up_down = pd.concat([df_kyc_minority_upsampled,df_kyc_majority_downsampled])\n",
    "    \n",
    "    # shuffle dataframe\n",
    "    df_kyc_up_down = df_kyc_up_down.sample(frac=1)\n",
    "\n",
    "    # store index\n",
    "    sample_ids.append(df_kyc_up_down.index)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimintation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed: 35.6min remaining: 23.7min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 36.2min finished\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m results_f1, names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(), \u001b[38;5;28mlist\u001b[39m()\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 31\u001b[0m     scores_f1, features \u001b[38;5;241m=\u001b[39m evaluate_model_f1(model, X,y)\n\u001b[0;32m     32\u001b[0m     results_f1\u001b[38;5;241m.\u001b[39mappend(scores_f1)\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(scores_f1)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import cross_val_score, RepeatedKFold\n",
    "# from sklearn.feature_selection import RFE\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "# # define dataset\n",
    "# df = pd.concat([df_train_sc,df_val_sc])\n",
    "\n",
    "# # partition\n",
    "# X = df.drop(columns=['label'])\n",
    "# y = df['label']\n",
    "\n",
    "# def get_models():\n",
    "#     models = dict()\n",
    "#     for i in range(20,50):\n",
    "#         rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select = i)\n",
    "#         model = DecisionTreeClassifier()\n",
    "#         models[str(i)] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "#         return models\n",
    "\n",
    "# def evaluate_model_f1(model, X,y):\n",
    "#     cv = RepeatedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
    "#     scores = cross_val_score(model, X, y, scoring = 'f1_macro', cv=cv, n_jobs=-1, error_score = 'raise', verbose = 2)\n",
    "\n",
    "#     return scores, features\n",
    "\n",
    "# # evaluate\n",
    "\n",
    "# models = get_models()\n",
    "# results_f1, names = list(), list()\n",
    "# for name, model in models.items():\n",
    "#     scores_f1, features = evaluate_model_f1(model, X,y)\n",
    "#     results_f1.append(scores_f1)\n",
    "#     print(f'>{name}, {np.mean(scores_f1)}')\n",
    "#     print('Features Selected:', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m selector \u001b[38;5;241m=\u001b[39m RFE(estimator, n_features_to_select\u001b[38;5;241m=\u001b[39mi, step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# selector = selector.fit(X, y)\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m features \u001b[38;5;241m=\u001b[39m selector\u001b[38;5;241m.\u001b[39mget_feature_names_out()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMacro F1:\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean(scores))\n",
      "File \u001b[1;32mc:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    560\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 562\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 309\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from sklearn.feature_selection import RFE\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# # define dataset\n",
    "# df = pd.concat([df_train_sc,df_val_sc])\n",
    "\n",
    "# # partition\n",
    "# X = df.drop(columns=['label'])\n",
    "# y = df['label']\n",
    "\n",
    "# # model\n",
    "# estimator = DecisionTreeClassifier()\n",
    "\n",
    "# # RFE loop\n",
    "# for i in range(20,50):\n",
    "#     selector = RFE(estimator, n_features_to_select=i, step=1)\n",
    "#     # selector = selector.fit(X, y)\n",
    "#     scores = cross_val_score(estimator=selector, X=X, y=y, cv=5, n_jobs=4)\n",
    "#     features = selector.get_feature_names_out()\n",
    "\n",
    "#     print('Macro F1:', np.mean(scores))\n",
    "#     print('Features:',features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train & Evaluate Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\stefa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96     19027\n",
      "           1       0.24      0.87      0.37       552\n",
      "\n",
      "    accuracy                           0.92     19579\n",
      "   macro avg       0.62      0.90      0.66     19579\n",
      "weighted avg       0.97      0.92      0.94     19579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Model\n",
    "resampling_model = MyLogistic(len(sample_ids))\n",
    "\n",
    "# Train Model\n",
    "resampling_model.fit(sample_ids, df_train_sc)\n",
    "\n",
    "# predict\n",
    "df_kyc_val_X = df_val_sc.drop(columns=['label'])\n",
    "df_kyc_val_y = df_val_sc['label']\n",
    "\n",
    "predictions = resampling_model.predict(df_kyc_val_X)\n",
    "\n",
    "# print report\n",
    "print(classification_report(df_kyc_val_y,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train & Evaluate Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99     19027\n",
      "           1       0.53      0.64      0.58       552\n",
      "\n",
      "    accuracy                           0.97     19579\n",
      "   macro avg       0.76      0.81      0.78     19579\n",
      "weighted avg       0.98      0.97      0.98     19579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Model\n",
    "resampling_model = MyRandomForestClassifier(31)\n",
    "\n",
    "# Train Model\n",
    "resampling_model.fit(sample_ids, df_train_sc)\n",
    "\n",
    "# predict\n",
    "df_kyc_val_X = df_val_sc.drop(columns=['label'])\n",
    "df_kyc_val_y = df_val_sc['label']\n",
    "\n",
    "predictions = resampling_model.predict(df_kyc_val_X)\n",
    "\n",
    "# print report\n",
    "print(classification_report(df_kyc_val_y,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Up-and-Downsampling with Neural Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Permutation Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 263 features, not all of them are likely important, many may also be colinear. \n",
    "\n",
    "We can use feature permutation importance to determine which features are the best predictors.\n",
    "\n",
    "For every feature in the feature space, randomly permute it, so that it is loses its correspondence with the target and measure the decrease in performance. Permuted features with that cause the highest decrease in performance are more important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Permutation Importance with three-layer neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....Calcualting Base f1 Score.....\n",
      "4589/4589 [==============================] - 6s 1ms/step - loss: 0.0697 - binary_accuracy: 0.9773\n",
      "612/612 [==============================] - 1s 749us/step\n",
      "base f1 score: 0.5814185814185815\n",
      ".....Starting Permuation Importance.....\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0584 - binary_accuracy: 0.9792\n",
      "612/612 [==============================] - 1s 861us/step\n",
      "Feature: Gender\n",
      "Permuted f1 score: 0.5846153846153846\n",
      "performance decrease: -0.003196803196803155\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0559 - binary_accuracy: 0.9801\n",
      "612/612 [==============================] - 0s 755us/step\n",
      "Feature: Age\n",
      "Permuted f1 score: 0.58098223615465\n",
      "performance decrease: 0.00043634526393154793\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0546 - binary_accuracy: 0.9805\n",
      "612/612 [==============================] - 1s 938us/step\n",
      "Feature: Tenure\n",
      "Permuted f1 score: 0.5675392670157068\n",
      "performance decrease: 0.01387931440287471\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0535 - binary_accuracy: 0.9810\n",
      "612/612 [==============================] - 0s 764us/step\n",
      "Feature: Occ_Actor\n",
      "Permuted f1 score: 0.5803108808290155\n",
      "performance decrease: 0.0011077005895659964\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0525 - binary_accuracy: 0.9813\n",
      "612/612 [==============================] - 0s 758us/step\n",
      "Feature: Occ_Actuary\n",
      "Permuted f1 score: 0.5803757828810021\n",
      "performance decrease: 0.0010427985375793813\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0516 - binary_accuracy: 0.9816\n",
      "612/612 [==============================] - 0s 775us/step\n",
      "Feature: Occ_Anesthesiologist\n",
      "Permuted f1 score: 0.5642633228840125\n",
      "performance decrease: 0.017155258534569007\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0507 - binary_accuracy: 0.9819\n",
      "612/612 [==============================] - 1s 873us/step\n",
      "Feature: Occ_Animal Trainer\n",
      "Permuted f1 score: 0.5634095634095635\n",
      "performance decrease: 0.018009018009017996\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0499 - binary_accuracy: 0.9822\n",
      "612/612 [==============================] - 0s 736us/step\n",
      "Feature: Occ_Antique Dealer\n",
      "Permuted f1 score: 0.5628245067497404\n",
      "performance decrease: 0.01859407466884111\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0490 - binary_accuracy: 0.9825\n",
      "612/612 [==============================] - 0s 750us/step\n",
      "Feature: Occ_Antiques Dealer\n",
      "Permuted f1 score: 0.5559038662486938\n",
      "performance decrease: 0.02551471516988768\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0480 - binary_accuracy: 0.9828\n",
      "612/612 [==============================] - 0s 744us/step\n",
      "Feature: Occ_Arborist\n",
      "Permuted f1 score: 0.5525773195876289\n",
      "performance decrease: 0.02884126183095259\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0471 - binary_accuracy: 0.9830\n",
      "612/612 [==============================] - 0s 772us/step\n",
      "Feature: Occ_Archaeologist\n",
      "Permuted f1 score: 0.5469728601252609\n",
      "performance decrease: 0.034445721293320575\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0462 - binary_accuracy: 0.9832\n",
      "612/612 [==============================] - 1s 909us/step\n",
      "Feature: Occ_Architect\n",
      "Permuted f1 score: 0.5492227979274612\n",
      "performance decrease: 0.03219578349112029\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0453 - binary_accuracy: 0.9835\n",
      "612/612 [==============================] - 0s 730us/step\n",
      "Feature: Occ_Art Critic\n",
      "Permuted f1 score: 0.5493827160493827\n",
      "performance decrease: 0.03203586536919878\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0444 - binary_accuracy: 0.9837\n",
      "612/612 [==============================] - 0s 751us/step\n",
      "Feature: Occ_Art Dealer\n",
      "Permuted f1 score: 0.5506653019447287\n",
      "performance decrease: 0.030753279473852757\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0437 - binary_accuracy: 0.9841\n",
      "612/612 [==============================] - 0s 750us/step\n",
      "Feature: Occ_Art Gallery Owner\n",
      "Permuted f1 score: 0.5497435897435897\n",
      "performance decrease: 0.03167499167499177\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0429 - binary_accuracy: 0.9842\n",
      "612/612 [==============================] - 0s 738us/step\n",
      "Feature: Occ_Art Historian\n",
      "Permuted f1 score: 0.549792531120332\n",
      "performance decrease: 0.0316260502982495\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0421 - binary_accuracy: 0.9844\n",
      "612/612 [==============================] - 0s 733us/step\n",
      "Feature: Occ_Artist\n",
      "Permuted f1 score: 0.5538461538461539\n",
      "performance decrease: 0.027572427572427616\n",
      "4589/4589 [==============================] - 6s 1ms/step - loss: 0.0414 - binary_accuracy: 0.9847\n",
      "612/612 [==============================] - 1s 775us/step\n",
      "Feature: Occ_Astronomer\n",
      "Permuted f1 score: 0.5504201680672269\n",
      "performance decrease: 0.03099841335135456\n",
      "4589/4589 [==============================] - 6s 1ms/step - loss: 0.0407 - binary_accuracy: 0.9848\n",
      "612/612 [==============================] - 1s 798us/step\n",
      "Feature: Occ_Astrophysicist\n",
      "Permuted f1 score: 0.553014553014553\n",
      "performance decrease: 0.028404028404028447\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0401 - binary_accuracy: 0.9852\n",
      "612/612 [==============================] - 0s 766us/step\n",
      "Feature: Occ_Auctioneer\n",
      "Permuted f1 score: 0.5506653019447287\n",
      "performance decrease: 0.030753279473852757\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0395 - binary_accuracy: 0.9852\n",
      "612/612 [==============================] - 1s 1ms/step\n",
      "Feature: Occ_Author\n",
      "Permuted f1 score: 0.5530612244897959\n",
      "performance decrease: 0.028357356928785604\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0388 - binary_accuracy: 0.9855\n",
      "612/612 [==============================] - 0s 789us/step\n",
      "Feature: Occ_Auto Dealer\n",
      "Permuted f1 score: 0.557948717948718\n",
      "performance decrease: 0.02346986346986346\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0381 - binary_accuracy: 0.9858\n",
      "612/612 [==============================] - 0s 753us/step\n",
      "Feature: Occ_Baker\n",
      "Permuted f1 score: 0.5565749235474006\n",
      "performance decrease: 0.024843657871180924\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0375 - binary_accuracy: 0.9859\n",
      "612/612 [==============================] - 0s 749us/step\n",
      "Feature: Occ_Banker\n",
      "Permuted f1 score: 0.5610766045548654\n",
      "performance decrease: 0.020341976863716082\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0369 - binary_accuracy: 0.9860\n",
      "612/612 [==============================] - 0s 757us/step\n",
      "Feature: Occ_Barista\n",
      "Permuted f1 score: 0.5430051813471503\n",
      "performance decrease: 0.038413400071431236\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0363 - binary_accuracy: 0.9865\n",
      "612/612 [==============================] - 0s 777us/step\n",
      "Feature: Occ_Bartender\n",
      "Permuted f1 score: 0.538860103626943\n",
      "performance decrease: 0.04255847779163846\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0359 - binary_accuracy: 0.9866\n",
      "612/612 [==============================] - 0s 753us/step\n",
      "Feature: Occ_Beekeeper\n",
      "Permuted f1 score: 0.5294117647058824\n",
      "performance decrease: 0.05200681671269913\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0355 - binary_accuracy: 0.9868\n",
      "612/612 [==============================] - 0s 771us/step\n",
      "Feature: Occ_Bioengineer\n",
      "Permuted f1 score: 0.5192307692307692\n",
      "performance decrease: 0.06218781218781233\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0351 - binary_accuracy: 0.9868\n",
      "612/612 [==============================] - 0s 761us/step\n",
      "Feature: Occ_Biologist\n",
      "Permuted f1 score: 0.5259809119830329\n",
      "performance decrease: 0.05543766943554862\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0345 - binary_accuracy: 0.9871\n",
      "612/612 [==============================] - 0s 735us/step\n",
      "Feature: Occ_Book Editor\n",
      "Permuted f1 score: 0.5334750265674814\n",
      "performance decrease: 0.047943554851100134\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0343 - binary_accuracy: 0.9873\n",
      "612/612 [==============================] - 0s 747us/step\n",
      "Feature: Occ_Brewer\n",
      "Permuted f1 score: 0.5354497354497354\n",
      "performance decrease: 0.045968845968846095\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0340 - binary_accuracy: 0.9873\n",
      "612/612 [==============================] - 0s 773us/step\n",
      "Feature: Occ_Bus Driver\n",
      "Permuted f1 score: 0.524896265560166\n",
      "performance decrease: 0.056522315858415495\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0335 - binary_accuracy: 0.9878\n",
      "612/612 [==============================] - 0s 749us/step\n",
      "Feature: Occ_Business Owner\n",
      "Permuted f1 score: 0.5254237288135593\n",
      "performance decrease: 0.05599485260502224\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0333 - binary_accuracy: 0.9878\n",
      "612/612 [==============================] - 0s 749us/step\n",
      "Feature: Occ_Butcher\n",
      "Permuted f1 score: 0.5304437564499485\n",
      "performance decrease: 0.05097482496863304\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0329 - binary_accuracy: 0.9879\n",
      "612/612 [==============================] - 0s 782us/step\n",
      "Feature: Occ_Call Center Representative\n",
      "Permuted f1 score: 0.5325203252032521\n",
      "performance decrease: 0.048898256215329394\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0325 - binary_accuracy: 0.9881\n",
      "612/612 [==============================] - 1s 811us/step\n",
      "Feature: Occ_Car Dealership Owner\n",
      "Permuted f1 score: 0.5326530612244899\n",
      "performance decrease: 0.04876552019409164\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0322 - binary_accuracy: 0.9883\n",
      "612/612 [==============================] - 0s 757us/step\n",
      "Feature: Occ_Carpenter\n",
      "Permuted f1 score: 0.5275827482447342\n",
      "performance decrease: 0.053835833173847325\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0318 - binary_accuracy: 0.9882\n",
      "612/612 [==============================] - 0s 753us/step\n",
      "Feature: Occ_Cartographer\n",
      "Permuted f1 score: 0.5357502517623363\n",
      "performance decrease: 0.04566832965624523\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0313 - binary_accuracy: 0.9885\n",
      "612/612 [==============================] - 1s 779us/step\n",
      "Feature: Occ_Cartoonist\n",
      "Permuted f1 score: 0.5249500998003993\n",
      "performance decrease: 0.05646848161818219\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0311 - binary_accuracy: 0.9886\n",
      "612/612 [==============================] - 0s 762us/step\n",
      "Feature: Occ_Cash-intensive Business Owner (e.g., Laundromat)\n",
      "Permuted f1 score: 0.5231388329979879\n",
      "performance decrease: 0.05827974842059358\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0309 - binary_accuracy: 0.9887\n",
      "612/612 [==============================] - 0s 750us/step\n",
      "Feature: Occ_Cashier\n",
      "Permuted f1 score: 0.5301681503461918\n",
      "performance decrease: 0.05125043107238969\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0305 - binary_accuracy: 0.9889\n",
      "612/612 [==============================] - 1s 785us/step\n",
      "Feature: Occ_Casino Operator\n",
      "Permuted f1 score: 0.5342601787487586\n",
      "performance decrease: 0.04715840266982285\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0302 - binary_accuracy: 0.9889\n",
      "612/612 [==============================] - 0s 760us/step\n",
      "Feature: Occ_Ceramicist\n",
      "Permuted f1 score: 0.5281553398058253\n",
      "performance decrease: 0.053263241612756196\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0297 - binary_accuracy: 0.9890\n",
      "612/612 [==============================] - 0s 748us/step\n",
      "Feature: Occ_Chef\n",
      "Permuted f1 score: 0.5239491691104594\n",
      "performance decrease: 0.05746941230812208\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0295 - binary_accuracy: 0.9892\n",
      "612/612 [==============================] - 0s 751us/step\n",
      "Feature: Occ_Chemist\n",
      "Permuted f1 score: 0.5183752417794971\n",
      "performance decrease: 0.06304333963908437\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0293 - binary_accuracy: 0.9892\n",
      "612/612 [==============================] - 1s 954us/step\n",
      "Feature: Occ_Childcare Worker\n",
      "Permuted f1 score: 0.532304725168756\n",
      "performance decrease: 0.04911385624982545\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0290 - binary_accuracy: 0.9891\n",
      "612/612 [==============================] - 0s 763us/step\n",
      "Feature: Occ_Chiropractor\n",
      "Permuted f1 score: 0.5297504798464491\n",
      "performance decrease: 0.05166810157213242\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0287 - binary_accuracy: 0.9893\n",
      "612/612 [==============================] - 0s 749us/step\n",
      "Feature: Occ_Choreographer\n",
      "Permuted f1 score: 0.5268199233716475\n",
      "performance decrease: 0.05459865804693398\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0282 - binary_accuracy: 0.9896\n",
      "612/612 [==============================] - 0s 754us/step\n",
      "Feature: Occ_Cicerone\n",
      "Permuted f1 score: 0.5268199233716475\n",
      "performance decrease: 0.05459865804693398\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0281 - binary_accuracy: 0.9896\n",
      "612/612 [==============================] - 0s 755us/step\n",
      "Feature: Occ_Civil Servant\n",
      "Permuted f1 score: 0.5191570881226053\n",
      "performance decrease: 0.06226149329597619\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0278 - binary_accuracy: 0.9898\n",
      "612/612 [==============================] - 0s 785us/step\n",
      "Feature: Occ_Cleaner\n",
      "Permuted f1 score: 0.519730510105871\n",
      "performance decrease: 0.06168807131271048\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0274 - binary_accuracy: 0.9897\n",
      "612/612 [==============================] - 0s 781us/step\n",
      "Feature: Occ_Coffee Roaster\n",
      "Permuted f1 score: 0.5140096618357488\n",
      "performance decrease: 0.06740891958283268\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0273 - binary_accuracy: 0.9899\n",
      "612/612 [==============================] - 0s 783us/step\n",
      "Feature: Occ_Comic Book Artist\n",
      "Permuted f1 score: 0.5167464114832535\n",
      "performance decrease: 0.06467216993532798\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0272 - binary_accuracy: 0.9899\n",
      "612/612 [==============================] - 0s 769us/step\n",
      "Feature: Occ_Commodity Broker\n",
      "Permuted f1 score: 0.5162523900573613\n",
      "performance decrease: 0.06516619136122015\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0269 - binary_accuracy: 0.9900\n",
      "612/612 [==============================] - 0s 736us/step\n",
      "Feature: Occ_Construction Contractor\n",
      "Permuted f1 score: 0.5132575757575757\n",
      "performance decrease: 0.0681610056610058\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0265 - binary_accuracy: 0.9902\n",
      "612/612 [==============================] - 0s 755us/step\n",
      "Feature: Occ_Construction Worker\n",
      "Permuted f1 score: 0.52\n",
      "performance decrease: 0.061418581418581475\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0263 - binary_accuracy: 0.9903\n",
      "612/612 [==============================] - 0s 767us/step\n",
      "Feature: Occ_Corporate Executive\n",
      "Permuted f1 score: 0.5142314990512333\n",
      "performance decrease: 0.06718708236734816\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0261 - binary_accuracy: 0.9903\n",
      "612/612 [==============================] - 0s 738us/step\n",
      "Feature: Occ_Cryoseismologist\n",
      "Permuted f1 score: 0.5172735760971054\n",
      "performance decrease: 0.06414500532147605\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0257 - binary_accuracy: 0.9905\n",
      "612/612 [==============================] - 1s 944us/step\n",
      "Feature: Occ_Cryptocurrency Trader\n",
      "Permuted f1 score: 0.5145539906103286\n",
      "performance decrease: 0.06686459080825291\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0256 - binary_accuracy: 0.9906\n",
      "612/612 [==============================] - 0s 785us/step\n",
      "Feature: Occ_Curator\n",
      "Permuted f1 score: 0.5125815470643057\n",
      "performance decrease: 0.0688370343542758\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0252 - binary_accuracy: 0.9908\n",
      "612/612 [==============================] - 0s 751us/step\n",
      "Feature: Occ_Currency Exchange Owner\n",
      "Permuted f1 score: 0.5178236397748593\n",
      "performance decrease: 0.06359494164372215\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0250 - binary_accuracy: 0.9908\n",
      "612/612 [==============================] - 1s 907us/step\n",
      "Feature: Occ_DJ\n",
      "Permuted f1 score: 0.5220657276995305\n",
      "performance decrease: 0.05935285371905097\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0249 - binary_accuracy: 0.9909\n",
      "612/612 [==============================] - 0s 736us/step\n",
      "Feature: Occ_Dendrochronologist\n",
      "Permuted f1 score: 0.5229007633587786\n",
      "performance decrease: 0.05851781805980294\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0252 - binary_accuracy: 0.9908\n",
      "612/612 [==============================] - 0s 737us/step\n",
      "Feature: Occ_Dentist\n",
      "Permuted f1 score: 0.5255198487712666\n",
      "performance decrease: 0.05589873264731493\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0244 - binary_accuracy: 0.9910\n",
      "612/612 [==============================] - 0s 768us/step\n",
      "Feature: Occ_Dietician\n",
      "Permuted f1 score: 0.5222929936305732\n",
      "performance decrease: 0.05912558778800825\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0242 - binary_accuracy: 0.9910\n",
      "612/612 [==============================] - 0s 763us/step\n",
      "Feature: Occ_Distiller\n",
      "Permuted f1 score: 0.5307262569832403\n",
      "performance decrease: 0.05069232443534122\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0241 - binary_accuracy: 0.9912\n",
      "612/612 [==============================] - 0s 744us/step\n",
      "Feature: Occ_Doctor\n",
      "Permuted f1 score: 0.5248868778280543\n",
      "performance decrease: 0.05653170359052717\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0238 - binary_accuracy: 0.9916\n",
      "612/612 [==============================] - 1s 922us/step\n",
      "Feature: Occ_Economist\n",
      "Permuted f1 score: 0.529032258064516\n",
      "performance decrease: 0.052386323354065456\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0238 - binary_accuracy: 0.9914\n",
      "612/612 [==============================] - 0s 742us/step\n",
      "Feature: Occ_Egyptologist\n",
      "Permuted f1 score: 0.5228519195612431\n",
      "performance decrease: 0.05856666185733839\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0234 - binary_accuracy: 0.9915\n",
      "612/612 [==============================] - 1s 804us/step\n",
      "Feature: Occ_Electrician\n",
      "Permuted f1 score: 0.5241635687732342\n",
      "performance decrease: 0.05725501264534727\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0235 - binary_accuracy: 0.9913\n",
      "612/612 [==============================] - 0s 759us/step\n",
      "Feature: Occ_Engineer\n",
      "Permuted f1 score: 0.5265116279069768\n",
      "performance decrease: 0.054906953511604684\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0233 - binary_accuracy: 0.9914\n",
      "612/612 [==============================] - 0s 744us/step\n",
      "Feature: Occ_Enologist\n",
      "Permuted f1 score: 0.5267034990791896\n",
      "performance decrease: 0.05471508233939193\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0232 - binary_accuracy: 0.9915\n",
      "612/612 [==============================] - 0s 756us/step\n",
      "Feature: Occ_Entomologist\n",
      "Permuted f1 score: 0.5247079964061095\n",
      "performance decrease: 0.05671058501247195\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0230 - binary_accuracy: 0.9914\n",
      "612/612 [==============================] - 0s 766us/step\n",
      "Feature: Occ_Environmental Scientist\n",
      "Permuted f1 score: 0.5263157894736843\n",
      "performance decrease: 0.0551027919448972\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0229 - binary_accuracy: 0.9918\n",
      "612/612 [==============================] - 0s 750us/step\n",
      "Feature: Occ_Ethnobotanist\n",
      "Permuted f1 score: 0.5289256198347108\n",
      "performance decrease: 0.052492961583870734\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0228 - binary_accuracy: 0.9916\n",
      "612/612 [==============================] - 0s 761us/step\n",
      "Feature: Occ_Ethnomusicologist\n",
      "Permuted f1 score: 0.5242009132420091\n",
      "performance decrease: 0.05721766817657237\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0222 - binary_accuracy: 0.9920\n",
      "612/612 [==============================] - 0s 765us/step\n",
      "Feature: Occ_Event Planner\n",
      "Permuted f1 score: 0.5229936880072137\n",
      "performance decrease: 0.058424893411367806\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0222 - binary_accuracy: 0.9919\n",
      "612/612 [==============================] - 0s 769us/step\n",
      "Feature: Occ_Factory Worker\n",
      "Permuted f1 score: 0.5183887915936952\n",
      "performance decrease: 0.06302978982488627\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0219 - binary_accuracy: 0.9920\n",
      "612/612 [==============================] - 0s 762us/step\n",
      "Feature: Occ_Farm Laborer\n",
      "Permuted f1 score: 0.5184518451845186\n",
      "performance decrease: 0.0629667362340629\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0217 - binary_accuracy: 0.9921\n",
      "612/612 [==============================] - 1s 1ms/step\n",
      "Feature: Occ_Farmer\n",
      "Permuted f1 score: 0.5177935943060499\n",
      "performance decrease: 0.06362498711253162\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0219 - binary_accuracy: 0.9920\n",
      "612/612 [==============================] - 0s 750us/step\n",
      "Feature: Occ_Fashion Designer\n",
      "Permuted f1 score: 0.5233812949640289\n",
      "performance decrease: 0.05803728645455264\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0219 - binary_accuracy: 0.9920\n",
      "612/612 [==============================] - 0s 758us/step\n",
      "Feature: Occ_Fast Food Worker\n",
      "Permuted f1 score: 0.523465703971119\n",
      "performance decrease: 0.05795287744746247\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0218 - binary_accuracy: 0.9919\n",
      "612/612 [==============================] - 0s 761us/step\n",
      "Feature: Occ_Film Editor\n",
      "Permuted f1 score: 0.5189873417721519\n",
      "performance decrease: 0.062431239646429604\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0213 - binary_accuracy: 0.9920\n",
      "612/612 [==============================] - 0s 755us/step\n",
      "Feature: Occ_Filmmaker\n",
      "Permuted f1 score: 0.516591928251121\n",
      "performance decrease: 0.0648266531674605\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0211 - binary_accuracy: 0.9923\n",
      "612/612 [==============================] - 0s 754us/step\n",
      "Feature: Occ_Financial Advisor\n",
      "Permuted f1 score: 0.5217391304347826\n",
      "performance decrease: 0.0596794509837989\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0209 - binary_accuracy: 0.9924\n",
      "612/612 [==============================] - 0s 758us/step\n",
      "Feature: Occ_Firefighter\n",
      "Permuted f1 score: 0.5108303249097473\n",
      "performance decrease: 0.07058825650883416\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0211 - binary_accuracy: 0.9924\n",
      "612/612 [==============================] - 1s 955us/step\n",
      "Feature: Occ_Fisherman\n",
      "Permuted f1 score: 0.5099818511796733\n",
      "performance decrease: 0.07143673023890817\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0207 - binary_accuracy: 0.9925\n",
      "612/612 [==============================] - 0s 751us/step\n",
      "Feature: Occ_Fitness Trainer\n",
      "Permuted f1 score: 0.5195035460992907\n",
      "performance decrease: 0.06191503531929077\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0209 - binary_accuracy: 0.9924\n",
      "612/612 [==============================] - 0s 750us/step\n",
      "Feature: Occ_Flight Attendant\n",
      "Permuted f1 score: 0.5187835420393561\n",
      "performance decrease: 0.06263503937922543\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0206 - binary_accuracy: 0.9925\n",
      "612/612 [==============================] - 0s 727us/step\n",
      "Feature: Occ_Florist\n",
      "Permuted f1 score: 0.5120859444941809\n",
      "performance decrease: 0.06933263692440061\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0205 - binary_accuracy: 0.9925\n",
      "612/612 [==============================] - 0s 752us/step\n",
      "Feature: Occ_Food Critic\n",
      "Permuted f1 score: 0.5114235500878734\n",
      "performance decrease: 0.06999503133070806\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0202 - binary_accuracy: 0.9925\n",
      "612/612 [==============================] - 1s 909us/step\n",
      "Feature: Occ_Food Scientist\n",
      "Permuted f1 score: 0.5116681071737251\n",
      "performance decrease: 0.06975047424485636\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0202 - binary_accuracy: 0.9925\n",
      "612/612 [==============================] - 0s 749us/step\n",
      "Feature: Occ_Forester\n",
      "Permuted f1 score: 0.5100087032201915\n",
      "performance decrease: 0.07140987819838995\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0199 - binary_accuracy: 0.9928\n",
      "612/612 [==============================] - 0s 747us/step\n",
      "Feature: Occ_Free Trade Zone Operator\n",
      "Permuted f1 score: 0.5152603231597845\n",
      "performance decrease: 0.06615825825879695\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0200 - binary_accuracy: 0.9927\n",
      "612/612 [==============================] - 0s 776us/step\n",
      "Feature: Occ_Freelancer (e.g., Graphic Designer, Writer)\n",
      "Permuted f1 score: 0.5164737310774711\n",
      "performance decrease: 0.06494485034111042\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0199 - binary_accuracy: 0.9928\n",
      "612/612 [==============================] - 0s 750us/step\n",
      "Feature: Occ_Game Developer\n",
      "Permuted f1 score: 0.5149592021758839\n",
      "performance decrease: 0.06645937924269762\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0195 - binary_accuracy: 0.9929\n",
      "612/612 [==============================] - 0s 758us/step\n",
      "Feature: Occ_Gardener\n",
      "Permuted f1 score: 0.5110132158590308\n",
      "performance decrease: 0.07040536555955068\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0197 - binary_accuracy: 0.9927\n",
      "612/612 [==============================] - 0s 758us/step\n",
      "Feature: Occ_Gemologist\n",
      "Permuted f1 score: 0.5093499554764025\n",
      "performance decrease: 0.072068625942179\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0195 - binary_accuracy: 0.9929\n",
      "612/612 [==============================] - 0s 772us/step\n",
      "Feature: Occ_Geologist\n",
      "Permuted f1 score: 0.5138269402319358\n",
      "performance decrease: 0.06759164118664573\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0196 - binary_accuracy: 0.9927\n",
      "612/612 [==============================] - 0s 756us/step\n",
      "Feature: Occ_Glaciologist\n",
      "Permuted f1 score: 0.5057471264367815\n",
      "performance decrease: 0.07567145498179995\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0194 - binary_accuracy: 0.9929\n",
      "612/612 [==============================] - 0s 750us/step\n",
      "Feature: Occ_Graphic Artist\n",
      "Permuted f1 score: 0.5159010600706714\n",
      "performance decrease: 0.06551752134791011\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0191 - binary_accuracy: 0.9929\n",
      "612/612 [==============================] - 0s 733us/step\n",
      "Feature: Occ_Graphologist\n",
      "Permuted f1 score: 0.5196428571428573\n",
      "performance decrease: 0.0617757242757242\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0189 - binary_accuracy: 0.9932\n",
      "612/612 [==============================] - 0s 760us/step\n",
      "Feature: Occ_Grocery Store Clerk\n",
      "Permuted f1 score: 0.5152603231597845\n",
      "performance decrease: 0.06615825825879695\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0195 - binary_accuracy: 0.9929\n",
      "612/612 [==============================] - 0s 761us/step\n",
      "Feature: Occ_Hairstylist\n",
      "Permuted f1 score: 0.5186500888099468\n",
      "performance decrease: 0.06276849260863471\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0190 - binary_accuracy: 0.9932\n",
      "612/612 [==============================] - 0s 763us/step\n",
      "Feature: Occ_Hedge Fund Manager\n",
      "Permuted f1 score: 0.5121731289449954\n",
      "performance decrease: 0.06924545247358604\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0188 - binary_accuracy: 0.9932\n",
      "612/612 [==============================] - 0s 757us/step\n",
      "Feature: Occ_Herpetologist\n",
      "Permuted f1 score: 0.5167118337850045\n",
      "performance decrease: 0.06470674763357698\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0191 - binary_accuracy: 0.9930\n",
      "612/612 [==============================] - 0s 756us/step\n",
      "Feature: Occ_High-End Real Estate Developer\n",
      "Permuted f1 score: 0.5156669650850492\n",
      "performance decrease: 0.06575161633353233\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0189 - binary_accuracy: 0.9932\n",
      "612/612 [==============================] - 0s 784us/step\n",
      "Feature: Occ_Historian\n",
      "Permuted f1 score: 0.5159010600706714\n",
      "performance decrease: 0.06551752134791011\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0184 - binary_accuracy: 0.9933\n",
      "612/612 [==============================] - 0s 750us/step\n",
      "Feature: Occ_Home Health Aide\n",
      "Permuted f1 score: 0.5071174377224199\n",
      "performance decrease: 0.07430114369616159\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0190 - binary_accuracy: 0.9931\n",
      "612/612 [==============================] - 0s 750us/step\n",
      "Feature: Occ_Hotelier\n",
      "Permuted f1 score: 0.5089605734767024\n",
      "performance decrease: 0.07245800794187907\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0185 - binary_accuracy: 0.9933\n",
      "612/612 [==============================] - 0s 760us/step\n",
      "Feature: Occ_Hydrologist\n",
      "Permuted f1 score: 0.5175202156334233\n",
      "performance decrease: 0.06389836578515817\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0183 - binary_accuracy: 0.9934\n",
      "612/612 [==============================] - 0s 749us/step\n",
      "Feature: Occ_Ichthyologist\n",
      "Permuted f1 score: 0.5216606498194946\n",
      "performance decrease: 0.05975793159908693\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0179 - binary_accuracy: 0.9936\n",
      "612/612 [==============================] - 1s 924us/step\n",
      "Feature: Occ_Illustrator\n",
      "Permuted f1 score: 0.5182546749777382\n",
      "performance decrease: 0.06316390644084324\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0177 - binary_accuracy: 0.9935\n",
      "612/612 [==============================] - 0s 742us/step\n",
      "Feature: Occ_Import/Export Business Owner\n",
      "Permuted f1 score: 0.5119152691968225\n",
      "performance decrease: 0.06950331222175898\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0182 - binary_accuracy: 0.9934\n",
      "612/612 [==============================] - 0s 776us/step\n",
      "Feature: Occ_Import/Export Dealer\n",
      "Permuted f1 score: 0.5084745762711865\n",
      "performance decrease: 0.07294400514739496\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0180 - binary_accuracy: 0.9934\n",
      "612/612 [==============================] - 0s 764us/step\n",
      "Feature: Occ_Interior Designer\n",
      "Permuted f1 score: 0.5013286093888397\n",
      "performance decrease: 0.08008997202974177\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0175 - binary_accuracy: 0.9935\n",
      "612/612 [==============================] - 0s 750us/step\n",
      "Feature: Occ_International Consultant\n",
      "Permuted f1 score: 0.5125899280575539\n",
      "performance decrease: 0.06882865336102761\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0177 - binary_accuracy: 0.9936\n",
      "612/612 [==============================] - 0s 750us/step\n",
      "Feature: Occ_International Salesperson\n",
      "Permuted f1 score: 0.5105633802816901\n",
      "performance decrease: 0.07085520113689137\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0175 - binary_accuracy: 0.9935\n",
      "612/612 [==============================] - 0s 749us/step\n",
      "Feature: Occ_Jewelry Dealer\n",
      "Permuted f1 score: 0.5178571428571429\n",
      "performance decrease: 0.06356143856143859\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0172 - binary_accuracy: 0.9936\n",
      "612/612 [==============================] - 0s 739us/step\n",
      "Feature: Occ_Journalist\n",
      "Permuted f1 score: 0.502994011976048\n",
      "performance decrease: 0.07842456944253351\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0174 - binary_accuracy: 0.9937\n",
      "612/612 [==============================] - 1s 829us/step\n",
      "Feature: Occ_Kinesiologist\n",
      "Permuted f1 score: 0.5128205128205129\n",
      "performance decrease: 0.0685980685980686\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0175 - binary_accuracy: 0.9936\n",
      "612/612 [==============================] - 0s 742us/step\n",
      "Feature: Occ_Landlord\n",
      "Permuted f1 score: 0.5092511013215859\n",
      "performance decrease: 0.07216748009699558\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0167 - binary_accuracy: 0.9940\n",
      "612/612 [==============================] - 0s 784us/step\n",
      "Feature: Occ_Landscaper\n",
      "Permuted f1 score: 0.5036231884057971\n",
      "performance decrease: 0.07779539301278438\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0174 - binary_accuracy: 0.9935\n",
      "612/612 [==============================] - 0s 748us/step\n",
      "Feature: Occ_Lawyer\n",
      "Permuted f1 score: 0.5075960679177838\n",
      "performance decrease: 0.07382251350079772\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0169 - binary_accuracy: 0.9939\n",
      "612/612 [==============================] - 0s 749us/step\n",
      "Feature: Occ_Lepidopterist\n",
      "Permuted f1 score: 0.512\n",
      "performance decrease: 0.06941858141858148\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0167 - binary_accuracy: 0.9938\n",
      "612/612 [==============================] - 1s 921us/step\n",
      "Feature: Occ_Librarian\n",
      "Permuted f1 score: 0.5062611806797853\n",
      "performance decrease: 0.07515740073879618\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0173 - binary_accuracy: 0.9938\n",
      "612/612 [==============================] - 1s 932us/step\n",
      "Feature: Occ_Librarian Assistant\n",
      "Permuted f1 score: 0.5104450499545866\n",
      "performance decrease: 0.07097353146399488\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0167 - binary_accuracy: 0.9939\n",
      "612/612 [==============================] - 1s 918us/step\n",
      "Feature: Occ_Librettist\n",
      "Permuted f1 score: 0.5081374321880651\n",
      "performance decrease: 0.07328114923051643\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0168 - binary_accuracy: 0.9938\n",
      "612/612 [==============================] - 0s 752us/step\n",
      "Feature: Occ_Lifeguard\n",
      "Permuted f1 score: 0.5207956600361664\n",
      "performance decrease: 0.060622921382415096\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0164 - binary_accuracy: 0.9940\n",
      "612/612 [==============================] - 0s 744us/step\n",
      "Feature: Occ_Limnologist\n",
      "Permuted f1 score: 0.5220458553791887\n",
      "performance decrease: 0.05937272603939281\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0164 - binary_accuracy: 0.9941\n",
      "612/612 [==============================] - 0s 764us/step\n",
      "Feature: Occ_Linguist\n",
      "Permuted f1 score: 0.5209790209790209\n",
      "performance decrease: 0.06043956043956056\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0159 - binary_accuracy: 0.9943\n",
      "612/612 [==============================] - 1s 933us/step\n",
      "Feature: Occ_Literary Critic\n",
      "Permuted f1 score: 0.5211267605633804\n",
      "performance decrease: 0.06029182085520113\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0167 - binary_accuracy: 0.9938\n",
      "612/612 [==============================] - 1s 907us/step\n",
      "Feature: Occ_Loan or Finance Company Owner\n",
      "Permuted f1 score: 0.5127753303964757\n",
      "performance decrease: 0.06864325102210578\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0156 - binary_accuracy: 0.9942\n",
      "612/612 [==============================] - 1s 933us/step\n",
      "Feature: Occ_Local Fair Operator\n",
      "Permuted f1 score: 0.5030355594102343\n",
      "performance decrease: 0.07838302200834724\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0165 - binary_accuracy: 0.9939\n",
      "612/612 [==============================] - 1s 902us/step\n",
      "Feature: Occ_Local Radio Operator\n",
      "Permuted f1 score: 0.5176056338028169\n",
      "performance decrease: 0.06381294761576461\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0158 - binary_accuracy: 0.9943\n",
      "612/612 [==============================] - 1s 911us/step\n",
      "Feature: Occ_Luthier\n",
      "Permuted f1 score: 0.5148514851485149\n",
      "performance decrease: 0.06656709627006663\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0162 - binary_accuracy: 0.9941\n",
      "612/612 [==============================] - 1s 916us/step\n",
      "Feature: Occ_Luxury Goods Dealer (e.g., Art, Jewelry)\n",
      "Permuted f1 score: 0.511304347826087\n",
      "performance decrease: 0.07011423359249447\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0161 - binary_accuracy: 0.9943\n",
      "612/612 [==============================] - 0s 748us/step\n",
      "Feature: Occ_Luxury Yacht Broker\n",
      "Permuted f1 score: 0.5133047210300429\n",
      "performance decrease: 0.06811386038853862\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0156 - binary_accuracy: 0.9945\n",
      "612/612 [==============================] - 0s 761us/step\n",
      "Feature: Occ_Makeup Artist\n",
      "Permuted f1 score: 0.5153913808267371\n",
      "performance decrease: 0.06602720059184441\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0157 - binary_accuracy: 0.9943\n",
      "612/612 [==============================] - 0s 736us/step\n",
      "Feature: Occ_Malacologist\n",
      "Permuted f1 score: 0.5121527777777778\n",
      "performance decrease: 0.0692658036408037\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0158 - binary_accuracy: 0.9944\n",
      "612/612 [==============================] - 0s 731us/step\n",
      "Feature: Occ_Marine Biologist\n",
      "Permuted f1 score: 0.5183246073298429\n",
      "performance decrease: 0.06309397408873862\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0155 - binary_accuracy: 0.9944\n",
      "612/612 [==============================] - 0s 761us/step\n",
      "Feature: Occ_Marine Engineer\n",
      "Permuted f1 score: 0.519163763066202\n",
      "performance decrease: 0.06225481835237945\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0156 - binary_accuracy: 0.9943\n",
      "612/612 [==============================] - 0s 739us/step\n",
      "Feature: Occ_Maritime or Shipping Agent\n",
      "Permuted f1 score: 0.5191793041926851\n",
      "performance decrease: 0.062239277225896394\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0157 - binary_accuracy: 0.9943\n",
      "612/612 [==============================] - 0s 746us/step\n",
      "Feature: Occ_Massage Therapist\n",
      "Permuted f1 score: 0.5201716738197425\n",
      "performance decrease: 0.061246907598838995\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0161 - binary_accuracy: 0.9942\n",
      "612/612 [==============================] - 0s 743us/step\n",
      "Feature: Occ_Mechanic\n",
      "Permuted f1 score: 0.5232660228270413\n",
      "performance decrease: 0.05815255859154023\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0154 - binary_accuracy: 0.9945\n",
      "612/612 [==============================] - 0s 747us/step\n",
      "Feature: Occ_Meteorologist\n",
      "Permuted f1 score: 0.5228070175438596\n",
      "performance decrease: 0.058611563874721884\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0154 - binary_accuracy: 0.9945\n",
      "612/612 [==============================] - 0s 751us/step\n",
      "Feature: Occ_Miner\n",
      "Permuted f1 score: 0.5158450704225351\n",
      "performance decrease: 0.06557351099604636\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0155 - binary_accuracy: 0.9944\n",
      "612/612 [==============================] - 0s 772us/step\n",
      "Feature: Occ_Money Service Business Owner\n",
      "Permuted f1 score: 0.5144356955380578\n",
      "performance decrease: 0.0669828858805237\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0154 - binary_accuracy: 0.9943\n",
      "612/612 [==============================] - 0s 739us/step\n",
      "Feature: Occ_Music Producer\n",
      "Permuted f1 score: 0.5213600697471665\n",
      "performance decrease: 0.06005851167141496\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0154 - binary_accuracy: 0.9945\n",
      "612/612 [==============================] - 0s 746us/step\n",
      "Feature: Occ_Musician\n",
      "Permuted f1 score: 0.5205959684487292\n",
      "performance decrease: 0.06082261296985225\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0153 - binary_accuracy: 0.9945\n",
      "612/612 [==============================] - 0s 772us/step\n",
      "Feature: Occ_Mycologist\n",
      "Permuted f1 score: 0.5183246073298429\n",
      "performance decrease: 0.06309397408873862\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0151 - binary_accuracy: 0.9946\n",
      "612/612 [==============================] - 0s 738us/step\n",
      "Feature: Occ_Nanny\n",
      "Permuted f1 score: 0.521813515825492\n",
      "performance decrease: 0.059605065593089535\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0154 - binary_accuracy: 0.9946\n",
      "612/612 [==============================] - 0s 750us/step\n",
      "Feature: Occ_Nematologist\n",
      "Permuted f1 score: 0.5163572060123784\n",
      "performance decrease: 0.06506137540620305\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0151 - binary_accuracy: 0.9947\n",
      "612/612 [==============================] - 0s 770us/step\n",
      "Feature: Occ_News Anchor\n",
      "Permuted f1 score: 0.5106022052586938\n",
      "performance decrease: 0.07081637615988767\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0146 - binary_accuracy: 0.9948\n",
      "612/612 [==============================] - 1s 912us/step\n",
      "Feature: Occ_Nightclub or Bar Owner\n",
      "Permuted f1 score: 0.5178727114210985\n",
      "performance decrease: 0.06354586999748302\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0147 - binary_accuracy: 0.9947\n",
      "612/612 [==============================] - 0s 771us/step\n",
      "Feature: Occ_Non-profit Organization Director\n",
      "Permuted f1 score: 0.519163763066202\n",
      "performance decrease: 0.06225481835237945\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0154 - binary_accuracy: 0.9945\n",
      "612/612 [==============================] - 0s 767us/step\n",
      "Feature: Occ_Notary Public\n",
      "Permuted f1 score: 0.5176678445229682\n",
      "performance decrease: 0.06375073689561328\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0144 - binary_accuracy: 0.9949\n",
      "612/612 [==============================] - 0s 773us/step\n",
      "Feature: Occ_Numismatist\n",
      "Permuted f1 score: 0.5236864771748492\n",
      "performance decrease: 0.05773210424373232\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0146 - binary_accuracy: 0.9947\n",
      "612/612 [==============================] - 0s 741us/step\n",
      "Feature: Occ_Nurse\n",
      "Permuted f1 score: 0.5224913494809689\n",
      "performance decrease: 0.05892723193761262\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0148 - binary_accuracy: 0.9948\n",
      "612/612 [==============================] - 0s 762us/step\n",
      "Feature: Occ_Nutritionist\n",
      "Permuted f1 score: 0.5282363162467419\n",
      "performance decrease: 0.05318226517183955\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0150 - binary_accuracy: 0.9947\n",
      "612/612 [==============================] - 0s 764us/step\n",
      "Feature: Occ_Oceanographer\n",
      "Permuted f1 score: 0.5165794066317627\n",
      "performance decrease: 0.06483917478681878\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0143 - binary_accuracy: 0.9950\n",
      "612/612 [==============================] - 0s 738us/step\n",
      "Feature: Occ_Offshore Investment Advisor\n",
      "Permuted f1 score: 0.5092186128182615\n",
      "performance decrease: 0.07219996860031996\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0146 - binary_accuracy: 0.9949\n",
      "612/612 [==============================] - 0s 772us/step\n",
      "Feature: Occ_Offshore Trustee\n",
      "Permuted f1 score: 0.5082108902333622\n",
      "performance decrease: 0.0732076911852193\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0146 - binary_accuracy: 0.9949\n",
      "612/612 [==============================] - 1s 938us/step\n",
      "Feature: Occ_Online Gambling Site Operator\n",
      "Permuted f1 score: 0.5164075993091536\n",
      "performance decrease: 0.0650109821094279\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0151 - binary_accuracy: 0.9948\n",
      "612/612 [==============================] - 0s 761us/step\n",
      "Feature: Occ_Optometrist\n",
      "Permuted f1 score: 0.506108202443281\n",
      "performance decrease: 0.07531037897530046\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0147 - binary_accuracy: 0.9948\n",
      "612/612 [==============================] - 0s 760us/step\n",
      "Feature: Occ_Ornithologist\n",
      "Permuted f1 score: 0.5122377622377622\n",
      "performance decrease: 0.06918081918081931\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0143 - binary_accuracy: 0.9950\n",
      "612/612 [==============================] - 0s 750us/step\n",
      "Feature: Occ_Osteologist\n",
      "Permuted f1 score: 0.5132275132275133\n",
      "performance decrease: 0.06819106819106824\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0141 - binary_accuracy: 0.9950\n",
      "612/612 [==============================] - 0s 750us/step\n",
      "Feature: Occ_Other\n",
      "Permuted f1 score: 0.5091543156059285\n",
      "performance decrease: 0.072264265812653\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0141 - binary_accuracy: 0.9952\n",
      "612/612 [==============================] - 0s 728us/step\n",
      "Feature: Occ_Paleontologist\n",
      "Permuted f1 score: 0.5220458553791887\n",
      "performance decrease: 0.05937272603939281\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0143 - binary_accuracy: 0.9950\n",
      "612/612 [==============================] - 0s 753us/step\n",
      "Feature: Occ_Paramedic\n",
      "Permuted f1 score: 0.5237258347978909\n",
      "performance decrease: 0.05769274662069057\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0150 - binary_accuracy: 0.9946\n",
      "612/612 [==============================] - 1s 806us/step\n",
      "Feature: Occ_Pastry Chef\n",
      "Permuted f1 score: 0.5131348511383537\n",
      "performance decrease: 0.06828373028022783\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0139 - binary_accuracy: 0.9952\n",
      "612/612 [==============================] - 0s 764us/step\n",
      "Feature: Occ_Pawn Shop Owner\n",
      "Permuted f1 score: 0.5197132616487454\n",
      "performance decrease: 0.061705319769836064\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0143 - binary_accuracy: 0.9950\n",
      "612/612 [==============================] - 0s 769us/step\n",
      "Feature: Occ_Payment Processors Owner\n",
      "Permuted f1 score: 0.5257548845470693\n",
      "performance decrease: 0.05566369687151218\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0144 - binary_accuracy: 0.9949\n",
      "612/612 [==============================] - 0s 745us/step\n",
      "Feature: Occ_Pediatrician\n",
      "Permuted f1 score: 0.5191111111111111\n",
      "performance decrease: 0.062307470307470414\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0136 - binary_accuracy: 0.9951\n",
      "612/612 [==============================] - 0s 729us/step\n",
      "Feature: Occ_Pedologist\n",
      "Permuted f1 score: 0.5155555555555557\n",
      "performance decrease: 0.06586302586302584\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0147 - binary_accuracy: 0.9948\n",
      "612/612 [==============================] - 0s 763us/step\n",
      "Feature: Occ_Pet Groomer\n",
      "Permuted f1 score: 0.5210526315789473\n",
      "performance decrease: 0.06036594983963417\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0136 - binary_accuracy: 0.9950\n",
      "612/612 [==============================] - 1s 954us/step\n",
      "Feature: Occ_Pharmacist\n",
      "Permuted f1 score: 0.5198618307426598\n",
      "performance decrease: 0.0615567506759217\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0140 - binary_accuracy: 0.9951\n",
      "612/612 [==============================] - 0s 747us/step\n",
      "Feature: Occ_Philatelist\n",
      "Permuted f1 score: 0.5159010600706714\n",
      "performance decrease: 0.06551752134791011\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0138 - binary_accuracy: 0.9952\n",
      "612/612 [==============================] - 0s 751us/step\n",
      "Feature: Occ_Photographer\n",
      "Permuted f1 score: 0.5235602094240839\n",
      "performance decrease: 0.057858371994497615\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0139 - binary_accuracy: 0.9950\n",
      "612/612 [==============================] - 0s 751us/step\n",
      "Feature: Occ_Physical Therapist\n",
      "Permuted f1 score: 0.5174216027874564\n",
      "performance decrease: 0.06399697863112508\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0133 - binary_accuracy: 0.9952\n",
      "612/612 [==============================] - 0s 780us/step\n",
      "Feature: Occ_Physicist\n",
      "Permuted f1 score: 0.5183917878528658\n",
      "performance decrease: 0.06302679356571572\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0133 - binary_accuracy: 0.9952\n",
      "612/612 [==============================] - 1s 823us/step\n",
      "Feature: Occ_Pilot\n",
      "Permuted f1 score: 0.5176876617773943\n",
      "performance decrease: 0.06373091964118716\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0137 - binary_accuracy: 0.9951\n",
      "612/612 [==============================] - 0s 750us/step\n",
      "Feature: Occ_Plumber\n",
      "Permuted f1 score: 0.5152306353350741\n",
      "performance decrease: 0.06618794608350742\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0129 - binary_accuracy: 0.9954\n",
      "612/612 [==============================] - 0s 734us/step\n",
      "Feature: Occ_Police Officer\n",
      "Permuted f1 score: 0.5121527777777778\n",
      "performance decrease: 0.0692658036408037\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0134 - binary_accuracy: 0.9953\n",
      "612/612 [==============================] - 0s 744us/step\n",
      "Feature: Occ_Political Scientist\n",
      "Permuted f1 score: 0.5183246073298429\n",
      "performance decrease: 0.06309397408873862\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0134 - binary_accuracy: 0.9954\n",
      "612/612 [==============================] - 0s 760us/step\n",
      "Feature: Occ_Postal Worker\n",
      "Permuted f1 score: 0.5103092783505154\n",
      "performance decrease: 0.07110930306806607\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0133 - binary_accuracy: 0.9954\n",
      "612/612 [==============================] - 0s 758us/step\n",
      "Feature: Occ_Precious Metals Dealer\n",
      "Permuted f1 score: 0.5177304964539008\n",
      "performance decrease: 0.0636880849646807\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0131 - binary_accuracy: 0.9952\n",
      "612/612 [==============================] - 0s 764us/step\n",
      "Feature: Occ_Printmaker\n",
      "Permuted f1 score: 0.5047867711053089\n",
      "performance decrease: 0.0766318103132726\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0130 - binary_accuracy: 0.9954\n",
      "612/612 [==============================] - 0s 772us/step\n",
      "Feature: Occ_Private Banker\n",
      "Permuted f1 score: 0.5101500441306266\n",
      "performance decrease: 0.0712685372879549\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0134 - binary_accuracy: 0.9952\n",
      "612/612 [==============================] - 1s 935us/step\n",
      "Feature: Occ_Private Equity Fund Manager\n",
      "Permuted f1 score: 0.5062388591800356\n",
      "performance decrease: 0.07517972223854585\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0130 - binary_accuracy: 0.9954\n",
      "612/612 [==============================] - 0s 744us/step\n",
      "Feature: Occ_Private Jet Broker\n",
      "Permuted f1 score: 0.5058295964125561\n",
      "performance decrease: 0.0755889850060254\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0136 - binary_accuracy: 0.9953\n",
      "612/612 [==============================] - 0s 765us/step\n",
      "Feature: Occ_Private Security Company Owner\n",
      "Permuted f1 score: 0.5104895104895105\n",
      "performance decrease: 0.07092907092907097\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0131 - binary_accuracy: 0.9953\n",
      "612/612 [==============================] - 0s 787us/step\n",
      "Feature: Occ_Private Tutor\n",
      "Permuted f1 score: 0.5138269402319358\n",
      "performance decrease: 0.06759164118664573\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0126 - binary_accuracy: 0.9956\n",
      "612/612 [==============================] - 0s 773us/step\n",
      "Feature: Occ_Property Manager\n",
      "Permuted f1 score: 0.5127753303964757\n",
      "performance decrease: 0.06864325102210578\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0129 - binary_accuracy: 0.9953\n",
      "612/612 [==============================] - 0s 770us/step\n",
      "Feature: Occ_Psychologist\n",
      "Permuted f1 score: 0.5163572060123784\n",
      "performance decrease: 0.06506137540620305\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0130 - binary_accuracy: 0.9955\n",
      "612/612 [==============================] - 0s 750us/step\n",
      "Feature: Occ_Radio Host\n",
      "Permuted f1 score: 0.49955076370170703\n",
      "performance decrease: 0.08186781771687446\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0122 - binary_accuracy: 0.9957\n",
      "612/612 [==============================] - 0s 766us/step\n",
      "Feature: Occ_Radiologist\n",
      "Permuted f1 score: 0.5043936731107205\n",
      "performance decrease: 0.07702490830786102\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0130 - binary_accuracy: 0.9955\n",
      "612/612 [==============================] - 0s 761us/step\n",
      "Feature: Occ_Real Estate Agent\n",
      "Permuted f1 score: 0.5083553210202286\n",
      "performance decrease: 0.07306326039835287\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0127 - binary_accuracy: 0.9954\n",
      "612/612 [==============================] - 0s 754us/step\n",
      "Feature: Occ_Real Estate Broker\n",
      "Permuted f1 score: 0.5004533091568449\n",
      "performance decrease: 0.08096527226173655\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0132 - binary_accuracy: 0.9954\n",
      "612/612 [==============================] - 0s 771us/step\n",
      "Feature: Occ_Receptionist\n",
      "Permuted f1 score: 0.5202821869488536\n",
      "performance decrease: 0.06113639446972785\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0130 - binary_accuracy: 0.9955\n",
      "612/612 [==============================] - 0s 743us/step\n",
      "Feature: Occ_Research Scientist\n",
      "Permuted f1 score: 0.5164737310774711\n",
      "performance decrease: 0.06494485034111042\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0125 - binary_accuracy: 0.9956\n",
      "612/612 [==============================] - 0s 767us/step\n",
      "Feature: Occ_Retail Salesperson\n",
      "Permuted f1 score: 0.5202821869488536\n",
      "performance decrease: 0.06113639446972785\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0127 - binary_accuracy: 0.9956\n",
      "612/612 [==============================] - 0s 757us/step\n",
      "Feature: Occ_Retired\n",
      "Permuted f1 score: 0.5205959684487292\n",
      "performance decrease: 0.06082261296985225\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0128 - binary_accuracy: 0.9955\n",
      "612/612 [==============================] - 0s 771us/step\n",
      "Feature: Occ_School Bus Driver\n",
      "Permuted f1 score: 0.5059144676979073\n",
      "performance decrease: 0.07550411372067423\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0127 - binary_accuracy: 0.9955\n",
      "612/612 [==============================] - 0s 748us/step\n",
      "Feature: Occ_School Teacher\n",
      "Permuted f1 score: 0.5035587188612098\n",
      "performance decrease: 0.07785986255737165\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0125 - binary_accuracy: 0.9956\n",
      "612/612 [==============================] - 0s 744us/step\n",
      "Feature: Occ_Sculptor\n",
      "Permuted f1 score: 0.5185825410544512\n",
      "performance decrease: 0.06283604036413026\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0125 - binary_accuracy: 0.9956\n",
      "612/612 [==============================] - 0s 732us/step\n",
      "Feature: Occ_Security Guard\n",
      "Permuted f1 score: 0.511831726555653\n",
      "performance decrease: 0.06958685486292848\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0127 - binary_accuracy: 0.9956\n",
      "612/612 [==============================] - 0s 750us/step\n",
      "Feature: Occ_Seismologist\n",
      "Permuted f1 score: 0.5236051502145923\n",
      "performance decrease: 0.057813431203989185\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0124 - binary_accuracy: 0.9957\n",
      "612/612 [==============================] - 0s 781us/step\n",
      "Feature: Occ_Semiotician\n",
      "Permuted f1 score: 0.5205959684487292\n",
      "performance decrease: 0.06082261296985225\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0127 - binary_accuracy: 0.9955\n",
      "612/612 [==============================] - 0s 751us/step\n",
      "Feature: Occ_Set Designer\n",
      "Permuted f1 score: 0.5095986038394416\n",
      "performance decrease: 0.07181997757913994\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0128 - binary_accuracy: 0.9957\n",
      "612/612 [==============================] - 0s 757us/step\n",
      "Feature: Occ_Shell Company Operator\n",
      "Permuted f1 score: 0.5133214920071048\n",
      "performance decrease: 0.06809708941147674\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0122 - binary_accuracy: 0.9957\n",
      "612/612 [==============================] - 0s 741us/step\n",
      "Feature: Occ_Sinologist\n",
      "Permuted f1 score: 0.5031446540880504\n",
      "performance decrease: 0.07827392733053107\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0129 - binary_accuracy: 0.9956\n",
      "612/612 [==============================] - 0s 742us/step\n",
      "Feature: Occ_Social Worker\n",
      "Permuted f1 score: 0.511304347826087\n",
      "performance decrease: 0.07011423359249447\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0124 - binary_accuracy: 0.9957\n",
      "612/612 [==============================] - 0s 768us/step\n",
      "Feature: Occ_Sociologist\n",
      "Permuted f1 score: 0.5095320623916813\n",
      "performance decrease: 0.07188651902690024\n",
      "4589/4589 [==============================] - 5s 1ms/step - loss: 0.0132 - binary_accuracy: 0.9953\n",
      "612/612 [==============================] - 0s 747us/step\n",
      "Feature: Occ_Software Developer\n",
      "Permuted f1 score: 0.5115452930728241\n",
      "performance decrease: 0.06987328834575735\n",
      "4589/4589 [==============================] - 9s 2ms/step - loss: 0.0129 - binary_accuracy: 0.9954\n",
      "612/612 [==============================] - 1s 1ms/step\n",
      "Feature: Occ_Sommelier\n",
      "Permuted f1 score: 0.5035087719298246\n",
      "performance decrease: 0.07790980948875692\n",
      "4589/4589 [==============================] - 11s 2ms/step - loss: 0.0120 - binary_accuracy: 0.9958\n",
      "612/612 [==============================] - 2s 3ms/step\n",
      "Feature: Occ_Sound Engineer\n",
      "Permuted f1 score: 0.4991304347826087\n",
      "performance decrease: 0.08228814663597278\n",
      "4589/4589 [==============================] - 13s 3ms/step - loss: 0.0123 - binary_accuracy: 0.9958\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: Occ_Sports Agent\n",
      "Permuted f1 score: 0.49568221070811747\n",
      "performance decrease: 0.08573637071046403\n",
      "4589/4589 [==============================] - 14s 3ms/step - loss: 0.0122 - binary_accuracy: 0.9958\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: Occ_Statistician\n",
      "Permuted f1 score: 0.5084745762711865\n",
      "performance decrease: 0.07294400514739496\n",
      "4589/4589 [==============================] - 14s 3ms/step - loss: 0.0125 - binary_accuracy: 0.9957\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: Occ_Stock Broker\n",
      "Permuted f1 score: 0.5217391304347826\n",
      "performance decrease: 0.0596794509837989\n",
      "4589/4589 [==============================] - 13s 3ms/step - loss: 0.0125 - binary_accuracy: 0.9958\n",
      "612/612 [==============================] - 1s 1ms/step\n",
      "Feature: Occ_Student\n",
      "Permuted f1 score: 0.5148342059336823\n",
      "performance decrease: 0.06658437548489915\n",
      "4589/4589 [==============================] - 12s 3ms/step - loss: 0.0122 - binary_accuracy: 0.9959\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: Occ_Surgeon\n",
      "Permuted f1 score: 0.5047210300429185\n",
      "performance decrease: 0.07669755137566303\n",
      "4589/4589 [==============================] - 12s 3ms/step - loss: 0.0120 - binary_accuracy: 0.9959\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: Occ_Surveyor\n",
      "Permuted f1 score: 0.5090595340811044\n",
      "performance decrease: 0.07235904733747711\n",
      "4589/4589 [==============================] - 12s 3ms/step - loss: 0.0114 - binary_accuracy: 0.9960\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: Occ_TV Producer\n",
      "Permuted f1 score: 0.5105263157894737\n",
      "performance decrease: 0.07089226562910778\n",
      "4589/4589 [==============================] - 11s 2ms/step - loss: 0.0132 - binary_accuracy: 0.9956\n",
      "612/612 [==============================] - 1s 1ms/step\n",
      "Feature: Occ_Tailor\n",
      "Permuted f1 score: 0.49823943661971826\n",
      "performance decrease: 0.08317914479886324\n",
      "4589/4589 [==============================] - 12s 3ms/step - loss: 0.0125 - binary_accuracy: 0.9957\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: Occ_Tattoo Artist\n",
      "Permuted f1 score: 0.5086206896551724\n",
      "performance decrease: 0.07279789176340912\n",
      "4589/4589 [==============================] - 12s 3ms/step - loss: 0.0120 - binary_accuracy: 0.9960\n",
      "612/612 [==============================] - 1s 1ms/step\n",
      "Feature: Occ_Tax Advisor\n",
      "Permuted f1 score: 0.5004212299915753\n",
      "performance decrease: 0.08099735142700615\n",
      "4589/4589 [==============================] - 10s 2ms/step - loss: 0.0119 - binary_accuracy: 0.9959\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: Occ_Taxi Driver\n",
      "Permuted f1 score: 0.5030146425495263\n",
      "performance decrease: 0.07840393886905517\n",
      "4589/4589 [==============================] - 11s 2ms/step - loss: 0.0119 - binary_accuracy: 0.9960\n",
      "612/612 [==============================] - 1s 1ms/step\n",
      "Feature: Occ_Telemarketer\n",
      "Permuted f1 score: 0.5017361111111112\n",
      "performance decrease: 0.07968247030747033\n",
      "4589/4589 [==============================] - 15s 3ms/step - loss: 0.0125 - binary_accuracy: 0.9958\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: Occ_Theater Director\n",
      "Permuted f1 score: 0.5102389078498293\n",
      "performance decrease: 0.07117967356875221\n",
      "4589/4589 [==============================] - 13s 3ms/step - loss: 0.0118 - binary_accuracy: 0.9958\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: Occ_Therapist\n",
      "Permuted f1 score: 0.5088339222614842\n",
      "performance decrease: 0.07258465915709733\n",
      "4589/4589 [==============================] - 13s 3ms/step - loss: 0.0115 - binary_accuracy: 0.9961\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: Occ_Tour Guide\n",
      "Permuted f1 score: 0.5021720243266724\n",
      "performance decrease: 0.07924655709190909\n",
      "4589/4589 [==============================] - 14s 3ms/step - loss: 0.0122 - binary_accuracy: 0.9959\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: Occ_Translator\n",
      "Permuted f1 score: 0.5053003533568904\n",
      "performance decrease: 0.0761182280616911\n",
      "4589/4589 [==============================] - 12s 3ms/step - loss: 0.0117 - binary_accuracy: 0.9959\n",
      "612/612 [==============================] - 1s 1ms/step\n",
      "Feature: Occ_Travel Agency Owner\n",
      "Permuted f1 score: 0.5043327556325824\n",
      "performance decrease: 0.0770858257859991\n",
      "4589/4589 [==============================] - 13s 3ms/step - loss: 0.0115 - binary_accuracy: 0.9960\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: Occ_Travel Agent\n",
      "Permuted f1 score: 0.49473684210526314\n",
      "performance decrease: 0.08668173931331835\n",
      "4589/4589 [==============================] - 13s 3ms/step - loss: 0.0121 - binary_accuracy: 0.9959\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: Occ_Trust and Company Service Provider\n",
      "Permuted f1 score: 0.5158450704225351\n",
      "performance decrease: 0.06557351099604636\n",
      "4589/4589 [==============================] - 13s 3ms/step - loss: 0.0119 - binary_accuracy: 0.9961\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: Occ_Unemployed\n",
      "Permuted f1 score: 0.503896103896104\n",
      "performance decrease: 0.07752247752247754\n",
      "4589/4589 [==============================] - 12s 3ms/step - loss: 0.0120 - binary_accuracy: 0.9958\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: Occ_University Professor\n",
      "Permuted f1 score: 0.491743119266055\n",
      "performance decrease: 0.08967546215252648\n",
      "4589/4589 [==============================] - 12s 3ms/step - loss: 0.0116 - binary_accuracy: 0.9959\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: Occ_Unknown\n",
      "Permuted f1 score: 0.5112262521588947\n",
      "performance decrease: 0.07019232925968677\n",
      "4589/4589 [==============================] - 15s 3ms/step - loss: 0.0120 - binary_accuracy: 0.9957\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: Occ_Urban Planner\n",
      "Permuted f1 score: 0.4973451327433629\n",
      "performance decrease: 0.0840734486752186\n",
      "4589/4589 [==============================] - 15s 3ms/step - loss: 0.0111 - binary_accuracy: 0.9960\n",
      "612/612 [==============================] - 1s 1ms/step\n",
      "Feature: Occ_Venture Capitalist\n",
      "Permuted f1 score: 0.5208148804251551\n",
      "performance decrease: 0.06060370099342638\n",
      "4589/4589 [==============================] - 16s 3ms/step - loss: 0.0121 - binary_accuracy: 0.9958\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: Occ_Veterinarian\n",
      "Permuted f1 score: 0.525764192139738\n",
      "performance decrease: 0.055654389278843475\n",
      "4589/4589 [==============================] - 12s 3ms/step - loss: 0.0121 - binary_accuracy: 0.9959\n",
      "612/612 [==============================] - 1s 1ms/step\n",
      "Feature: Occ_Veterinarian Assistant\n",
      "Permuted f1 score: 0.5078534031413613\n",
      "performance decrease: 0.0735651782772202\n",
      "4589/4589 [==============================] - 11s 2ms/step - loss: 0.0114 - binary_accuracy: 0.9960\n",
      "612/612 [==============================] - 1s 1ms/step\n",
      "Feature: Occ_Vexillologist\n",
      "Permuted f1 score: 0.5094339622641508\n",
      "performance decrease: 0.07198461915443066\n",
      "4589/4589 [==============================] - 11s 2ms/step - loss: 0.0112 - binary_accuracy: 0.9961\n",
      "612/612 [==============================] - 1s 1ms/step\n",
      "Feature: Occ_Videographer\n",
      "Permuted f1 score: 0.5072094995759118\n",
      "performance decrease: 0.07420908184266972\n",
      "4589/4589 [==============================] - 12s 3ms/step - loss: 0.0116 - binary_accuracy: 0.9960\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: Occ_Virtual Asset Service Providers\n",
      "Permuted f1 score: 0.505281690140845\n",
      "performance decrease: 0.07613689127773648\n",
      "4589/4589 [==============================] - 12s 3ms/step - loss: 0.0120 - binary_accuracy: 0.9959\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: Occ_Voice Actor\n",
      "Permuted f1 score: 0.5004299226139296\n",
      "performance decrease: 0.08098865880465189\n",
      "4589/4589 [==============================] - 13s 3ms/step - loss: 0.0116 - binary_accuracy: 0.9959\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: Occ_Volcanologist\n",
      "Permuted f1 score: 0.5112262521588947\n",
      "performance decrease: 0.07019232925968677\n",
      "4589/4589 [==============================] - 12s 3ms/step - loss: 0.0112 - binary_accuracy: 0.9961\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: Occ_Waiter/Waitress\n",
      "Permuted f1 score: 0.5110732538330494\n",
      "performance decrease: 0.07034532758553214\n",
      "4589/4589 [==============================] - 11s 2ms/step - loss: 0.0111 - binary_accuracy: 0.9960\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: Occ_Warehouse Worker\n",
      "Permuted f1 score: 0.5131348511383537\n",
      "performance decrease: 0.06828373028022783\n",
      "4589/4589 [==============================] - 10s 2ms/step - loss: 0.0114 - binary_accuracy: 0.9960\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: Occ_Wedding Planner\n",
      "Permuted f1 score: 0.5132743362831859\n",
      "performance decrease: 0.06814424513539563\n",
      "4589/4589 [==============================] - 11s 2ms/step - loss: 0.0112 - binary_accuracy: 0.9962\n",
      "612/612 [==============================] - 1s 1ms/step\n",
      "Feature: Occ_Window Cleaner\n",
      "Permuted f1 score: 0.507168458781362\n",
      "performance decrease: 0.07425012263721953\n",
      "4589/4589 [==============================] - 11s 2ms/step - loss: 0.0118 - binary_accuracy: 0.9962\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: Occ_Zookeeper\n",
      "Permuted f1 score: 0.5069444444444445\n",
      "performance decrease: 0.07447413697413696\n",
      "4589/4589 [==============================] - 10s 2ms/step - loss: 0.0115 - binary_accuracy: 0.9962\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: deposits\n",
      "Permuted f1 score: 0.5130801687763713\n",
      "performance decrease: 0.06833841264221019\n",
      "4589/4589 [==============================] - 12s 3ms/step - loss: 0.0120 - binary_accuracy: 0.9959\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: withdrawals\n",
      "Permuted f1 score: 0.5144312393887945\n",
      "performance decrease: 0.06698734202978696\n",
      "4589/4589 [==============================] - 12s 3ms/step - loss: 0.0111 - binary_accuracy: 0.9962\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: amount_cash\n",
      "Permuted f1 score: 0.5106007067137809\n",
      "performance decrease: 0.07081787470480061\n",
      "4589/4589 [==============================] - 14s 3ms/step - loss: 0.0119 - binary_accuracy: 0.9960\n",
      "612/612 [==============================] - 2s 3ms/step\n",
      "Feature: amount_emt_sent\n",
      "Permuted f1 score: 0.5131810193321616\n",
      "performance decrease: 0.06823756208641985\n",
      "4589/4589 [==============================] - 13s 3ms/step - loss: 0.0119 - binary_accuracy: 0.9959\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: amount_emt_received\n",
      "Permuted f1 score: 0.5051369863013698\n",
      "performance decrease: 0.07628159511721166\n",
      "4589/4589 [==============================] - 14s 3ms/step - loss: 0.0109 - binary_accuracy: 0.9963\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: amount_wire_sent\n",
      "Permuted f1 score: 0.500878734622144\n",
      "performance decrease: 0.08053984679643744\n",
      "4589/4589 [==============================] - 13s 3ms/step - loss: 0.0113 - binary_accuracy: 0.9962\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: amount_wire_received\n",
      "Permuted f1 score: 0.4904013961605585\n",
      "performance decrease: 0.09101718525802299\n",
      "4589/4589 [==============================] - 14s 3ms/step - loss: 0.0113 - binary_accuracy: 0.9961\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: message_flag\n",
      "Permuted f1 score: 0.49473684210526314\n",
      "performance decrease: 0.08668173931331835\n",
      "4589/4589 [==============================] - 13s 3ms/step - loss: 0.0113 - binary_accuracy: 0.9961\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "Feature: Country_CA\n",
      "Permuted f1 score: 0.4991304347826087\n",
      "performance decrease: 0.08228814663597278\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "# partition datasets\n",
    "X_train = df_train_sc.drop(columns=['label'])\n",
    "y_train = df_train_sc['label']\n",
    "\n",
    "X_val = df_val_sc.drop(columns=['label'])\n",
    "y_val = df_val_sc['label']\n",
    "\n",
    "# Train Model\n",
    "model = MyNeuralNetwork(X_train.shape[1])\n",
    "\n",
    "epochs = 1\n",
    "batch = 128\n",
    "\n",
    "# fit\n",
    "keras.utils.set_random_seed(1337)\n",
    "print('.....Calcualting Base f1 Score.....')\n",
    "model.fit(X_train,y_train)\n",
    "predictions = (model.predict(X_val).ravel()>0.5)+0\n",
    "base_score = f1_score(y_val, predictions)\n",
    "print('base f1 score:',base_score)\n",
    "\n",
    "\n",
    "# Permuation loop\n",
    "print('.....Starting Permuation Importance.....')\n",
    "features = []\n",
    "permutation_score =[]\n",
    "for feature in X_train.columns:\n",
    "    X_permute_train = X_train.copy()\n",
    "    X_permute_train[feature] = X_permute_train[feature].sample(frac=1)\n",
    "    # fit model\n",
    "    model.fit(X_permute_train,y_train)\n",
    "    # predict f1\n",
    "    predictions = (model.predict(X_val).ravel()>0.5)+0\n",
    "    score = f1_score(y_val, predictions)\n",
    "    # performance decrease\n",
    "    p_score = base_score - score\n",
    "    print('Feature:',feature)\n",
    "    print('Permuted f1 score:', score)\n",
    "    print('performance decrease:',p_score)\n",
    "    # append lists\n",
    "    permutation_score.append(p_score)\n",
    "    features.append(feature)\n",
    "\n",
    "df_results = pd.DataFrame({'feature': features, 'performance_decrease': permutation_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df_results.plot(kind = 'bar')\n",
    "\n",
    "df_results.sort_values(by = 'performance_decrease', ascending=False).plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train & Evaluate Custom Neural Network without early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21145/21145 [==============================] - 21s 963us/step - loss: 0.1936 - binary_accuracy: 0.9265\n",
      "13643/13643 [==============================] - 14s 981us/step - loss: 0.2086 - binary_accuracy: 0.9218\n",
      "1437/1437 [==============================] - 2s 978us/step - loss: 0.2783 - binary_accuracy: 0.8950\n",
      "1402/1402 [==============================] - 2s 952us/step - loss: 0.2890 - binary_accuracy: 0.8894\n",
      "22189/22189 [==============================] - 23s 1ms/step - loss: 0.1922 - binary_accuracy: 0.9275\n",
      "26585/26585 [==============================] - 29s 1ms/step - loss: 0.1865 - binary_accuracy: 0.9296\n",
      "18834/18834 [==============================] - 19s 976us/step - loss: 0.2008 - binary_accuracy: 0.9238\n",
      "14543/14543 [==============================] - 14s 936us/step - loss: 0.2087 - binary_accuracy: 0.9204\n",
      "4447/4447 [==============================] - 5s 937us/step - loss: 0.2458 - binary_accuracy: 0.9065\n",
      "6881/6881 [==============================] - 8s 1ms/step - loss: 0.2288 - binary_accuracy: 0.9133\n",
      "5657/5657 [==============================] - 7s 1ms/step - loss: 0.2407 - binary_accuracy: 0.9081\n",
      "26464/26464 [==============================] - 26s 953us/step - loss: 0.1859 - binary_accuracy: 0.9296\n",
      "18505/18505 [==============================] - 17s 909us/step - loss: 0.2006 - binary_accuracy: 0.9229\n",
      "3977/3977 [==============================] - 4s 974us/step - loss: 0.2496 - binary_accuracy: 0.9061\n",
      "9031/9031 [==============================] - 9s 918us/step - loss: 0.2217 - binary_accuracy: 0.9158\n",
      "2736/2736 [==============================] - 3s 935us/step - loss: 0.2582 - binary_accuracy: 0.9019\n",
      "24412/24412 [==============================] - 24s 973us/step - loss: 0.1894 - binary_accuracy: 0.9282\n",
      "5325/5325 [==============================] - 7s 1ms/step - loss: 0.2392 - binary_accuracy: 0.9090\n",
      "15270/15270 [==============================] - 15s 979us/step - loss: 0.2057 - binary_accuracy: 0.9212\n",
      "21112/21112 [==============================] - 22s 992us/step - loss: 0.1948 - binary_accuracy: 0.9264\n",
      "16382/16382 [==============================] - 22s 1ms/step - loss: 0.2038 - binary_accuracy: 0.9224\n",
      "2840/2840 [==============================] - 4s 996us/step - loss: 0.2570 - binary_accuracy: 0.9029\n",
      "3022/3022 [==============================] - 4s 1ms/step - loss: 0.2566 - binary_accuracy: 0.9026\n",
      "28155/28155 [==============================] - 29s 1ms/step - loss: 0.1825 - binary_accuracy: 0.9310\n",
      "12969/12969 [==============================] - 13s 990us/step - loss: 0.2126 - binary_accuracy: 0.9192\n",
      "6505/6505 [==============================] - 7s 975us/step - loss: 0.2373 - binary_accuracy: 0.9095\n",
      "15385/15385 [==============================] - 16s 998us/step - loss: 0.2057 - binary_accuracy: 0.9209\n",
      "5893/5893 [==============================] - 6s 954us/step - loss: 0.2382 - binary_accuracy: 0.9096\n",
      "17124/17124 [==============================] - 21s 1ms/step - loss: 0.1991 - binary_accuracy: 0.9244\n",
      "26850/26850 [==============================] - 28s 1ms/step - loss: 0.1843 - binary_accuracy: 0.9308\n",
      "22090/22090 [==============================] - 23s 1ms/step - loss: 0.1937 - binary_accuracy: 0.9269\n",
      "612/612 [==============================] - 0s 700us/step\n",
      "612/612 [==============================] - 0s 750us/step\n",
      "612/612 [==============================] - 0s 715us/step\n",
      "612/612 [==============================] - 1s 771us/step\n",
      "612/612 [==============================] - 0s 738us/step\n",
      "612/612 [==============================] - 0s 733us/step\n",
      "612/612 [==============================] - 1s 768us/step\n",
      "612/612 [==============================] - 1s 819us/step\n",
      "612/612 [==============================] - 0s 705us/step\n",
      "612/612 [==============================] - 1s 750us/step\n",
      "612/612 [==============================] - 0s 717us/step\n",
      "612/612 [==============================] - 1s 755us/step\n",
      "612/612 [==============================] - 0s 724us/step\n",
      "612/612 [==============================] - 0s 766us/step\n",
      "612/612 [==============================] - 0s 731us/step\n",
      "612/612 [==============================] - 1s 762us/step\n",
      "612/612 [==============================] - 0s 737us/step\n",
      "612/612 [==============================] - 0s 758us/step\n",
      "612/612 [==============================] - 1s 910us/step\n",
      "612/612 [==============================] - 1s 797us/step\n",
      "612/612 [==============================] - 0s 756us/step\n",
      "612/612 [==============================] - 1s 767us/step\n",
      "612/612 [==============================] - 1s 745us/step\n",
      "612/612 [==============================] - 1s 749us/step\n",
      "612/612 [==============================] - 1s 947us/step\n",
      "612/612 [==============================] - 0s 754us/step\n",
      "612/612 [==============================] - 0s 710us/step\n",
      "612/612 [==============================] - 0s 742us/step\n",
      "612/612 [==============================] - 1s 798us/step\n",
      "612/612 [==============================] - 0s 716us/step\n",
      "612/612 [==============================] - 1s 793us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     19027\n",
      "           1       0.65      0.57      0.61       552\n",
      "\n",
      "    accuracy                           0.98     19579\n",
      "   macro avg       0.82      0.78      0.80     19579\n",
      "weighted avg       0.98      0.98      0.98     19579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_shape = df_train_sc.drop(columns=['label']).shape[1]\n",
    "epochs = 1\n",
    "batch_size = 10\n",
    "\n",
    "\n",
    "# Initialize Model\n",
    "resampling_model = MyNeuralNetworkClassifier(number_of_models,input_shape)\n",
    "\n",
    "# Train Model\n",
    "resampling_model.fit(sample_ids, df_train_sc, epochs, batch_size)\n",
    "\n",
    "# predict\n",
    "df_kyc_val_X = df_val_sc.drop(columns=['label'])\n",
    "df_kyc_val_y = df_val_sc['label']\n",
    "\n",
    "predictions = resampling_model.predict(df_kyc_val_X, threshold = 0.95)\n",
    "\n",
    "# print report\n",
    "print(classification_report(df_kyc_val_y,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15948/15948 [==============================] - 143s 9ms/step - loss: 1.1864 - binary_accuracy: 0.8761\n",
      "13364/13364 [==============================] - 122s 9ms/step - loss: 1.2616 - binary_accuracy: 0.8748\n",
      "5022/5022 [==============================] - 47s 9ms/step - loss: 1.9864 - binary_accuracy: 0.8688\n",
      "16997/16997 [==============================] - 156s 9ms/step - loss: 1.1625 - binary_accuracy: 0.8771\n",
      "2576/2576 [==============================] - 24s 9ms/step - loss: 3.0562 - binary_accuracy: 0.8693\n",
      "19125/19125 [==============================] - 175s 9ms/step - loss: 1.1297 - binary_accuracy: 0.8784\n",
      "27819/27819 [==============================] - 251s 9ms/step - loss: 1.0209 - binary_accuracy: 0.8845\n",
      "16811/16811 [==============================] - 151s 9ms/step - loss: 1.1713 - binary_accuracy: 0.8767\n",
      "3291/3291 [==============================] - 31s 9ms/step - loss: 2.5832 - binary_accuracy: 0.8709\n",
      "8413/8413 [==============================] - 77s 9ms/step - loss: 1.5140 - binary_accuracy: 0.8768\n",
      "20759/20759 [==============================] - 187s 9ms/step - loss: 1.1019 - binary_accuracy: 0.8772\n",
      "16550/16550 [==============================] - 153s 9ms/step - loss: 1.1721 - binary_accuracy: 0.8778\n",
      "22834/22834 [==============================] - 207s 9ms/step - loss: 1.0643 - binary_accuracy: 0.8848\n",
      "9984/9984 [==============================] - 89s 9ms/step - loss: 1.3975 - binary_accuracy: 0.8771\n",
      "3111/3111 [==============================] - 29s 9ms/step - loss: 2.6950 - binary_accuracy: 0.8642\n",
      "17622/17622 [==============================] - 163s 9ms/step - loss: 1.1510 - binary_accuracy: 0.8803\n",
      "8610/8610 [==============================] - 80s 9ms/step - loss: 1.5005 - binary_accuracy: 0.8721\n",
      "19121/19121 [==============================] - 179s 9ms/step - loss: 1.1300 - binary_accuracy: 0.8783\n",
      "6995/6995 [==============================] - 64s 9ms/step - loss: 1.6549 - binary_accuracy: 0.8726\n",
      "18730/18730 [==============================] - 171s 9ms/step - loss: 1.1320 - binary_accuracy: 0.8801\n",
      "22301/22301 [==============================] - 207s 9ms/step - loss: 1.0790 - binary_accuracy: 0.8838\n",
      "918/918 [==============================] - 9s 9ms/step - loss: 7.0268 - binary_accuracy: 0.8607\n",
      "24449/24449 [==============================] - 223s 9ms/step - loss: 1.0566 - binary_accuracy: 0.8827\n",
      "24280/24280 [==============================] - 226s 9ms/step - loss: 1.0572 - binary_accuracy: 0.8835\n",
      "1332/1332 [==============================] - 13s 9ms/step - loss: 5.1142 - binary_accuracy: 0.8626\n",
      "1200/1200 [==============================] - 12s 9ms/step - loss: 5.5887 - binary_accuracy: 0.8635\n",
      "17325/17325 [==============================] - 160s 9ms/step - loss: 1.1586 - binary_accuracy: 0.8769\n",
      "6797/6797 [==============================] - 63s 9ms/step - loss: 1.6876 - binary_accuracy: 0.8685\n",
      "17279/17279 [==============================] - 157s 9ms/step - loss: 1.1604 - binary_accuracy: 0.8781\n",
      "25108/25108 [==============================] - 225s 9ms/step - loss: 1.0472 - binary_accuracy: 0.8852\n",
      "17635/17635 [==============================] - 159s 9ms/step - loss: 1.1479 - binary_accuracy: 0.8801\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     19027\n",
      "           1       0.62      0.45      0.52       552\n",
      "\n",
      "    accuracy                           0.98     19579\n",
      "   macro avg       0.80      0.72      0.75     19579\n",
      "weighted avg       0.97      0.98      0.97     19579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_shape = df_train_sc.drop(columns=['label']).shape[1]\n",
    "epochs = 1\n",
    "batch_size = 10\n",
    "\n",
    "\n",
    "# Initialize Model\n",
    "resampling_model = MyNeuralNetworkClassifier(number_of_models,input_shape)\n",
    "\n",
    "# Train Model\n",
    "resampling_model.fit(sample_ids, df_train_sc, epochs, batch_size)\n",
    "\n",
    "# predict\n",
    "df_kyc_val_X = df_val_sc.drop(columns=['label'])\n",
    "df_kyc_val_y = df_val_sc['label']\n",
    "\n",
    "predictions = resampling_model.predict(df_kyc_val_X, threshold = 0.95)\n",
    "\n",
    "# print report\n",
    "print(classification_report(df_kyc_val_y,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train & Evaluate Custom Neural Network with Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "992/992 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.8807372895979294\n",
      "2809/2809 [==============================] - 38s 13ms/step - loss: 2.7963 - binary_accuracy: 0.8727 - val_loss: 0.7991 - val_binary_accuracy: 0.8808\n",
      "Epoch 2/30\n",
      "992/992 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9060136311380134\n",
      "2809/2809 [==============================] - 36s 13ms/step - loss: 0.7726 - binary_accuracy: 0.8999 - val_loss: 0.7562 - val_binary_accuracy: 0.9060\n",
      "Epoch 3/30\n",
      "992/992 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9051589627123946\n",
      "2809/2809 [==============================] - 35s 13ms/step - loss: 0.7565 - binary_accuracy: 0.9046 - val_loss: 0.7521 - val_binary_accuracy: 0.9052\n",
      "Epoch 4/30\n",
      "992/992 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9066456007003545\n",
      "2809/2809 [==============================] - 36s 13ms/step - loss: 0.7537 - binary_accuracy: 0.9050 - val_loss: 0.7515 - val_binary_accuracy: 0.9066\n",
      "Epoch 5/30\n",
      "992/992 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9068665816036812\n",
      "2809/2809 [==============================] - 36s 13ms/step - loss: 0.7526 - binary_accuracy: 0.9053 - val_loss: 0.7510 - val_binary_accuracy: 0.9070\n",
      "Epoch 6/30\n",
      "992/992 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9061076458763715\n",
      "2809/2809 [==============================] - 36s 13ms/step - loss: 0.7519 - binary_accuracy: 0.9053 - val_loss: 0.7551 - val_binary_accuracy: 0.9061\n",
      "Epoch 7/30\n",
      "992/992 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9097213668480537\n",
      "2809/2809 [==============================] - 37s 13ms/step - loss: 0.7510 - binary_accuracy: 0.9053 - val_loss: 0.7422 - val_binary_accuracy: 0.9097\n",
      "Epoch 8/30\n",
      "992/992 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9029996560468052\n",
      "2809/2809 [==============================] - 36s 13ms/step - loss: 0.7499 - binary_accuracy: 0.9056 - val_loss: 0.7458 - val_binary_accuracy: 0.9031\n",
      "Epoch 9/30\n",
      "992/992 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9100185422900737\n",
      "2809/2809 [==============================] - 37s 13ms/step - loss: 0.7482 - binary_accuracy: 0.9065 - val_loss: 0.7547 - val_binary_accuracy: 0.9100\n",
      "Epoch 10/30\n",
      "992/992 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9056205500096279\n",
      "2809/2809 [==============================] - 37s 13ms/step - loss: 0.7468 - binary_accuracy: 0.9065 - val_loss: 0.7407 - val_binary_accuracy: 0.9056\n",
      "Epoch 11/30\n",
      "992/992 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.908093211418723\n",
      "Early Stopping\n",
      "2809/2809 [==============================] - 36s 13ms/step - loss: 0.7478 - binary_accuracy: 0.9069 - val_loss: 0.7374 - val_binary_accuracy: 0.9081\n",
      "Epoch 1/30\n",
      "640/640 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.8761201804081393\n",
      "1812/1812 [==============================] - 30s 14ms/step - loss: 3.8661 - binary_accuracy: 0.8727 - val_loss: 0.7885 - val_binary_accuracy: 0.8761\n",
      "Epoch 2/30\n",
      "640/640 [==============================] - 2s 3ms/step\n",
      "Validation Macro F1 Score 0.9056691477425804\n",
      "1812/1812 [==============================] - 25s 14ms/step - loss: 0.7818 - binary_accuracy: 0.8882 - val_loss: 0.7617 - val_binary_accuracy: 0.9057\n",
      "Epoch 3/30\n",
      "640/640 [==============================] - 2s 3ms/step\n",
      "Validation Macro F1 Score 0.9027196425643915\n",
      "1812/1812 [==============================] - 24s 13ms/step - loss: 0.7640 - binary_accuracy: 0.9027 - val_loss: 0.7571 - val_binary_accuracy: 0.9028\n",
      "Epoch 4/30\n",
      "640/640 [==============================] - 2s 3ms/step\n",
      "Validation Macro F1 Score 0.911678241533844\n",
      "1812/1812 [==============================] - 24s 13ms/step - loss: 0.7572 - binary_accuracy: 0.9047 - val_loss: 0.7493 - val_binary_accuracy: 0.9117\n",
      "Epoch 5/30\n",
      "640/640 [==============================] - 2s 3ms/step\n",
      "Validation Macro F1 Score 0.9097335561682922\n",
      "1812/1812 [==============================] - 24s 13ms/step - loss: 0.7533 - binary_accuracy: 0.9047 - val_loss: 0.7440 - val_binary_accuracy: 0.9097\n",
      "Epoch 6/30\n",
      "640/640 [==============================] - 2s 3ms/step\n",
      "Validation Macro F1 Score 0.9110665449353542\n",
      "Early Stopping\n",
      "1812/1812 [==============================] - 24s 13ms/step - loss: 0.7535 - binary_accuracy: 0.9049 - val_loss: 0.7387 - val_binary_accuracy: 0.9111\n",
      "Epoch 1/30\n",
      "68/68 [==============================] - 0s 2ms/step loss: 30.3516 - binary_accuracy: \n",
      "Validation Macro F1 Score 0.8462494717565854\n",
      "191/191 [==============================] - 4s 14ms/step - loss: 29.7648 - binary_accuracy: 0.8591 - val_loss: 1.0349 - val_binary_accuracy: 0.8497\n",
      "Epoch 2/30\n",
      "68/68 [==============================] - 0s 2ms/step loss: 0.9125 - binary_accuracy: \n",
      "Validation Macro F1 Score 0.8760902203849337\n",
      "191/191 [==============================] - 3s 13ms/step - loss: 0.9125 - binary_accuracy: 0.8682 - val_loss: 0.8795 - val_binary_accuracy: 0.8762\n",
      "Epoch 3/30\n",
      "68/68 [==============================] - 0s 2ms/step loss: 0.8581 - binary_accuracy: \n",
      "Validation Macro F1 Score 0.876794978814231\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 0.8565 - binary_accuracy: 0.8717 - val_loss: 0.8341 - val_binary_accuracy: 0.8771\n",
      "Epoch 4/30\n",
      "68/68 [==============================] - 0s 2ms/step loss: 0.8341 - binary_accuracy: \n",
      "Validation Macro F1 Score 0.8805850361687524\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 0.8334 - binary_accuracy: 0.8720 - val_loss: 0.8083 - val_binary_accuracy: 0.8808\n",
      "Epoch 5/30\n",
      "68/68 [==============================] - 0s 3ms/step loss: 0.8218 - binary_accuracy\n",
      "Validation Macro F1 Score 0.8809952366701366\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 0.8218 - binary_accuracy: 0.8732 - val_loss: 0.8009 - val_binary_accuracy: 0.8813\n",
      "Epoch 6/30\n",
      "68/68 [==============================] - 0s 2ms/step loss: 0.8114 - binary_accuracy: \n",
      "Validation Macro F1 Score 0.8783714881229222\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 0.8122 - binary_accuracy: 0.8709 - val_loss: 0.7988 - val_binary_accuracy: 0.8785\n",
      "Epoch 7/30\n",
      "68/68 [==============================] - 0s 2ms/step loss: 0.8094 - binary_accuracy: \n",
      "Validation Macro F1 Score 0.874715909090909\n",
      "Early Stopping\n",
      "191/191 [==============================] - 3s 14ms/step - loss: 0.8089 - binary_accuracy: 0.8720 - val_loss: 0.8065 - val_binary_accuracy: 0.8748\n",
      "Epoch 1/30\n",
      "66/66 [==============================] - 0s 2ms/step loss: 31.0690 - binary_accuracy: \n",
      "Validation Macro F1 Score 0.8538065114219006\n",
      "187/187 [==============================] - 4s 14ms/step - loss: 30.5510 - binary_accuracy: 0.8526 - val_loss: 1.1394 - val_binary_accuracy: 0.8540\n",
      "Epoch 2/30\n",
      "66/66 [==============================] - 0s 2ms/step loss: 0.9141 - binary_accuracy: \n",
      "Validation Macro F1 Score 0.8614547037637309\n",
      "187/187 [==============================] - 2s 13ms/step - loss: 0.9141 - binary_accuracy: 0.8656 - val_loss: 0.8920 - val_binary_accuracy: 0.8616\n",
      "Epoch 3/30\n",
      "66/66 [==============================] - 0s 2ms/step loss: 0.8600 - binary_accuracy: \n",
      "Validation Macro F1 Score 0.8744075443425574\n",
      "187/187 [==============================] - 3s 13ms/step - loss: 0.8596 - binary_accuracy: 0.8657 - val_loss: 0.8321 - val_binary_accuracy: 0.8745\n",
      "Epoch 4/30\n",
      "66/66 [==============================] - 0s 2ms/step loss: 0.8330 - binary_accuracy: \n",
      "Validation Macro F1 Score 0.8782391575747708\n",
      "187/187 [==============================] - 3s 14ms/step - loss: 0.8330 - binary_accuracy: 0.8678 - val_loss: 0.8198 - val_binary_accuracy: 0.8783\n",
      "Epoch 5/30\n",
      "66/66 [==============================] - 0s 2ms/step loss: 0.8238 - binary_accuracy: \n",
      "Validation Macro F1 Score 0.8735139989797875\n",
      "187/187 [==============================] - 3s 13ms/step - loss: 0.8238 - binary_accuracy: 0.8691 - val_loss: 0.8352 - val_binary_accuracy: 0.8735\n",
      "Epoch 6/30\n",
      "66/66 [==============================] - 0s 2ms/step loss: 0.8147 - binary_accuracy: \n",
      "Validation Macro F1 Score 0.871439633389786\n",
      "Early Stopping\n",
      "187/187 [==============================] - 3s 14ms/step - loss: 0.8146 - binary_accuracy: 0.8700 - val_loss: 0.7995 - val_binary_accuracy: 0.8716\n",
      "Epoch 1/30\n",
      "1041/1041 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.8870871272571064\n",
      "2947/2947 [==============================] - 40s 13ms/step - loss: 2.6925 - binary_accuracy: 0.8720 - val_loss: 0.7825 - val_binary_accuracy: 0.8871\n",
      "Epoch 2/30\n",
      "1041/1041 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9093529500652938\n",
      "2947/2947 [==============================] - 40s 14ms/step - loss: 0.7758 - binary_accuracy: 0.8984 - val_loss: 0.7443 - val_binary_accuracy: 0.9094\n",
      "Epoch 3/30\n",
      "1041/1041 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9104860474014214\n",
      "2947/2947 [==============================] - 39s 13ms/step - loss: 0.7596 - binary_accuracy: 0.9042 - val_loss: 0.7498 - val_binary_accuracy: 0.9105\n",
      "Epoch 4/30\n",
      "1041/1041 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9069916635279294\n",
      "2947/2947 [==============================] - 39s 13ms/step - loss: 0.7564 - binary_accuracy: 0.9051 - val_loss: 0.7430 - val_binary_accuracy: 0.9070\n",
      "Epoch 5/30\n",
      "1041/1041 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9105548833731886\n",
      "2947/2947 [==============================] - 39s 13ms/step - loss: 0.7546 - binary_accuracy: 0.9048 - val_loss: 0.7464 - val_binary_accuracy: 0.9106\n",
      "Epoch 6/30\n",
      "1041/1041 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9107605766127249\n",
      "2947/2947 [==============================] - 41s 14ms/step - loss: 0.7512 - binary_accuracy: 0.9054 - val_loss: 0.7402 - val_binary_accuracy: 0.9108\n",
      "Epoch 7/30\n",
      "1041/1041 [==============================] - 3s 2ms/step\n",
      "Validation Macro F1 Score 0.9107185979433942\n",
      "2947/2947 [==============================] - 41s 14ms/step - loss: 0.7511 - binary_accuracy: 0.9061 - val_loss: 0.7366 - val_binary_accuracy: 0.9107\n",
      "Epoch 8/30\n",
      "1041/1041 [==============================] - 3s 3ms/step\n",
      "Validation Macro F1 Score 0.9098637297100818\n",
      "Early Stopping\n",
      "2947/2947 [==============================] - 42s 14ms/step - loss: 0.7509 - binary_accuracy: 0.9054 - val_loss: 0.7374 - val_binary_accuracy: 0.9099\n",
      "Epoch 1/30\n",
      "1247/1247 [==============================] - 3s 3ms/step\n",
      "Validation Macro F1 Score 0.8987693608376214\n",
      "3531/3531 [==============================] - 52s 14ms/step - loss: 2.3702 - binary_accuracy: 0.8743 - val_loss: 0.7632 - val_binary_accuracy: 0.8988\n",
      "Epoch 2/30\n",
      "1247/1247 [==============================] - 3s 2ms/step\n",
      "Validation Macro F1 Score 0.9077140206144135\n",
      "3531/3531 [==============================] - 47s 13ms/step - loss: 0.7609 - binary_accuracy: 0.9017 - val_loss: 0.7378 - val_binary_accuracy: 0.9077\n",
      "Epoch 3/30\n",
      "1247/1247 [==============================] - 3s 2ms/step\n",
      "Validation Macro F1 Score 0.9021321450767621\n",
      "3531/3531 [==============================] - 47s 13ms/step - loss: 0.7518 - binary_accuracy: 0.9035 - val_loss: 0.7644 - val_binary_accuracy: 0.9021\n",
      "Epoch 4/30\n",
      "1247/1247 [==============================] - 3s 3ms/step\n",
      "Validation Macro F1 Score 0.903100685923461\n",
      "Early Stopping\n",
      "3531/3531 [==============================] - 54s 15ms/step - loss: 0.7496 - binary_accuracy: 0.9040 - val_loss: 0.7461 - val_binary_accuracy: 0.9031\n",
      "Epoch 1/30\n",
      "883/883 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.8811296766189078\n",
      "2502/2502 [==============================] - 40s 15ms/step - loss: 3.0284 - binary_accuracy: 0.8696 - val_loss: 0.7790 - val_binary_accuracy: 0.8811\n",
      "Epoch 2/30\n",
      "883/883 [==============================] - 2s 3ms/step\n",
      "Validation Macro F1 Score 0.906010126245473\n",
      "2502/2502 [==============================] - 38s 15ms/step - loss: 0.7779 - binary_accuracy: 0.8957 - val_loss: 0.7532 - val_binary_accuracy: 0.9061\n",
      "Epoch 3/30\n",
      "883/883 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9117892714010379\n",
      "2502/2502 [==============================] - 38s 15ms/step - loss: 0.7623 - binary_accuracy: 0.9025 - val_loss: 0.7465 - val_binary_accuracy: 0.9118\n",
      "Epoch 4/30\n",
      "883/883 [==============================] - 2s 3ms/step\n",
      "Validation Macro F1 Score 0.89777957865005\n",
      "2502/2502 [==============================] - 38s 15ms/step - loss: 0.7593 - binary_accuracy: 0.9031 - val_loss: 0.7611 - val_binary_accuracy: 0.8978\n",
      "Epoch 5/30\n",
      "883/883 [==============================] - 2s 3ms/step\n",
      "Validation Macro F1 Score 0.9078614649692123\n",
      "Early Stopping\n",
      "2502/2502 [==============================] - 38s 15ms/step - loss: 0.7575 - binary_accuracy: 0.9039 - val_loss: 0.7514 - val_binary_accuracy: 0.9079\n",
      "Epoch 1/30\n",
      "682/682 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.8790200333931684\n",
      "1932/1932 [==============================] - 31s 15ms/step - loss: 3.6817 - binary_accuracy: 0.8684 - val_loss: 0.7882 - val_binary_accuracy: 0.8792\n",
      "Epoch 2/30\n",
      "682/682 [==============================] - 2s 3ms/step\n",
      "Validation Macro F1 Score 0.8984954461918878\n",
      "1932/1932 [==============================] - 30s 15ms/step - loss: 0.7976 - binary_accuracy: 0.8780 - val_loss: 0.7749 - val_binary_accuracy: 0.8985\n",
      "Epoch 3/30\n",
      "682/682 [==============================] - 2s 3ms/step\n",
      "Validation Macro F1 Score 0.9035010383101524\n",
      "1932/1932 [==============================] - 29s 15ms/step - loss: 0.7732 - binary_accuracy: 0.8992 - val_loss: 0.7522 - val_binary_accuracy: 0.9035\n",
      "Epoch 4/30\n",
      "682/682 [==============================] - 2s 3ms/step\n",
      "Validation Macro F1 Score 0.9060675486116904\n",
      "1932/1932 [==============================] - 30s 15ms/step - loss: 0.7592 - binary_accuracy: 0.9017 - val_loss: 0.7483 - val_binary_accuracy: 0.9061\n",
      "Epoch 5/30\n",
      "682/682 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9047444080705223\n",
      "1932/1932 [==============================] - 29s 15ms/step - loss: 0.7555 - binary_accuracy: 0.9023 - val_loss: 0.7430 - val_binary_accuracy: 0.9047\n",
      "Epoch 6/30\n",
      "682/682 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9067597802384347\n",
      "1932/1932 [==============================] - 29s 15ms/step - loss: 0.7534 - binary_accuracy: 0.9036 - val_loss: 0.7470 - val_binary_accuracy: 0.9068\n",
      "Epoch 7/30\n",
      "682/682 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.8987060212454303\n",
      "1932/1932 [==============================] - 29s 15ms/step - loss: 0.7535 - binary_accuracy: 0.9033 - val_loss: 0.7660 - val_binary_accuracy: 0.8987\n",
      "Epoch 8/30\n",
      "682/682 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9094096112340518\n",
      "1932/1932 [==============================] - 29s 15ms/step - loss: 0.7516 - binary_accuracy: 0.9043 - val_loss: 0.7447 - val_binary_accuracy: 0.9094\n",
      "Epoch 9/30\n",
      "682/682 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9069848205006683\n",
      "1932/1932 [==============================] - 29s 15ms/step - loss: 0.7516 - binary_accuracy: 0.9035 - val_loss: 0.7461 - val_binary_accuracy: 0.9070\n",
      "Epoch 10/30\n",
      "682/682 [==============================] - 1s 2ms/step\n",
      "Validation Macro F1 Score 0.9036236731988255\n",
      "Early Stopping\n",
      "1932/1932 [==============================] - 25s 13ms/step - loss: 0.7514 - binary_accuracy: 0.9035 - val_loss: 0.7493 - val_binary_accuracy: 0.9036\n",
      "Epoch 1/30\n",
      "209/209 [==============================] - 1s 2ms/steposs: 10.2472 - binary\n",
      "Validation Macro F1 Score 0.8685992119892774\n",
      "591/591 [==============================] - 9s 13ms/step - loss: 10.2075 - binary_accuracy: 0.8635 - val_loss: 0.8337 - val_binary_accuracy: 0.8687\n",
      "Epoch 2/30\n",
      "209/209 [==============================] - 0s 2ms/steposs: 0.8205 - binar\n",
      "Validation Macro F1 Score 0.8689582678405228\n",
      "591/591 [==============================] - 8s 13ms/step - loss: 0.8202 - binary_accuracy: 0.8711 - val_loss: 0.8116 - val_binary_accuracy: 0.8691\n",
      "Epoch 3/30\n",
      "209/209 [==============================] - 0s 2ms/steposs: 0.8036 - binar\n",
      "Validation Macro F1 Score 0.8761583114253579\n",
      "591/591 [==============================] - 8s 13ms/step - loss: 0.8040 - binary_accuracy: 0.8724 - val_loss: 0.7986 - val_binary_accuracy: 0.8762\n",
      "Epoch 4/30\n",
      "209/209 [==============================] - 0s 2ms/steposs: 0.8004 - binar\n",
      "Validation Macro F1 Score 0.8738895697472195\n",
      "591/591 [==============================] - 8s 13ms/step - loss: 0.8005 - binary_accuracy: 0.8734 - val_loss: 0.7998 - val_binary_accuracy: 0.8739\n",
      "Epoch 5/30\n",
      "209/209 [==============================] - 0s 2ms/steposs: 0.7993 - binar\n",
      "Validation Macro F1 Score 0.8845559669902759\n",
      "591/591 [==============================] - 8s 13ms/step - loss: 0.7991 - binary_accuracy: 0.8763 - val_loss: 0.7895 - val_binary_accuracy: 0.8846\n",
      "Epoch 6/30\n",
      "209/209 [==============================] - 0s 2ms/steposs: 0.7992 - binar\n",
      "Validation Macro F1 Score 0.8792092109244716\n",
      "591/591 [==============================] - 8s 14ms/step - loss: 0.7991 - binary_accuracy: 0.8851 - val_loss: 0.8080 - val_binary_accuracy: 0.8793\n",
      "Epoch 7/30\n",
      "209/209 [==============================] - 0s 2ms/steposs: 0.7942 - binar\n",
      "Validation Macro F1 Score 0.893083547241103\n",
      "591/591 [==============================] - 8s 13ms/step - loss: 0.7943 - binary_accuracy: 0.8908 - val_loss: 0.7906 - val_binary_accuracy: 0.8931\n",
      "Epoch 8/30\n",
      "209/209 [==============================] - 1s 2ms/steposs: 0.7793 - bin\n",
      "Validation Macro F1 Score 0.8960710545708412\n",
      "591/591 [==============================] - 8s 13ms/step - loss: 0.7791 - binary_accuracy: 0.8986 - val_loss: 0.7792 - val_binary_accuracy: 0.8961\n",
      "Epoch 9/30\n",
      "209/209 [==============================] - 0s 2ms/steposs: 0.7721 - binar\n",
      "Validation Macro F1 Score 0.9011200076376991\n",
      "591/591 [==============================] - 8s 13ms/step - loss: 0.7719 - binary_accuracy: 0.9015 - val_loss: 0.7663 - val_binary_accuracy: 0.9012\n",
      "Epoch 10/30\n",
      "209/209 [==============================] - 0s 2ms/steposs: 0.7665 - binar\n",
      "Validation Macro F1 Score 0.900129236529648\n",
      "591/591 [==============================] - 8s 13ms/step - loss: 0.7665 - binary_accuracy: 0.9028 - val_loss: 0.7628 - val_binary_accuracy: 0.9001\n",
      "Epoch 11/30\n",
      "209/209 [==============================] - 0s 2ms/steposs: 0.7616 - binar\n",
      "Validation Macro F1 Score 0.900831285064479\n",
      "Early Stopping\n",
      "591/591 [==============================] - 7s 13ms/step - loss: 0.7616 - binary_accuracy: 0.9037 - val_loss: 0.7511 - val_binary_accuracy: 0.9009\n",
      "Epoch 1/30\n",
      "323/323 [==============================] - 1s 2ms/steposs: 6.884\n",
      "Validation Macro F1 Score 0.8650103778094633\n",
      "914/914 [==============================] - 13s 13ms/step - loss: 6.8659 - binary_accuracy: 0.8689 - val_loss: 0.8532 - val_binary_accuracy: 0.8650\n",
      "Epoch 2/30\n",
      "323/323 [==============================] - 1s 2ms/steposs: 0.80\n",
      "Validation Macro F1 Score 0.873809379552695\n",
      "914/914 [==============================] - 12s 13ms/step - loss: 0.8008 - binary_accuracy: 0.8725 - val_loss: 0.7999 - val_binary_accuracy: 0.8739\n",
      "Epoch 3/30\n",
      "323/323 [==============================] - 1s 2ms/steposs: 0.79\n",
      "Validation Macro F1 Score 0.8750701533554581\n",
      "914/914 [==============================] - 12s 13ms/step - loss: 0.7932 - binary_accuracy: 0.8761 - val_loss: 0.7936 - val_binary_accuracy: 0.8751\n",
      "Epoch 4/30\n",
      "323/323 [==============================] - 1s 3ms/steposs: \n",
      "Validation Macro F1 Score 0.8933181972143647\n",
      "914/914 [==============================] - 12s 13ms/step - loss: 0.7893 - binary_accuracy: 0.8852 - val_loss: 0.7833 - val_binary_accuracy: 0.8933\n",
      "Epoch 5/30\n",
      "323/323 [==============================] - 1s 2ms/steposs: 0.77\n",
      "Validation Macro F1 Score 0.899406818238156\n",
      "914/914 [==============================] - 12s 13ms/step - loss: 0.7756 - binary_accuracy: 0.8977 - val_loss: 0.7618 - val_binary_accuracy: 0.8994\n",
      "Epoch 6/30\n",
      "323/323 [==============================] - 1s 2ms/steposs: 0.76\n",
      "Validation Macro F1 Score 0.8999768537456476\n",
      "914/914 [==============================] - 12s 13ms/step - loss: 0.7631 - binary_accuracy: 0.9024 - val_loss: 0.7652 - val_binary_accuracy: 0.9000\n",
      "Epoch 7/30\n",
      "323/323 [==============================] - 1s 3ms/stepo\n",
      "Validation Macro F1 Score 0.9026899728531059\n",
      "914/914 [==============================] - 12s 14ms/step - loss: 0.7583 - binary_accuracy: 0.9040 - val_loss: 0.7590 - val_binary_accuracy: 0.9027\n",
      "Epoch 8/30\n",
      "323/323 [==============================] - 1s 2ms/steposs: 0.75\n",
      "Validation Macro F1 Score 0.8989225517909889\n",
      "914/914 [==============================] - 13s 15ms/step - loss: 0.7567 - binary_accuracy: 0.9052 - val_loss: 0.7870 - val_binary_accuracy: 0.8990\n",
      "Epoch 9/30\n",
      "323/323 [==============================] - 1s 2ms/steposs: 0.75\n",
      "Validation Macro F1 Score 0.9090203207672806\n",
      "914/914 [==============================] - 12s 13ms/step - loss: 0.7538 - binary_accuracy: 0.9054 - val_loss: 0.7505 - val_binary_accuracy: 0.9090\n",
      "Epoch 10/30\n",
      "323/323 [==============================] - 1s 2ms/steposs: 0.75\n",
      "Validation Macro F1 Score 0.9095926031026016\n",
      "914/914 [==============================] - 12s 13ms/step - loss: 0.7539 - binary_accuracy: 0.9043 - val_loss: 0.7425 - val_binary_accuracy: 0.9096\n",
      "Epoch 11/30\n",
      "323/323 [==============================] - 1s 2ms/steposs: 0.75\n",
      "Validation Macro F1 Score 0.90776068105447\n",
      "914/914 [==============================] - 12s 13ms/step - loss: 0.7532 - binary_accuracy: 0.9054 - val_loss: 0.7480 - val_binary_accuracy: 0.9078\n",
      "Epoch 12/30\n",
      "323/323 [==============================] - 1s 2ms/steposs: 0.\n",
      "Validation Macro F1 Score 0.9056183828256912\n",
      "Early Stopping\n",
      "914/914 [==============================] - 12s 13ms/step - loss: 0.7497 - binary_accuracy: 0.9065 - val_loss: 0.7459 - val_binary_accuracy: 0.9056\n",
      "Epoch 1/30\n",
      "266/266 [==============================] - 1s 2ms/steposs: 8.2261 - \n",
      "Validation Macro F1 Score 0.8678474895630863\n",
      "752/752 [==============================] - 12s 14ms/step - loss: 8.2235 - binary_accuracy: 0.8661 - val_loss: 0.8144 - val_binary_accuracy: 0.8679\n",
      "Epoch 2/30\n",
      "266/266 [==============================] - 1s 2ms/steposs: 0.8110 -\n",
      "Validation Macro F1 Score 0.8645109101990134\n",
      "752/752 [==============================] - 10s 13ms/step - loss: 0.8110 - binary_accuracy: 0.8700 - val_loss: 0.8050 - val_binary_accuracy: 0.8647\n",
      "Epoch 3/30\n",
      "266/266 [==============================] - 1s 2ms/steposs: 0.7963 -\n",
      "Validation Macro F1 Score 0.8709105498399349\n",
      "752/752 [==============================] - 10s 13ms/step - loss: 0.7962 - binary_accuracy: 0.8727 - val_loss: 0.7902 - val_binary_accuracy: 0.8711\n",
      "Epoch 4/30\n",
      "266/266 [==============================] - 1s 2ms/steposs: 0.7954 -\n",
      "Validation Macro F1 Score 0.8769223988968402\n",
      "752/752 [==============================] - 10s 13ms/step - loss: 0.7954 - binary_accuracy: 0.8749 - val_loss: 0.7990 - val_binary_accuracy: 0.8770\n",
      "Epoch 5/30\n",
      "266/266 [==============================] - 1s 2ms/steposs: 0.7944 -\n",
      "Validation Macro F1 Score 0.8814871815533256\n",
      "752/752 [==============================] - 10s 13ms/step - loss: 0.7943 - binary_accuracy: 0.8852 - val_loss: 0.7853 - val_binary_accuracy: 0.8816\n",
      "Epoch 6/30\n",
      "266/266 [==============================] - 1s 2ms/steposs: 0.7835 -\n",
      "Validation Macro F1 Score 0.8982875700287772\n",
      "752/752 [==============================] - 10s 13ms/step - loss: 0.7834 - binary_accuracy: 0.8935 - val_loss: 0.7706 - val_binary_accuracy: 0.8983\n",
      "Epoch 7/30\n",
      "266/266 [==============================] - 1s 2ms/steposs: 0.7691 -\n",
      "Validation Macro F1 Score 0.8985266710766875\n",
      "752/752 [==============================] - 10s 13ms/step - loss: 0.7692 - binary_accuracy: 0.9003 - val_loss: 0.7768 - val_binary_accuracy: 0.8985\n",
      "Epoch 8/30\n",
      "266/266 [==============================] - 1s 2ms/steposs: 0.7657 -\n",
      "Validation Macro F1 Score 0.8992918593821002\n",
      "752/752 [==============================] - 10s 13ms/step - loss: 0.7657 - binary_accuracy: 0.9019 - val_loss: 0.7630 - val_binary_accuracy: 0.8994\n",
      "Epoch 9/30\n",
      "266/266 [==============================] - 1s 2ms/steposs: 0.7659 - b\n",
      "Validation Macro F1 Score 0.9047344367583441\n",
      "752/752 [==============================] - 10s 13ms/step - loss: 0.7659 - binary_accuracy: 0.9012 - val_loss: 0.7626 - val_binary_accuracy: 0.9048\n",
      "Epoch 10/30\n",
      "266/266 [==============================] - 1s 2ms/steposs: 0.7627 -\n",
      "Validation Macro F1 Score 0.8984560424720818\n",
      "752/752 [==============================] - 10s 13ms/step - loss: 0.7628 - binary_accuracy: 0.9027 - val_loss: 0.7649 - val_binary_accuracy: 0.8985\n",
      "Epoch 11/30\n",
      "266/266 [==============================] - 1s 2ms/steposs: 0.7641 -\n",
      "Validation Macro F1 Score 0.9055745641030087\n",
      "752/752 [==============================] - 10s 13ms/step - loss: 0.7639 - binary_accuracy: 0.9031 - val_loss: 0.7589 - val_binary_accuracy: 0.9056\n",
      "Epoch 12/30\n",
      "266/266 [==============================] - 1s 2ms/steposs: 0.7606 -\n",
      "Validation Macro F1 Score 0.904533970035597\n",
      "752/752 [==============================] - 10s 13ms/step - loss: 0.7605 - binary_accuracy: 0.9038 - val_loss: 0.7551 - val_binary_accuracy: 0.9045\n",
      "Epoch 13/30\n",
      "266/266 [==============================] - 1s 2ms/steposs: 0.7619 -\n",
      "Validation Macro F1 Score 0.9078373587670205\n",
      "752/752 [==============================] - 10s 13ms/step - loss: 0.7617 - binary_accuracy: 0.9042 - val_loss: 0.7602 - val_binary_accuracy: 0.9078\n",
      "Epoch 14/30\n",
      "266/266 [==============================] - 1s 2ms/steposs: 0.7596 - b\n",
      "Validation Macro F1 Score 0.8968010138677058\n",
      "752/752 [==============================] - 10s 13ms/step - loss: 0.7595 - binary_accuracy: 0.9038 - val_loss: 0.7669 - val_binary_accuracy: 0.8969\n",
      "Epoch 15/30\n",
      "266/266 [==============================] - 1s 2ms/steposs: 0.7580 - b\n",
      "Validation Macro F1 Score 0.9061804451002402\n",
      "Early Stopping\n",
      "752/752 [==============================] - 10s 13ms/step - loss: 0.7580 - binary_accuracy: 0.9041 - val_loss: 0.7529 - val_binary_accuracy: 0.9062\n",
      "Epoch 1/30\n",
      "1241/1241 [==============================] - 3s 2ms/step\n",
      "Validation Macro F1 Score 0.8952717466250191\n",
      "3515/3515 [==============================] - 50s 14ms/step - loss: 2.3775 - binary_accuracy: 0.8773 - val_loss: 0.7818 - val_binary_accuracy: 0.8953\n",
      "Epoch 2/30\n",
      "1241/1241 [==============================] - 3s 2ms/step\n",
      "Validation Macro F1 Score 0.9108706751736149\n",
      "3515/3515 [==============================] - 49s 14ms/step - loss: 0.7625 - binary_accuracy: 0.9017 - val_loss: 0.7460 - val_binary_accuracy: 0.9109\n",
      "Epoch 3/30\n",
      "1241/1241 [==============================] - 3s 2ms/step\n",
      "Validation Macro F1 Score 0.9057083400940684\n",
      "3515/3515 [==============================] - 47s 13ms/step - loss: 0.7506 - binary_accuracy: 0.9050 - val_loss: 0.7585 - val_binary_accuracy: 0.9057\n",
      "Epoch 4/30\n",
      "1241/1241 [==============================] - 3s 2ms/step\n",
      "Validation Macro F1 Score 0.9066908502266633\n",
      "Early Stopping\n",
      "3515/3515 [==============================] - 46s 13ms/step - loss: 0.7480 - binary_accuracy: 0.9053 - val_loss: 0.7465 - val_binary_accuracy: 0.9067\n",
      "Epoch 1/30\n",
      "868/868 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.8754842596532633\n",
      "2458/2458 [==============================] - 33s 13ms/step - loss: 3.0621 - binary_accuracy: 0.8704 - val_loss: 0.7890 - val_binary_accuracy: 0.8755\n",
      "Epoch 2/30\n",
      "868/868 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9036985863217597\n",
      "2458/2458 [==============================] - 32s 13ms/step - loss: 0.7878 - binary_accuracy: 0.8904 - val_loss: 0.7597 - val_binary_accuracy: 0.9037\n",
      "Epoch 3/30\n",
      "868/868 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9064296404634591\n",
      "2458/2458 [==============================] - 32s 13ms/step - loss: 0.7650 - binary_accuracy: 0.9024 - val_loss: 0.7521 - val_binary_accuracy: 0.9064\n",
      "Epoch 4/30\n",
      "868/868 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9020935175711924\n",
      "2458/2458 [==============================] - 32s 13ms/step - loss: 0.7576 - binary_accuracy: 0.9030 - val_loss: 0.7647 - val_binary_accuracy: 0.9022\n",
      "Epoch 5/30\n",
      "868/868 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.902596725926829\n",
      "Early Stopping\n",
      "2458/2458 [==============================] - 32s 13ms/step - loss: 0.7575 - binary_accuracy: 0.9026 - val_loss: 0.7533 - val_binary_accuracy: 0.9026\n",
      "Epoch 1/30\n",
      "187/187 [==============================] - 0s 2ms/steposs: 11.3057 - binary_a\n",
      "Validation Macro F1 Score 0.8563960656289121\n",
      "529/529 [==============================] - 8s 13ms/step - loss: 11.2833 - binary_accuracy: 0.8603 - val_loss: 0.8911 - val_binary_accuracy: 0.8572\n",
      "Epoch 2/30\n",
      "187/187 [==============================] - 0s 2ms/steposs: 0.8366 - binary_\n",
      "Validation Macro F1 Score 0.8728621923309312\n",
      "529/529 [==============================] - 7s 13ms/step - loss: 0.8367 - binary_accuracy: 0.8711 - val_loss: 0.8220 - val_binary_accuracy: 0.8729\n",
      "Epoch 3/30\n",
      "187/187 [==============================] - 0s 2ms/steposs: 0.8159 - binary_\n",
      "Validation Macro F1 Score 0.8660663110374727\n",
      "529/529 [==============================] - 7s 13ms/step - loss: 0.8157 - binary_accuracy: 0.8715 - val_loss: 0.8150 - val_binary_accuracy: 0.8664\n",
      "Epoch 4/30\n",
      "187/187 [==============================] - 0s 2ms/steposs: 0.8071 - binary_\n",
      "Validation Macro F1 Score 0.8717680758148747\n",
      "Early Stopping\n",
      "529/529 [==============================] - 7s 13ms/step - loss: 0.8071 - binary_accuracy: 0.8723 - val_loss: 0.8144 - val_binary_accuracy: 0.8719\n",
      "Epoch 1/30\n",
      "424/424 [==============================] - 1s 2ms/step l\n",
      "Validation Macro F1 Score 0.8747304226505637\n",
      "1200/1200 [==============================] - 17s 13ms/step - loss: 5.4290 - binary_accuracy: 0.8702 - val_loss: 0.8016 - val_binary_accuracy: 0.8747\n",
      "Epoch 2/30\n",
      "424/424 [==============================] - 1s 2ms/step lo\n",
      "Validation Macro F1 Score 0.8766348760978733\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 0.7982 - binary_accuracy: 0.8748 - val_loss: 0.7949 - val_binary_accuracy: 0.8767\n",
      "Epoch 3/30\n",
      "424/424 [==============================] - 1s 2ms/step lo\n",
      "Validation Macro F1 Score 0.8981969820382062\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 0.7952 - binary_accuracy: 0.8842 - val_loss: 0.7735 - val_binary_accuracy: 0.8983\n",
      "Epoch 4/30\n",
      "424/424 [==============================] - 1s 2ms/step loss\n",
      "Validation Macro F1 Score 0.906579169836784\n",
      "1200/1200 [==============================] - 15s 13ms/step - loss: 0.7701 - binary_accuracy: 0.9011 - val_loss: 0.7622 - val_binary_accuracy: 0.9066\n",
      "Epoch 5/30\n",
      "424/424 [==============================] - 1s 2ms/step lo\n",
      "Validation Macro F1 Score 0.9073401667697526\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 0.7611 - binary_accuracy: 0.9040 - val_loss: 0.7641 - val_binary_accuracy: 0.9074\n",
      "Epoch 6/30\n",
      "424/424 [==============================] - 1s 2ms/step loss\n",
      "Validation Macro F1 Score 0.9080133783408086\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 0.7563 - binary_accuracy: 0.9058 - val_loss: 0.7550 - val_binary_accuracy: 0.9080\n",
      "Epoch 7/30\n",
      "424/424 [==============================] - 1s 2ms/step lo\n",
      "Validation Macro F1 Score 0.9034284607837759\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 0.7528 - binary_accuracy: 0.9067 - val_loss: 0.7525 - val_binary_accuracy: 0.9034\n",
      "Epoch 8/30\n",
      "424/424 [==============================] - 1s 2ms/step lo\n",
      "Validation Macro F1 Score 0.9057947433403435\n",
      "Early Stopping\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 0.7528 - binary_accuracy: 0.9062 - val_loss: 0.7572 - val_binary_accuracy: 0.9058\n",
      "Epoch 1/30\n",
      "129/129 [==============================] - 0s 2ms/steposs: 16.0670 - binary_accu\n",
      "Validation Macro F1 Score 0.8740249746374809\n",
      "364/364 [==============================] - 6s 14ms/step - loss: 16.0670 - binary_accuracy: 0.8609 - val_loss: 0.8715 - val_binary_accuracy: 0.8740\n",
      "Epoch 2/30\n",
      "129/129 [==============================] - 0s 2ms/steposs: 0.8472 - binary_accu\n",
      "Validation Macro F1 Score 0.8712385818388995\n",
      "364/364 [==============================] - 5s 13ms/step - loss: 0.8473 - binary_accuracy: 0.8690 - val_loss: 0.8248 - val_binary_accuracy: 0.8713\n",
      "Epoch 3/30\n",
      "129/129 [==============================] - 0s 2ms/steposs: 0.8203 - binary_accu\n",
      "Validation Macro F1 Score 0.8730188291882617\n",
      "Early Stopping\n",
      "364/364 [==============================] - 5s 13ms/step - loss: 0.8205 - binary_accuracy: 0.8707 - val_loss: 0.8172 - val_binary_accuracy: 0.8731\n",
      "Epoch 1/30\n",
      "1145/1145 [==============================] - 3s 2ms/step\n",
      "Validation Macro F1 Score 0.8803227767936159\n",
      "3243/3243 [==============================] - 45s 13ms/step - loss: 2.5204 - binary_accuracy: 0.8710 - val_loss: 0.7796 - val_binary_accuracy: 0.8804\n",
      "Epoch 2/30\n",
      "1145/1145 [==============================] - 3s 2ms/step\n",
      "Validation Macro F1 Score 0.9071092645953889\n",
      "3243/3243 [==============================] - 43s 13ms/step - loss: 0.7735 - binary_accuracy: 0.8976 - val_loss: 0.7467 - val_binary_accuracy: 0.9071\n",
      "Epoch 3/30\n",
      "1145/1145 [==============================] - 3s 2ms/step\n",
      "Validation Macro F1 Score 0.9093296360984762\n",
      "3243/3243 [==============================] - 43s 13ms/step - loss: 0.7592 - binary_accuracy: 0.9024 - val_loss: 0.7493 - val_binary_accuracy: 0.9093\n",
      "Epoch 4/30\n",
      "1145/1145 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.8899190480342606\n",
      "3243/3243 [==============================] - 42s 13ms/step - loss: 0.7570 - binary_accuracy: 0.9030 - val_loss: 0.7793 - val_binary_accuracy: 0.8904\n",
      "Epoch 5/30\n",
      "1145/1145 [==============================] - 3s 2ms/step\n",
      "Validation Macro F1 Score 0.9063840535950431\n",
      "Early Stopping\n",
      "3243/3243 [==============================] - 43s 13ms/step - loss: 0.7554 - binary_accuracy: 0.9030 - val_loss: 0.7436 - val_binary_accuracy: 0.9064\n",
      "Epoch 1/30\n",
      "250/250 [==============================] - 1s 2ms/steposs: 8.6846 - bi\n",
      "Validation Macro F1 Score 0.8772793470984854\n",
      "708/708 [==============================] - 11s 14ms/step - loss: 8.6492 - binary_accuracy: 0.8640 - val_loss: 0.8270 - val_binary_accuracy: 0.8773\n",
      "Epoch 2/30\n",
      "250/250 [==============================] - 1s 2ms/steposs: 0.8213 -\n",
      "Validation Macro F1 Score 0.8778133471919266\n",
      "708/708 [==============================] - 9s 13ms/step - loss: 0.8212 - binary_accuracy: 0.8700 - val_loss: 0.8036 - val_binary_accuracy: 0.8778\n",
      "Epoch 3/30\n",
      "250/250 [==============================] - 1s 2ms/steposs: 0.8038 - b\n",
      "Validation Macro F1 Score 0.8781324529925177\n",
      "708/708 [==============================] - 9s 13ms/step - loss: 0.8038 - binary_accuracy: 0.8722 - val_loss: 0.7816 - val_binary_accuracy: 0.8782\n",
      "Epoch 4/30\n",
      "250/250 [==============================] - 1s 2ms/steposs: 0.7967 - b\n",
      "Validation Macro F1 Score 0.8847505935321851\n",
      "708/708 [==============================] - 10s 14ms/step - loss: 0.7966 - binary_accuracy: 0.8765 - val_loss: 0.7782 - val_binary_accuracy: 0.8848\n",
      "Epoch 5/30\n",
      "250/250 [==============================] - 1s 2ms/steposs: 0.7857 - b\n",
      "Validation Macro F1 Score 0.9018513948040132\n",
      "708/708 [==============================] - 10s 13ms/step - loss: 0.7856 - binary_accuracy: 0.8935 - val_loss: 0.7619 - val_binary_accuracy: 0.9019\n",
      "Epoch 6/30\n",
      "250/250 [==============================] - 1s 2ms/steposs: 0.7721 - b\n",
      "Validation Macro F1 Score 0.8823842253947434\n",
      "708/708 [==============================] - 10s 14ms/step - loss: 0.7720 - binary_accuracy: 0.9005 - val_loss: 0.7954 - val_binary_accuracy: 0.8831\n",
      "Epoch 7/30\n",
      "250/250 [==============================] - 1s 2ms/steposs: 0.7642 - b\n",
      "Validation Macro F1 Score 0.8895691874045466\n",
      "Early Stopping\n",
      "708/708 [==============================] - 10s 14ms/step - loss: 0.7642 - binary_accuracy: 0.9028 - val_loss: 0.7755 - val_binary_accuracy: 0.8901\n",
      "Epoch 1/30\n",
      "716/716 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.8765728151671319\n",
      "2029/2029 [==============================] - 29s 14ms/step - loss: 3.5503 - binary_accuracy: 0.8700 - val_loss: 0.7888 - val_binary_accuracy: 0.8766\n",
      "Epoch 2/30\n",
      "716/716 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.8976963880980221\n",
      "2029/2029 [==============================] - 27s 13ms/step - loss: 0.7957 - binary_accuracy: 0.8846 - val_loss: 0.7759 - val_binary_accuracy: 0.8978\n",
      "Epoch 3/30\n",
      "716/716 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9065581102040381\n",
      "2029/2029 [==============================] - 27s 13ms/step - loss: 0.7666 - binary_accuracy: 0.9026 - val_loss: 0.7517 - val_binary_accuracy: 0.9066\n",
      "Epoch 4/30\n",
      "716/716 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9084447093758314\n",
      "2029/2029 [==============================] - 27s 13ms/step - loss: 0.7578 - binary_accuracy: 0.9048 - val_loss: 0.7478 - val_binary_accuracy: 0.9084\n",
      "Epoch 5/30\n",
      "716/716 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9047783532045981\n",
      "2029/2029 [==============================] - 27s 13ms/step - loss: 0.7553 - binary_accuracy: 0.9058 - val_loss: 0.7495 - val_binary_accuracy: 0.9048\n",
      "Epoch 6/30\n",
      "716/716 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9002708767740453\n",
      "Early Stopping\n",
      "2029/2029 [==============================] - 27s 13ms/step - loss: 0.7541 - binary_accuracy: 0.9057 - val_loss: 0.7590 - val_binary_accuracy: 0.9004\n",
      "Epoch 1/30\n",
      "990/990 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.8833501285057646\n",
      "2804/2804 [==============================] - 39s 13ms/step - loss: 2.7849 - binary_accuracy: 0.8728 - val_loss: 0.8017 - val_binary_accuracy: 0.8834\n",
      "Epoch 2/30\n",
      "990/990 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9039133601793002\n",
      "2804/2804 [==============================] - 38s 14ms/step - loss: 0.7761 - binary_accuracy: 0.8987 - val_loss: 0.7641 - val_binary_accuracy: 0.9039\n",
      "Epoch 3/30\n",
      "990/990 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9057404138030911\n",
      "2804/2804 [==============================] - 37s 13ms/step - loss: 0.7634 - binary_accuracy: 0.9032 - val_loss: 0.7578 - val_binary_accuracy: 0.9057\n",
      "Epoch 4/30\n",
      "990/990 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9010435350454205\n",
      "2804/2804 [==============================] - 37s 13ms/step - loss: 0.7608 - binary_accuracy: 0.9027 - val_loss: 0.7561 - val_binary_accuracy: 0.9011\n",
      "Epoch 5/30\n",
      "990/990 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9063088604036096\n",
      "2804/2804 [==============================] - 38s 14ms/step - loss: 0.7589 - binary_accuracy: 0.9034 - val_loss: 0.7569 - val_binary_accuracy: 0.9063\n",
      "Epoch 6/30\n",
      "990/990 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9063365084800945\n",
      "2804/2804 [==============================] - 37s 13ms/step - loss: 0.7585 - binary_accuracy: 0.9034 - val_loss: 0.7579 - val_binary_accuracy: 0.9063\n",
      "Epoch 7/30\n",
      "990/990 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9012894689786072\n",
      "2804/2804 [==============================] - 37s 13ms/step - loss: 0.7570 - binary_accuracy: 0.9035 - val_loss: 0.7574 - val_binary_accuracy: 0.9014\n",
      "Epoch 8/30\n",
      "990/990 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.901735211594077\n",
      "Early Stopping\n",
      "2804/2804 [==============================] - 37s 13ms/step - loss: 0.7568 - binary_accuracy: 0.9041 - val_loss: 0.7724 - val_binary_accuracy: 0.9018\n",
      "Epoch 1/30\n",
      "768/768 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.8778027716253747\n",
      "2176/2176 [==============================] - 31s 14ms/step - loss: 3.3573 - binary_accuracy: 0.8713 - val_loss: 0.7889 - val_binary_accuracy: 0.8778\n",
      "Epoch 2/30\n",
      "768/768 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9000099028117567\n",
      "2176/2176 [==============================] - 30s 14ms/step - loss: 0.7872 - binary_accuracy: 0.8891 - val_loss: 0.7625 - val_binary_accuracy: 0.9000\n",
      "Epoch 3/30\n",
      "768/768 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.8995959299737539\n",
      "2176/2176 [==============================] - 28s 13ms/step - loss: 0.7617 - binary_accuracy: 0.9037 - val_loss: 0.7700 - val_binary_accuracy: 0.8997\n",
      "Epoch 4/30\n",
      "768/768 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.905706960090297\n",
      "2176/2176 [==============================] - 29s 13ms/step - loss: 0.7577 - binary_accuracy: 0.9047 - val_loss: 0.7510 - val_binary_accuracy: 0.9057\n",
      "Epoch 5/30\n",
      "768/768 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9069301925556599\n",
      "2176/2176 [==============================] - 29s 13ms/step - loss: 0.7556 - binary_accuracy: 0.9054 - val_loss: 0.7479 - val_binary_accuracy: 0.9069\n",
      "Epoch 6/30\n",
      "768/768 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9034012895023649\n",
      "2176/2176 [==============================] - 29s 14ms/step - loss: 0.7529 - binary_accuracy: 0.9057 - val_loss: 0.7627 - val_binary_accuracy: 0.9034\n",
      "Epoch 7/30\n",
      "768/768 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9074443899465983\n",
      "2176/2176 [==============================] - 29s 14ms/step - loss: 0.7508 - binary_accuracy: 0.9075 - val_loss: 0.7484 - val_binary_accuracy: 0.9075\n",
      "Epoch 8/30\n",
      "768/768 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9075406680348541\n",
      "2176/2176 [==============================] - 29s 13ms/step - loss: 0.7523 - binary_accuracy: 0.9061 - val_loss: 0.7465 - val_binary_accuracy: 0.9075\n",
      "Epoch 9/30\n",
      "768/768 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9064219452948672\n",
      "2176/2176 [==============================] - 29s 13ms/step - loss: 0.7486 - binary_accuracy: 0.9063 - val_loss: 0.7565 - val_binary_accuracy: 0.9064\n",
      "Epoch 10/30\n",
      "768/768 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9002556122809684\n",
      "Early Stopping\n",
      "2176/2176 [==============================] - 29s 14ms/step - loss: 0.7492 - binary_accuracy: 0.9071 - val_loss: 0.7556 - val_binary_accuracy: 0.9003\n",
      "Epoch 1/30\n",
      "134/134 [==============================] - 0s 2ms/steposs: 15.5479 - binary_accu\n",
      "Validation Macro F1 Score 0.8712874279337921\n",
      "378/378 [==============================] - 6s 14ms/step - loss: 15.4670 - binary_accuracy: 0.8580 - val_loss: 0.8754 - val_binary_accuracy: 0.8718\n",
      "Epoch 2/30\n",
      "134/134 [==============================] - 0s 2ms/steposs: 0.8449 - binary_ac\n",
      "Validation Macro F1 Score 0.8746488099586642\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.8447 - binary_accuracy: 0.8699 - val_loss: 0.8118 - val_binary_accuracy: 0.8749\n",
      "Epoch 3/30\n",
      "134/134 [==============================] - 0s 3ms/steposs: 0.8225 - binary_\n",
      "Validation Macro F1 Score 0.8750997490926139\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.8220 - binary_accuracy: 0.8699 - val_loss: 0.8001 - val_binary_accuracy: 0.8753\n",
      "Epoch 4/30\n",
      "134/134 [==============================] - 0s 2ms/steposs: 0.8120 - binary_accu\n",
      "Validation Macro F1 Score 0.8700706422100846\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.8119 - binary_accuracy: 0.8719 - val_loss: 0.8068 - val_binary_accuracy: 0.8702\n",
      "Epoch 5/30\n",
      "134/134 [==============================] - 0s 2ms/steposs: 0.8074 - binary_ac\n",
      "Validation Macro F1 Score 0.8841591945105342\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.8074 - binary_accuracy: 0.8736 - val_loss: 0.7900 - val_binary_accuracy: 0.8842\n",
      "Epoch 6/30\n",
      "134/134 [==============================] - 0s 2ms/steposs: 0.8002 - binary_ac\n",
      "Validation Macro F1 Score 0.8850492320658756\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.8001 - binary_accuracy: 0.8762 - val_loss: 0.7971 - val_binary_accuracy: 0.8852\n",
      "Epoch 7/30\n",
      "134/134 [==============================] - 0s 2ms/steposs: 0.7981 - binary_ac\n",
      "Validation Macro F1 Score 0.891003466423592\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.7981 - binary_accuracy: 0.8844 - val_loss: 0.8208 - val_binary_accuracy: 0.8913\n",
      "Epoch 8/30\n",
      "134/134 [==============================] - 0s 2ms/steposs: 0.7956 - binary_ac\n",
      "Validation Macro F1 Score 0.9095897157409112\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.7955 - binary_accuracy: 0.8908 - val_loss: 0.7614 - val_binary_accuracy: 0.9096\n",
      "Epoch 9/30\n",
      "134/134 [==============================] - 0s 2ms/steposs: 0.7794 - binary_ac\n",
      "Validation Macro F1 Score 0.9135792612106244\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.7796 - binary_accuracy: 0.8991 - val_loss: 0.7527 - val_binary_accuracy: 0.9136\n",
      "Epoch 10/30\n",
      "134/134 [==============================] - 0s 2ms/steposs: 0.7742 - binary_ac\n",
      "Validation Macro F1 Score 0.9095967341105873\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.7745 - binary_accuracy: 0.8993 - val_loss: 0.7436 - val_binary_accuracy: 0.9096\n",
      "Epoch 11/30\n",
      "134/134 [==============================] - 0s 2ms/steposs: 0.7693 - binary_accu\n",
      "Validation Macro F1 Score 0.9131249120680751\n",
      "Early Stopping\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.7699 - binary_accuracy: 0.9004 - val_loss: 0.7517 - val_binary_accuracy: 0.9131\n",
      "Epoch 1/30\n",
      "142/142 [==============================] - 0s 2ms/steposs: 14.7221 - binary_ac\n",
      "Validation Macro F1 Score 0.8640744668316249\n",
      "402/402 [==============================] - 6s 14ms/step - loss: 14.6101 - binary_accuracy: 0.8614 - val_loss: 0.8616 - val_binary_accuracy: 0.8641\n",
      "Epoch 2/30\n",
      "142/142 [==============================] - 0s 2ms/steposs: 0.8428 - binary_ac\n",
      "Validation Macro F1 Score 0.8649497619565141\n",
      "402/402 [==============================] - 5s 13ms/step - loss: 0.8427 - binary_accuracy: 0.8701 - val_loss: 0.8190 - val_binary_accuracy: 0.8650\n",
      "Epoch 3/30\n",
      "142/142 [==============================] - 0s 2ms/steposs: 0.8152 - binary_ac\n",
      "Validation Macro F1 Score 0.8642570761109197\n",
      "402/402 [==============================] - 5s 13ms/step - loss: 0.8153 - binary_accuracy: 0.8726 - val_loss: 0.8084 - val_binary_accuracy: 0.8643\n",
      "Epoch 4/30\n",
      "142/142 [==============================] - 0s 2ms/steposs: 0.8023 - binary_ac\n",
      "Validation Macro F1 Score 0.8689173344136746\n",
      "402/402 [==============================] - 6s 14ms/step - loss: 0.8022 - binary_accuracy: 0.8743 - val_loss: 0.8013 - val_binary_accuracy: 0.8689\n",
      "Epoch 5/30\n",
      "142/142 [==============================] - 0s 2ms/steposs: 0.7952 - binary_ac\n",
      "Validation Macro F1 Score 0.8728288758705396\n",
      "402/402 [==============================] - 6s 14ms/step - loss: 0.7952 - binary_accuracy: 0.8771 - val_loss: 0.8123 - val_binary_accuracy: 0.8729\n",
      "Epoch 6/30\n",
      "142/142 [==============================] - 0s 3ms/steposs: 0.7906 - binary_\n",
      "Validation Macro F1 Score 0.8845187906978965\n",
      "402/402 [==============================] - 5s 14ms/step - loss: 0.7909 - binary_accuracy: 0.8810 - val_loss: 0.7995 - val_binary_accuracy: 0.8846\n",
      "Epoch 7/30\n",
      "142/142 [==============================] - 0s 2ms/steposs: 0.7869 - binary_ac\n",
      "Validation Macro F1 Score 0.8896730895819458\n",
      "402/402 [==============================] - 5s 13ms/step - loss: 0.7869 - binary_accuracy: 0.8904 - val_loss: 0.7927 - val_binary_accuracy: 0.8897\n",
      "Epoch 8/30\n",
      "142/142 [==============================] - 0s 2ms/steposs: 0.7724 - binary_ac\n",
      "Validation Macro F1 Score 0.8969398079927837\n",
      "402/402 [==============================] - 5s 13ms/step - loss: 0.7725 - binary_accuracy: 0.8984 - val_loss: 0.7761 - val_binary_accuracy: 0.8970\n",
      "Epoch 9/30\n",
      "142/142 [==============================] - 0s 2ms/steposs: 0.7651 - binary_ac\n",
      "Validation Macro F1 Score 0.8818846094886683\n",
      "402/402 [==============================] - 6s 14ms/step - loss: 0.7651 - binary_accuracy: 0.9024 - val_loss: 0.7913 - val_binary_accuracy: 0.8824\n",
      "Epoch 10/30\n",
      "142/142 [==============================] - 0s 2ms/steposs: 0.7570 - binary_ac\n",
      "Validation Macro F1 Score 0.9011083962903959\n",
      "402/402 [==============================] - 6s 14ms/step - loss: 0.7571 - binary_accuracy: 0.9058 - val_loss: 0.7611 - val_binary_accuracy: 0.9011\n",
      "Epoch 11/30\n",
      "142/142 [==============================] - 0s 3ms/steposs: 0.7576 - binary_\n",
      "Validation Macro F1 Score 0.9035582355918224\n",
      "402/402 [==============================] - 5s 14ms/step - loss: 0.7578 - binary_accuracy: 0.9050 - val_loss: 0.7607 - val_binary_accuracy: 0.9036\n",
      "Epoch 12/30\n",
      "142/142 [==============================] - 0s 2ms/steposs: 0.7552 - binary_ac\n",
      "Validation Macro F1 Score 0.898493153673084\n",
      "402/402 [==============================] - 5s 13ms/step - loss: 0.7548 - binary_accuracy: 0.9042 - val_loss: 0.7732 - val_binary_accuracy: 0.8985\n",
      "Epoch 13/30\n",
      "142/142 [==============================] - 0s 2ms/steposs: 0.7547 - binary_ac\n",
      "Validation Macro F1 Score 0.9037572785326173\n",
      "402/402 [==============================] - 5s 14ms/step - loss: 0.7547 - binary_accuracy: 0.9062 - val_loss: 0.7546 - val_binary_accuracy: 0.9038\n",
      "Epoch 14/30\n",
      "142/142 [==============================] - 0s 3ms/steposs: 0.7565 - binary_ac\n",
      "Validation Macro F1 Score 0.8987199702029922\n",
      "402/402 [==============================] - 5s 14ms/step - loss: 0.7565 - binary_accuracy: 0.9055 - val_loss: 0.7688 - val_binary_accuracy: 0.8987\n",
      "Epoch 15/30\n",
      "142/142 [==============================] - 0s 2ms/steposs: 0.7512 - binary_ac\n",
      "Validation Macro F1 Score 0.8968247758518055\n",
      "Early Stopping\n",
      "402/402 [==============================] - 5s 14ms/step - loss: 0.7512 - binary_accuracy: 0.9060 - val_loss: 0.7634 - val_binary_accuracy: 0.8970\n",
      "Epoch 1/30\n",
      "1320/1320 [==============================] - 3s 2ms/step\n",
      "Validation Macro F1 Score 0.8981911640396684\n",
      "3740/3740 [==============================] - 55s 14ms/step - loss: 2.2824 - binary_accuracy: 0.8792 - val_loss: 0.7761 - val_binary_accuracy: 0.8982\n",
      "Epoch 2/30\n",
      "1320/1320 [==============================] - 3s 2ms/step\n",
      "Validation Macro F1 Score 0.9092053362871861\n",
      "3740/3740 [==============================] - 51s 14ms/step - loss: 0.7586 - binary_accuracy: 0.9025 - val_loss: 0.7425 - val_binary_accuracy: 0.9092\n",
      "Epoch 3/30\n",
      "1320/1320 [==============================] - 3s 2ms/step\n",
      "Validation Macro F1 Score 0.9060459210633527\n",
      "3740/3740 [==============================] - 51s 14ms/step - loss: 0.7535 - binary_accuracy: 0.9039 - val_loss: 0.7465 - val_binary_accuracy: 0.9061\n",
      "Epoch 4/30\n",
      "1320/1320 [==============================] - 3s 2ms/step\n",
      "Validation Macro F1 Score 0.9069440423389745\n",
      "Early Stopping\n",
      "3740/3740 [==============================] - 51s 14ms/step - loss: 0.7525 - binary_accuracy: 0.9034 - val_loss: 0.7467 - val_binary_accuracy: 0.9069\n",
      "Epoch 1/30\n",
      "608/608 [==============================] - 1s 2ms/step\n",
      "Validation Macro F1 Score 0.8683180367392676\n",
      "1723/1723 [==============================] - 25s 14ms/step - loss: 4.0240 - binary_accuracy: 0.8714 - val_loss: 0.7901 - val_binary_accuracy: 0.8683\n",
      "Epoch 2/30\n",
      "608/608 [==============================] - 1s 2ms/step\n",
      "Validation Macro F1 Score 0.8883370260167951\n",
      "1723/1723 [==============================] - 24s 14ms/step - loss: 0.7931 - binary_accuracy: 0.8807 - val_loss: 0.8133 - val_binary_accuracy: 0.8883\n",
      "Epoch 3/30\n",
      "608/608 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.902070905282083\n",
      "1723/1723 [==============================] - 25s 15ms/step - loss: 0.7712 - binary_accuracy: 0.9000 - val_loss: 0.7679 - val_binary_accuracy: 0.9021\n",
      "Epoch 4/30\n",
      "608/608 [==============================] - 1s 2ms/step\n",
      "Validation Macro F1 Score 0.9067493943634364\n",
      "1723/1723 [==============================] - 24s 14ms/step - loss: 0.7594 - binary_accuracy: 0.9041 - val_loss: 0.7556 - val_binary_accuracy: 0.9067\n",
      "Epoch 5/30\n",
      "608/608 [==============================] - 1s 2ms/step\n",
      "Validation Macro F1 Score 0.901371942998771\n",
      "1723/1723 [==============================] - 24s 14ms/step - loss: 0.7570 - binary_accuracy: 0.9030 - val_loss: 0.7602 - val_binary_accuracy: 0.9016\n",
      "Epoch 6/30\n",
      "608/608 [==============================] - 1s 2ms/step\n",
      "Validation Macro F1 Score 0.9054527958850123\n",
      "Early Stopping\n",
      "1723/1723 [==============================] - 24s 14ms/step - loss: 0.7565 - binary_accuracy: 0.9048 - val_loss: 0.7509 - val_binary_accuracy: 0.9055\n",
      "Epoch 1/30\n",
      "305/305 [==============================] - 1s 2ms/steposs: 7.237\n",
      "Validation Macro F1 Score 0.8704075038648347\n",
      "864/864 [==============================] - 13s 14ms/step - loss: 7.2373 - binary_accuracy: 0.8668 - val_loss: 0.8508 - val_binary_accuracy: 0.8705\n",
      "Epoch 2/30\n",
      "305/305 [==============================] - 1s 2ms/steposs: 0.\n",
      "Validation Macro F1 Score 0.8768187667320657\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.8099 - binary_accuracy: 0.8721 - val_loss: 0.7941 - val_binary_accuracy: 0.8768\n",
      "Epoch 3/30\n",
      "305/305 [==============================] - 1s 2ms/steposs: 0.\n",
      "Validation Macro F1 Score 0.8811147857241286\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.7947 - binary_accuracy: 0.8738 - val_loss: 0.7875 - val_binary_accuracy: 0.8811\n",
      "Epoch 4/30\n",
      "305/305 [==============================] - 1s 3ms/steposs: \n",
      "Validation Macro F1 Score 0.8952131471844378\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.7901 - binary_accuracy: 0.8829 - val_loss: 0.7823 - val_binary_accuracy: 0.8954\n",
      "Epoch 5/30\n",
      "305/305 [==============================] - 1s 3ms/steposs: \n",
      "Validation Macro F1 Score 0.8977711217677744\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.7809 - binary_accuracy: 0.8943 - val_loss: 0.7724 - val_binary_accuracy: 0.8978\n",
      "Epoch 6/30\n",
      "305/305 [==============================] - 1s 2ms/steposs: 0.\n",
      "Validation Macro F1 Score 0.903053411705004\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.7730 - binary_accuracy: 0.8982 - val_loss: 0.7665 - val_binary_accuracy: 0.9031\n",
      "Epoch 7/30\n",
      "305/305 [==============================] - 1s 3ms/steposs: 0.\n",
      "Validation Macro F1 Score 0.903168556296158\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.7690 - binary_accuracy: 0.8979 - val_loss: 0.7674 - val_binary_accuracy: 0.9033\n",
      "Epoch 8/30\n",
      "305/305 [==============================] - 1s 3ms/steposs: \n",
      "Validation Macro F1 Score 0.9084449372549678\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.7666 - binary_accuracy: 0.8990 - val_loss: 0.7553 - val_binary_accuracy: 0.9085\n",
      "Epoch 9/30\n",
      "305/305 [==============================] - 1s 3ms/steposs: \n",
      "Validation Macro F1 Score 0.9045744275564684\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.7641 - binary_accuracy: 0.8999 - val_loss: 0.7646 - val_binary_accuracy: 0.9046\n",
      "Epoch 10/30\n",
      "305/305 [==============================] - 1s 3ms/steposs: \n",
      "Validation Macro F1 Score 0.898054724878731\n",
      "Early Stopping\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.7609 - binary_accuracy: 0.9003 - val_loss: 0.7651 - val_binary_accuracy: 0.8982\n",
      "Epoch 1/30\n",
      "722/722 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.8737169425290505\n",
      "2044/2044 [==============================] - 29s 14ms/step - loss: 3.5336 - binary_accuracy: 0.8688 - val_loss: 0.8038 - val_binary_accuracy: 0.8739\n",
      "Epoch 2/30\n",
      "722/722 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.8941537367363236\n",
      "2044/2044 [==============================] - 28s 14ms/step - loss: 0.7937 - binary_accuracy: 0.8837 - val_loss: 0.7776 - val_binary_accuracy: 0.8944\n",
      "Epoch 3/30\n",
      "722/722 [==============================] - 2s 3ms/step\n",
      "Validation Macro F1 Score 0.9081645870287456\n",
      "2044/2044 [==============================] - 29s 14ms/step - loss: 0.7669 - binary_accuracy: 0.9018 - val_loss: 0.7588 - val_binary_accuracy: 0.9082\n",
      "Epoch 4/30\n",
      "722/722 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.907117285800388\n",
      "2044/2044 [==============================] - 28s 14ms/step - loss: 0.7627 - binary_accuracy: 0.9028 - val_loss: 0.7534 - val_binary_accuracy: 0.9071\n",
      "Epoch 5/30\n",
      "722/722 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9067863724494554\n",
      "Early Stopping\n",
      "2044/2044 [==============================] - 28s 14ms/step - loss: 0.7585 - binary_accuracy: 0.9031 - val_loss: 0.7481 - val_binary_accuracy: 0.9068\n",
      "Epoch 1/30\n",
      "277/277 [==============================] - 1s 2ms/steposs: 7.9460 \n",
      "Validation Macro F1 Score 0.8744235839788634\n",
      "783/783 [==============================] - 12s 14ms/step - loss: 7.9130 - binary_accuracy: 0.8656 - val_loss: 0.8257 - val_binary_accuracy: 0.8744\n",
      "Epoch 2/30\n",
      "277/277 [==============================] - 1s 2ms/steposs: 0.8167\n",
      "Validation Macro F1 Score 0.8728490125789409\n",
      "783/783 [==============================] - 11s 14ms/step - loss: 0.8167 - binary_accuracy: 0.8714 - val_loss: 0.8049 - val_binary_accuracy: 0.8729\n",
      "Epoch 3/30\n",
      "277/277 [==============================] - 1s 2ms/steposs: 0.8035\n",
      "Validation Macro F1 Score 0.8770040137266423\n",
      "783/783 [==============================] - 11s 14ms/step - loss: 0.8035 - binary_accuracy: 0.8737 - val_loss: 0.8028 - val_binary_accuracy: 0.8770\n",
      "Epoch 4/30\n",
      "277/277 [==============================] - 1s 2ms/steposs: 0.79\n",
      "Validation Macro F1 Score 0.896943030824991\n",
      "783/783 [==============================] - 11s 14ms/step - loss: 0.7957 - binary_accuracy: 0.8846 - val_loss: 0.7734 - val_binary_accuracy: 0.8969\n",
      "Epoch 5/30\n",
      "277/277 [==============================] - 1s 2ms/steposs: 0.77\n",
      "Validation Macro F1 Score 0.9002796763335081\n",
      "783/783 [==============================] - 11s 14ms/step - loss: 0.7770 - binary_accuracy: 0.8988 - val_loss: 0.7643 - val_binary_accuracy: 0.9005\n",
      "Epoch 6/30\n",
      "277/277 [==============================] - 1s 2ms/steposs: 0.7691\n",
      "Validation Macro F1 Score 0.8916130569683319\n",
      "783/783 [==============================] - 11s 14ms/step - loss: 0.7691 - binary_accuracy: 0.9020 - val_loss: 0.8022 - val_binary_accuracy: 0.8917\n",
      "Epoch 7/30\n",
      "277/277 [==============================] - 1s 2ms/steposs: 0.7643\n",
      "Validation Macro F1 Score 0.896796122847253\n",
      "Early Stopping\n",
      "783/783 [==============================] - 11s 14ms/step - loss: 0.7644 - binary_accuracy: 0.9029 - val_loss: 0.7723 - val_binary_accuracy: 0.8971\n",
      "Epoch 1/30\n",
      "803/803 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.8715337239725991\n",
      "2275/2275 [==============================] - 32s 14ms/step - loss: 3.2541 - binary_accuracy: 0.8705 - val_loss: 0.8011 - val_binary_accuracy: 0.8717\n",
      "Epoch 2/30\n",
      "803/803 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9078796043273165\n",
      "2275/2275 [==============================] - 31s 14ms/step - loss: 0.7849 - binary_accuracy: 0.8894 - val_loss: 0.7606 - val_binary_accuracy: 0.9079\n",
      "Epoch 3/30\n",
      "803/803 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9071829668527436\n",
      "2275/2275 [==============================] - 31s 14ms/step - loss: 0.7671 - binary_accuracy: 0.9015 - val_loss: 0.7498 - val_binary_accuracy: 0.9072\n",
      "Epoch 4/30\n",
      "803/803 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9086190207744322\n",
      "2275/2275 [==============================] - 31s 14ms/step - loss: 0.7582 - binary_accuracy: 0.9037 - val_loss: 0.7551 - val_binary_accuracy: 0.9086\n",
      "Epoch 5/30\n",
      "803/803 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9109804630107338\n",
      "2275/2275 [==============================] - 31s 14ms/step - loss: 0.7531 - binary_accuracy: 0.9055 - val_loss: 0.7406 - val_binary_accuracy: 0.9110\n",
      "Epoch 6/30\n",
      "803/803 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9106467164519967\n",
      "2275/2275 [==============================] - 31s 14ms/step - loss: 0.7526 - binary_accuracy: 0.9056 - val_loss: 0.7494 - val_binary_accuracy: 0.9106\n",
      "Epoch 7/30\n",
      "803/803 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9084401224874775\n",
      "Early Stopping\n",
      "2275/2275 [==============================] - 31s 14ms/step - loss: 0.7513 - binary_accuracy: 0.9061 - val_loss: 0.7542 - val_binary_accuracy: 0.9085\n",
      "Epoch 1/30\n",
      "1259/1259 [==============================] - 3s 2ms/step\n",
      "Validation Macro F1 Score 0.9045211979105066\n",
      "3566/3566 [==============================] - 50s 14ms/step - loss: 2.3491 - binary_accuracy: 0.8807 - val_loss: 0.7685 - val_binary_accuracy: 0.9046\n",
      "Epoch 2/30\n",
      "1259/1259 [==============================] - 3s 2ms/step\n",
      "Validation Macro F1 Score 0.9093151148442278\n",
      "3566/3566 [==============================] - 49s 14ms/step - loss: 0.7630 - binary_accuracy: 0.9030 - val_loss: 0.7433 - val_binary_accuracy: 0.9093\n",
      "Epoch 3/30\n",
      "1259/1259 [==============================] - 3s 2ms/step\n",
      "Validation Macro F1 Score 0.9046368410891259\n",
      "3566/3566 [==============================] - 49s 14ms/step - loss: 0.7564 - binary_accuracy: 0.9041 - val_loss: 0.7487 - val_binary_accuracy: 0.9047\n",
      "Epoch 4/30\n",
      "1259/1259 [==============================] - 3s 2ms/step\n",
      "Validation Macro F1 Score 0.9108796300413762\n",
      "3566/3566 [==============================] - 49s 14ms/step - loss: 0.7545 - binary_accuracy: 0.9050 - val_loss: 0.7395 - val_binary_accuracy: 0.9109\n",
      "Epoch 5/30\n",
      "1259/1259 [==============================] - 3s 2ms/step\n",
      "Validation Macro F1 Score 0.9111824450902759\n",
      "3566/3566 [==============================] - 49s 14ms/step - loss: 0.7528 - binary_accuracy: 0.9057 - val_loss: 0.7486 - val_binary_accuracy: 0.9112\n",
      "Epoch 6/30\n",
      "1259/1259 [==============================] - 3s 2ms/step\n",
      "Validation Macro F1 Score 0.9057211858425172\n",
      "3566/3566 [==============================] - 49s 14ms/step - loss: 0.7520 - binary_accuracy: 0.9061 - val_loss: 0.7454 - val_binary_accuracy: 0.9057\n",
      "Epoch 7/30\n",
      "1259/1259 [==============================] - 3s 2ms/step\n",
      "Validation Macro F1 Score 0.9120465872886788\n",
      "3566/3566 [==============================] - 49s 14ms/step - loss: 0.7501 - binary_accuracy: 0.9073 - val_loss: 0.7450 - val_binary_accuracy: 0.9121\n",
      "Epoch 8/30\n",
      "1259/1259 [==============================] - 3s 2ms/step\n",
      "Validation Macro F1 Score 0.9071392927295368\n",
      "3566/3566 [==============================] - 49s 14ms/step - loss: 0.7505 - binary_accuracy: 0.9069 - val_loss: 0.7621 - val_binary_accuracy: 0.9072\n",
      "Epoch 9/30\n",
      "1259/1259 [==============================] - 3s 2ms/step\n",
      "Validation Macro F1 Score 0.9115278315079023\n",
      "Early Stopping\n",
      "3566/3566 [==============================] - 49s 14ms/step - loss: 0.7486 - binary_accuracy: 0.9073 - val_loss: 0.7498 - val_binary_accuracy: 0.9115\n",
      "Epoch 1/30\n",
      "1036/1036 [==============================] - 3s 2ms/step\n",
      "Validation Macro F1 Score 0.8857488684813961\n",
      "2934/2934 [==============================] - 42s 14ms/step - loss: 2.6964 - binary_accuracy: 0.8715 - val_loss: 0.7991 - val_binary_accuracy: 0.8859\n",
      "Epoch 2/30\n",
      "1036/1036 [==============================] - 3s 2ms/step\n",
      "Validation Macro F1 Score 0.9107288007204669\n",
      "2934/2934 [==============================] - 41s 14ms/step - loss: 0.7811 - binary_accuracy: 0.8954 - val_loss: 0.7495 - val_binary_accuracy: 0.9107\n",
      "Epoch 3/30\n",
      "1036/1036 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9095494188990747\n",
      "2934/2934 [==============================] - 41s 14ms/step - loss: 0.7654 - binary_accuracy: 0.9023 - val_loss: 0.7537 - val_binary_accuracy: 0.9096\n",
      "Epoch 4/30\n",
      "1036/1036 [==============================] - 3s 2ms/step\n",
      "Validation Macro F1 Score 0.911045691526088\n",
      "2934/2934 [==============================] - 41s 14ms/step - loss: 0.7600 - binary_accuracy: 0.9035 - val_loss: 0.7397 - val_binary_accuracy: 0.9111\n",
      "Epoch 5/30\n",
      "1036/1036 [==============================] - 3s 2ms/step\n",
      "Validation Macro F1 Score 0.9033339263012109\n",
      "2934/2934 [==============================] - 41s 14ms/step - loss: 0.7571 - binary_accuracy: 0.9033 - val_loss: 0.7547 - val_binary_accuracy: 0.9033\n",
      "Epoch 6/30\n",
      "1036/1036 [==============================] - 2s 2ms/step\n",
      "Validation Macro F1 Score 0.9107409043078616\n",
      "Early Stopping\n",
      "2934/2934 [==============================] - 41s 14ms/step - loss: 0.7550 - binary_accuracy: 0.9036 - val_loss: 0.7398 - val_binary_accuracy: 0.9108\n",
      "612/612 [==============================] - 2s 2ms/step\n",
      "612/612 [==============================] - 2s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 2s 2ms/step\n",
      "612/612 [==============================] - 2s 2ms/step\n",
      "612/612 [==============================] - 2s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 2s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 2s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 2s 2ms/step\n",
      "612/612 [==============================] - 2s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 2s 2ms/step\n",
      "612/612 [==============================] - 2s 2ms/step\n",
      "612/612 [==============================] - 2s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 2s 2ms/step\n",
      "612/612 [==============================] - 2s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 1s 2ms/step\n",
      "612/612 [==============================] - 2s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     19027\n",
      "           1       0.62      0.50      0.56       552\n",
      "\n",
      "    accuracy                           0.98     19579\n",
      "   macro avg       0.80      0.75      0.77     19579\n",
      "weighted avg       0.98      0.98      0.98     19579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_shape = df_train_sc.drop(columns=['label']).shape[1]\n",
    "epochs = 30\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "# Initialize Model\n",
    "resampling_model = MyNeuralNetworkClassifierEarlyStopping(number_of_models,input_shape)\n",
    "\n",
    "# Train Model\n",
    "resampling_model.fit(sample_ids, df_train_sc, epochs, batch_size)\n",
    "\n",
    "# predict\n",
    "df_kyc_val_X = df_val_sc.drop(columns=['label'])\n",
    "df_kyc_val_y = df_val_sc['label']\n",
    "\n",
    "predictions = resampling_model.predict(df_kyc_val_X, threshold = 0.95)\n",
    "\n",
    "# print report\n",
    "print(classification_report(df_kyc_val_y,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning Custom Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = df_train_sc.drop(columns=['label']).shape[1]\n",
    "epochs = 1\n",
    "batch_size = 10\n",
    "\n",
    "\n",
    "# Initialize Model\n",
    "resampling_model = MyNeuralNetworkClassifier(number_of_models,input_shape)\n",
    "\n",
    "# Train Model\n",
    "resampling_model.fit(sample_ids, df_train_sc, epochs, batch_size)\n",
    "\n",
    "# predict\n",
    "df_kyc_val_X = df_val_sc.drop(columns=['label'])\n",
    "df_kyc_val_y = df_val_sc['label']\n",
    "\n",
    "predictions = resampling_model.predict(df_kyc_val_X, threshold = 0.95)\n",
    "\n",
    "# print report\n",
    "print(classification_report(df_kyc_val_y,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
